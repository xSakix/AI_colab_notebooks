{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "seneca.ipynb",
      "provenance": [],
      "machine_shape": "hm",
      "authorship_tag": "ABX9TyPLFzuRhDeHwxHvmtWu6p+Z",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/xSakix/AI_colab_notebooks/blob/master/seneca.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "MdMVTaWXijAm",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "outputId": "82665b08-fefa-44fe-d1cd-50977ae810f5"
      },
      "source": [
        "!git clone https://github.com/huggingface/transformers\n",
        "!pip install transformers\n",
        "!pip install -r transformers/examples/requirements.txt"
      ],
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Cloning into 'transformers'...\n",
            "remote: Enumerating objects: 20089, done.\u001b[K\n",
            "remote: Total 20089 (delta 0), reused 0 (delta 0), pack-reused 20089\n",
            "Receiving objects: 100% (20089/20089), 11.63 MiB | 6.38 MiB/s, done.\n",
            "Resolving deltas: 100% (14682/14682), done.\n",
            "Collecting transformers\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/ee/fc/bd726a15ab2c66dc09306689d04da07a3770dad724f0883f0a4bfb745087/transformers-2.4.1-py3-none-any.whl (475kB)\n",
            "\u001b[K     |████████████████████████████████| 481kB 2.5MB/s \n",
            "\u001b[?25hRequirement already satisfied: boto3 in /usr/local/lib/python3.6/dist-packages (from transformers) (1.11.15)\n",
            "Collecting tokenizers==0.0.11\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/5e/36/7af38d572c935f8e0462ec7b4f7a46d73a2b3b1a938f50a5e8132d5b2dc5/tokenizers-0.0.11-cp36-cp36m-manylinux1_x86_64.whl (3.1MB)\n",
            "\u001b[K     |████████████████████████████████| 3.1MB 6.1MB/s \n",
            "\u001b[?25hCollecting sentencepiece\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/74/f4/2d5214cbf13d06e7cb2c20d84115ca25b53ea76fa1f0ade0e3c9749de214/sentencepiece-0.1.85-cp36-cp36m-manylinux1_x86_64.whl (1.0MB)\n",
            "\u001b[K     |████████████████████████████████| 1.0MB 22.1MB/s \n",
            "\u001b[?25hRequirement already satisfied: tqdm>=4.27 in /usr/local/lib/python3.6/dist-packages (from transformers) (4.28.1)\n",
            "Collecting sacremoses\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/a6/b4/7a41d630547a4afd58143597d5a49e07bfd4c42914d8335b2a5657efc14b/sacremoses-0.0.38.tar.gz (860kB)\n",
            "\u001b[K     |████████████████████████████████| 870kB 27.6MB/s \n",
            "\u001b[?25hRequirement already satisfied: regex!=2019.12.17 in /usr/local/lib/python3.6/dist-packages (from transformers) (2019.12.20)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.6/dist-packages (from transformers) (2.21.0)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.6/dist-packages (from transformers) (3.0.12)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.6/dist-packages (from transformers) (1.17.5)\n",
            "Requirement already satisfied: jmespath<1.0.0,>=0.7.1 in /usr/local/lib/python3.6/dist-packages (from boto3->transformers) (0.9.4)\n",
            "Requirement already satisfied: s3transfer<0.4.0,>=0.3.0 in /usr/local/lib/python3.6/dist-packages (from boto3->transformers) (0.3.3)\n",
            "Requirement already satisfied: botocore<1.15.0,>=1.14.15 in /usr/local/lib/python3.6/dist-packages (from boto3->transformers) (1.14.15)\n",
            "Requirement already satisfied: six in /usr/local/lib/python3.6/dist-packages (from sacremoses->transformers) (1.12.0)\n",
            "Requirement already satisfied: click in /usr/local/lib/python3.6/dist-packages (from sacremoses->transformers) (7.0)\n",
            "Requirement already satisfied: joblib in /usr/local/lib/python3.6/dist-packages (from sacremoses->transformers) (0.14.1)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.6/dist-packages (from requests->transformers) (2019.11.28)\n",
            "Requirement already satisfied: chardet<3.1.0,>=3.0.2 in /usr/local/lib/python3.6/dist-packages (from requests->transformers) (3.0.4)\n",
            "Requirement already satisfied: idna<2.9,>=2.5 in /usr/local/lib/python3.6/dist-packages (from requests->transformers) (2.8)\n",
            "Requirement already satisfied: urllib3<1.25,>=1.21.1 in /usr/local/lib/python3.6/dist-packages (from requests->transformers) (1.24.3)\n",
            "Requirement already satisfied: python-dateutil<3.0.0,>=2.1 in /usr/local/lib/python3.6/dist-packages (from botocore<1.15.0,>=1.14.15->boto3->transformers) (2.6.1)\n",
            "Requirement already satisfied: docutils<0.16,>=0.10 in /usr/local/lib/python3.6/dist-packages (from botocore<1.15.0,>=1.14.15->boto3->transformers) (0.15.2)\n",
            "Building wheels for collected packages: sacremoses\n",
            "  Building wheel for sacremoses (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for sacremoses: filename=sacremoses-0.0.38-cp36-none-any.whl size=884628 sha256=664772d6ea73feb8028ae68ec7a4154cdff76acac2398b6fd2531147be8b9ff8\n",
            "  Stored in directory: /root/.cache/pip/wheels/6d/ec/1a/21b8912e35e02741306f35f66c785f3afe94de754a0eaf1422\n",
            "Successfully built sacremoses\n",
            "Installing collected packages: tokenizers, sentencepiece, sacremoses, transformers\n",
            "Successfully installed sacremoses-0.0.38 sentencepiece-0.1.85 tokenizers-0.0.11 transformers-2.4.1\n",
            "Collecting tensorboardX\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/35/f1/5843425495765c8c2dd0784a851a93ef204d314fc87bcc2bbb9f662a3ad1/tensorboardX-2.0-py2.py3-none-any.whl (195kB)\n",
            "\u001b[K     |████████████████████████████████| 204kB 2.8MB/s \n",
            "\u001b[?25hRequirement already satisfied: tensorboard in /usr/local/lib/python3.6/dist-packages (from -r transformers/examples/requirements.txt (line 2)) (1.15.0)\n",
            "Requirement already satisfied: scikit-learn in /usr/local/lib/python3.6/dist-packages (from -r transformers/examples/requirements.txt (line 3)) (0.22.1)\n",
            "Collecting seqeval\n",
            "  Downloading https://files.pythonhosted.org/packages/34/91/068aca8d60ce56dd9ba4506850e876aba5e66a6f2f29aa223224b50df0de/seqeval-0.0.12.tar.gz\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.6/dist-packages (from tensorboardX->-r transformers/examples/requirements.txt (line 1)) (1.17.5)\n",
            "Requirement already satisfied: protobuf>=3.8.0 in /usr/local/lib/python3.6/dist-packages (from tensorboardX->-r transformers/examples/requirements.txt (line 1)) (3.10.0)\n",
            "Requirement already satisfied: six in /usr/local/lib/python3.6/dist-packages (from tensorboardX->-r transformers/examples/requirements.txt (line 1)) (1.12.0)\n",
            "Requirement already satisfied: setuptools>=41.0.0 in /usr/local/lib/python3.6/dist-packages (from tensorboard->-r transformers/examples/requirements.txt (line 2)) (45.1.0)\n",
            "Requirement already satisfied: absl-py>=0.4 in /usr/local/lib/python3.6/dist-packages (from tensorboard->-r transformers/examples/requirements.txt (line 2)) (0.9.0)\n",
            "Requirement already satisfied: markdown>=2.6.8 in /usr/local/lib/python3.6/dist-packages (from tensorboard->-r transformers/examples/requirements.txt (line 2)) (3.2.1)\n",
            "Requirement already satisfied: grpcio>=1.6.3 in /usr/local/lib/python3.6/dist-packages (from tensorboard->-r transformers/examples/requirements.txt (line 2)) (1.27.1)\n",
            "Requirement already satisfied: werkzeug>=0.11.15 in /usr/local/lib/python3.6/dist-packages (from tensorboard->-r transformers/examples/requirements.txt (line 2)) (1.0.0)\n",
            "Requirement already satisfied: wheel>=0.26; python_version >= \"3\" in /usr/local/lib/python3.6/dist-packages (from tensorboard->-r transformers/examples/requirements.txt (line 2)) (0.34.2)\n",
            "Requirement already satisfied: joblib>=0.11 in /usr/local/lib/python3.6/dist-packages (from scikit-learn->-r transformers/examples/requirements.txt (line 3)) (0.14.1)\n",
            "Requirement already satisfied: scipy>=0.17.0 in /usr/local/lib/python3.6/dist-packages (from scikit-learn->-r transformers/examples/requirements.txt (line 3)) (1.4.1)\n",
            "Requirement already satisfied: Keras>=2.2.4 in /usr/local/lib/python3.6/dist-packages (from seqeval->-r transformers/examples/requirements.txt (line 4)) (2.2.5)\n",
            "Requirement already satisfied: keras-applications>=1.0.8 in /usr/local/lib/python3.6/dist-packages (from Keras>=2.2.4->seqeval->-r transformers/examples/requirements.txt (line 4)) (1.0.8)\n",
            "Requirement already satisfied: keras-preprocessing>=1.1.0 in /usr/local/lib/python3.6/dist-packages (from Keras>=2.2.4->seqeval->-r transformers/examples/requirements.txt (line 4)) (1.1.0)\n",
            "Requirement already satisfied: pyyaml in /usr/local/lib/python3.6/dist-packages (from Keras>=2.2.4->seqeval->-r transformers/examples/requirements.txt (line 4)) (3.13)\n",
            "Requirement already satisfied: h5py in /usr/local/lib/python3.6/dist-packages (from Keras>=2.2.4->seqeval->-r transformers/examples/requirements.txt (line 4)) (2.8.0)\n",
            "Building wheels for collected packages: seqeval\n",
            "  Building wheel for seqeval (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for seqeval: filename=seqeval-0.0.12-cp36-none-any.whl size=7424 sha256=a15185c3218769f20f2893beba17272cf3c197c9057db3939e67847174a0f84a\n",
            "  Stored in directory: /root/.cache/pip/wheels/4f/32/0a/df3b340a82583566975377d65e724895b3fad101a3fb729f68\n",
            "Successfully built seqeval\n",
            "Installing collected packages: tensorboardX, seqeval\n",
            "Successfully installed seqeval-0.0.12 tensorboardX-2.0\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ac8MN2ZliuLa",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 122
        },
        "outputId": "edb67d9e-c493-4f3a-ded2-0d2b39588946"
      },
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Go to this URL in a browser: https://accounts.google.com/o/oauth2/auth?client_id=947318989803-6bn6qk8qdgf4n4g3pfee6491hc0brc4i.apps.googleusercontent.com&redirect_uri=urn%3aietf%3awg%3aoauth%3a2.0%3aoob&response_type=code&scope=email%20https%3a%2f%2fwww.googleapis.com%2fauth%2fdocs.test%20https%3a%2f%2fwww.googleapis.com%2fauth%2fdrive%20https%3a%2f%2fwww.googleapis.com%2fauth%2fdrive.photos.readonly%20https%3a%2f%2fwww.googleapis.com%2fauth%2fpeopleapi.readonly\n",
            "\n",
            "Enter your authorization code:\n",
            "··········\n",
            "Mounted at /content/drive\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "LtfDk87Vix7m",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "outputId": "133be7bb-a24d-430d-9fe3-bfb7a096282c"
      },
      "source": [
        "!python transformers/examples/run_language_modeling.py --output_dir='/content/drive/My Drive/seneca/output' --model_type=gpt2 --model_name_or_path='/content/drive/My Drive/seneca/output' --do_train --train_data_file='/content/drive/My Drive/seneca/seneca.txt' --do_eval --eval_data_file='/content/drive/My Drive/seneca/seneca.txt' --no_cuda --num_train_epochs 10 --overwrite_output_dir"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "02/19/2020 13:56:35 - WARNING - __main__ -   Process rank: -1, device: cpu, n_gpu: 0, distributed training: False, 16-bits training: False\n",
            "02/19/2020 13:56:35 - INFO - transformers.configuration_utils -   loading configuration file /content/drive/My Drive/seneca/output/config.json\n",
            "02/19/2020 13:56:35 - INFO - transformers.configuration_utils -   Model config GPT2Config {\n",
            "  \"architectures\": [\n",
            "    \"GPT2LMHeadModel\"\n",
            "  ],\n",
            "  \"attn_pdrop\": 0.1,\n",
            "  \"bos_token_id\": 0,\n",
            "  \"do_sample\": false,\n",
            "  \"embd_pdrop\": 0.1,\n",
            "  \"eos_token_ids\": 0,\n",
            "  \"finetuning_task\": null,\n",
            "  \"id2label\": {\n",
            "    \"0\": \"LABEL_0\",\n",
            "    \"1\": \"LABEL_1\"\n",
            "  },\n",
            "  \"initializer_range\": 0.02,\n",
            "  \"is_decoder\": false,\n",
            "  \"label2id\": {\n",
            "    \"LABEL_0\": 0,\n",
            "    \"LABEL_1\": 1\n",
            "  },\n",
            "  \"layer_norm_epsilon\": 1e-05,\n",
            "  \"length_penalty\": 1.0,\n",
            "  \"max_length\": 20,\n",
            "  \"model_type\": \"gpt2\",\n",
            "  \"n_ctx\": 1024,\n",
            "  \"n_embd\": 768,\n",
            "  \"n_head\": 12,\n",
            "  \"n_layer\": 12,\n",
            "  \"n_positions\": 1024,\n",
            "  \"num_beams\": 1,\n",
            "  \"num_labels\": 2,\n",
            "  \"num_return_sequences\": 1,\n",
            "  \"output_attentions\": false,\n",
            "  \"output_hidden_states\": false,\n",
            "  \"output_past\": true,\n",
            "  \"pad_token_id\": 0,\n",
            "  \"pruned_heads\": {},\n",
            "  \"repetition_penalty\": 1.0,\n",
            "  \"resid_pdrop\": 0.1,\n",
            "  \"summary_activation\": null,\n",
            "  \"summary_first_dropout\": 0.1,\n",
            "  \"summary_proj_to_labels\": true,\n",
            "  \"summary_type\": \"cls_index\",\n",
            "  \"summary_use_proj\": true,\n",
            "  \"temperature\": 1.0,\n",
            "  \"top_k\": 50,\n",
            "  \"top_p\": 1.0,\n",
            "  \"torchscript\": false,\n",
            "  \"use_bfloat16\": false,\n",
            "  \"vocab_size\": 50257\n",
            "}\n",
            "\n",
            "02/19/2020 13:56:35 - INFO - transformers.tokenization_utils -   Model name '/content/drive/My Drive/seneca/output' not found in model shortcut name list (gpt2, gpt2-medium, gpt2-large, gpt2-xl, distilgpt2). Assuming '/content/drive/My Drive/seneca/output' is a path, a model identifier, or url to a directory containing tokenizer files.\n",
            "02/19/2020 13:56:35 - INFO - transformers.tokenization_utils -   Didn't find file /content/drive/My Drive/seneca/output/added_tokens.json. We won't load it.\n",
            "02/19/2020 13:56:35 - INFO - transformers.tokenization_utils -   loading file /content/drive/My Drive/seneca/output/vocab.json\n",
            "02/19/2020 13:56:35 - INFO - transformers.tokenization_utils -   loading file /content/drive/My Drive/seneca/output/merges.txt\n",
            "02/19/2020 13:56:35 - INFO - transformers.tokenization_utils -   loading file None\n",
            "02/19/2020 13:56:35 - INFO - transformers.tokenization_utils -   loading file /content/drive/My Drive/seneca/output/special_tokens_map.json\n",
            "02/19/2020 13:56:35 - INFO - transformers.tokenization_utils -   loading file /content/drive/My Drive/seneca/output/tokenizer_config.json\n",
            "02/19/2020 13:56:35 - INFO - transformers.modeling_utils -   loading weights file /content/drive/My Drive/seneca/output/pytorch_model.bin\n",
            "02/19/2020 13:56:39 - INFO - __main__ -   Training/evaluation parameters Namespace(adam_epsilon=1e-08, block_size=1024, cache_dir=None, config_name=None, device=device(type='cpu'), do_eval=True, do_train=True, eval_all_checkpoints=False, eval_data_file='/content/drive/My Drive/seneca/seneca.txt', evaluate_during_training=False, fp16=False, fp16_opt_level='O1', gradient_accumulation_steps=1, learning_rate=5e-05, line_by_line=False, local_rank=-1, logging_steps=500, max_grad_norm=1.0, max_steps=-1, mlm=False, mlm_probability=0.15, model_name_or_path='/content/drive/My Drive/seneca/output', model_type='gpt2', n_gpu=0, no_cuda=True, num_train_epochs=10.0, output_dir='/content/drive/My Drive/seneca/output', overwrite_cache=False, overwrite_output_dir=True, per_gpu_eval_batch_size=4, per_gpu_train_batch_size=4, save_steps=500, save_total_limit=None, seed=42, server_ip='', server_port='', should_continue=False, tokenizer_name=None, train_data_file='/content/drive/My Drive/seneca/seneca.txt', warmup_steps=0, weight_decay=0.0)\n",
            "02/19/2020 13:56:39 - INFO - __main__ -   Loading features from cached file /content/drive/My Drive/seneca/gpt2_cached_lm_1024_seneca.txt\n",
            "02/19/2020 13:56:39 - INFO - __main__ -   ***** Running training *****\n",
            "02/19/2020 13:56:39 - INFO - __main__ -     Num examples = 169\n",
            "02/19/2020 13:56:39 - INFO - __main__ -     Num Epochs = 10\n",
            "02/19/2020 13:56:39 - INFO - __main__ -     Instantaneous batch size per GPU = 4\n",
            "02/19/2020 13:56:39 - INFO - __main__ -     Total train batch size (w. parallel, distributed & accumulation) = 4\n",
            "02/19/2020 13:56:39 - INFO - __main__ -     Gradient Accumulation steps = 1\n",
            "02/19/2020 13:56:39 - INFO - __main__ -     Total optimization steps = 430\n",
            "02/19/2020 13:56:39 - INFO - __main__ -     Starting fine-tuning.\n",
            "Epoch:   0% 0/10 [00:00<?, ?it/s]\n",
            "Iteration:   0% 0/43 [00:00<?, ?it/s]\u001b[A\n",
            "Iteration:   2% 1/43 [00:48<34:07, 48.74s/it]\u001b[A\n",
            "Iteration:   5% 2/43 [01:32<32:12, 47.13s/it]\u001b[A\n",
            "Iteration:   7% 3/43 [02:14<30:24, 45.60s/it]\u001b[A\n",
            "Iteration:   9% 4/43 [02:56<28:57, 44.55s/it]\u001b[A\n",
            "Iteration:  12% 5/43 [03:39<27:53, 44.04s/it]\u001b[A\n",
            "Iteration:  14% 6/43 [04:21<26:53, 43.60s/it]\u001b[A\n",
            "Iteration:  16% 7/43 [05:06<26:22, 43.95s/it]\u001b[A\n",
            "Iteration:  19% 8/43 [05:49<25:25, 43.60s/it]\u001b[A\n",
            "Iteration:  21% 9/43 [06:31<24:29, 43.23s/it]\u001b[A\n",
            "Iteration:  23% 10/43 [07:14<23:38, 42.99s/it]\u001b[A\n",
            "Iteration:  26% 11/43 [07:56<22:51, 42.86s/it]\u001b[A"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "WxO4jlXojC_K",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "outputId": "763d544b-cc81-48e7-b4b6-5c2500f03889"
      },
      "source": [
        "!python transformers/examples/run_generation.py --model_type=gpt2 --model_name_or_path='/content/drive/My Drive/seneca/output' --no_cuda --length 200"
      ],
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "02/19/2020 13:55:25 - INFO - transformers.tokenization_utils -   Model name '/content/drive/My Drive/seneca/output' not found in model shortcut name list (gpt2, gpt2-medium, gpt2-large, gpt2-xl, distilgpt2). Assuming '/content/drive/My Drive/seneca/output' is a path, a model identifier, or url to a directory containing tokenizer files.\n",
            "02/19/2020 13:55:25 - INFO - transformers.tokenization_utils -   Didn't find file /content/drive/My Drive/seneca/output/added_tokens.json. We won't load it.\n",
            "02/19/2020 13:55:25 - INFO - transformers.tokenization_utils -   loading file /content/drive/My Drive/seneca/output/vocab.json\n",
            "02/19/2020 13:55:25 - INFO - transformers.tokenization_utils -   loading file /content/drive/My Drive/seneca/output/merges.txt\n",
            "02/19/2020 13:55:25 - INFO - transformers.tokenization_utils -   loading file None\n",
            "02/19/2020 13:55:25 - INFO - transformers.tokenization_utils -   loading file /content/drive/My Drive/seneca/output/special_tokens_map.json\n",
            "02/19/2020 13:55:25 - INFO - transformers.tokenization_utils -   loading file /content/drive/My Drive/seneca/output/tokenizer_config.json\n",
            "02/19/2020 13:55:25 - INFO - transformers.configuration_utils -   loading configuration file /content/drive/My Drive/seneca/output/config.json\n",
            "02/19/2020 13:55:25 - INFO - transformers.configuration_utils -   Model config GPT2Config {\n",
            "  \"architectures\": [\n",
            "    \"GPT2LMHeadModel\"\n",
            "  ],\n",
            "  \"attn_pdrop\": 0.1,\n",
            "  \"bos_token_id\": 0,\n",
            "  \"do_sample\": false,\n",
            "  \"embd_pdrop\": 0.1,\n",
            "  \"eos_token_ids\": 0,\n",
            "  \"finetuning_task\": null,\n",
            "  \"id2label\": {\n",
            "    \"0\": \"LABEL_0\",\n",
            "    \"1\": \"LABEL_1\"\n",
            "  },\n",
            "  \"initializer_range\": 0.02,\n",
            "  \"is_decoder\": false,\n",
            "  \"label2id\": {\n",
            "    \"LABEL_0\": 0,\n",
            "    \"LABEL_1\": 1\n",
            "  },\n",
            "  \"layer_norm_epsilon\": 1e-05,\n",
            "  \"length_penalty\": 1.0,\n",
            "  \"max_length\": 20,\n",
            "  \"model_type\": \"gpt2\",\n",
            "  \"n_ctx\": 1024,\n",
            "  \"n_embd\": 768,\n",
            "  \"n_head\": 12,\n",
            "  \"n_layer\": 12,\n",
            "  \"n_positions\": 1024,\n",
            "  \"num_beams\": 1,\n",
            "  \"num_labels\": 2,\n",
            "  \"num_return_sequences\": 1,\n",
            "  \"output_attentions\": false,\n",
            "  \"output_hidden_states\": false,\n",
            "  \"output_past\": true,\n",
            "  \"pad_token_id\": 0,\n",
            "  \"pruned_heads\": {},\n",
            "  \"repetition_penalty\": 1.0,\n",
            "  \"resid_pdrop\": 0.1,\n",
            "  \"summary_activation\": null,\n",
            "  \"summary_first_dropout\": 0.1,\n",
            "  \"summary_proj_to_labels\": true,\n",
            "  \"summary_type\": \"cls_index\",\n",
            "  \"summary_use_proj\": true,\n",
            "  \"temperature\": 1.0,\n",
            "  \"top_k\": 50,\n",
            "  \"top_p\": 1.0,\n",
            "  \"torchscript\": false,\n",
            "  \"use_bfloat16\": false,\n",
            "  \"vocab_size\": 50257\n",
            "}\n",
            "\n",
            "02/19/2020 13:55:25 - INFO - transformers.modeling_utils -   loading weights file /content/drive/My Drive/seneca/output/pytorch_model.bin\n",
            "02/19/2020 13:55:30 - INFO - __main__ -   Namespace(device=device(type='cpu'), k=0, length=200, model_name_or_path='/content/drive/My Drive/seneca/output', model_type='gpt2', n_gpu=0, no_cuda=True, p=0.9, padding_text='', prompt='', repetition_penalty=1.0, seed=42, stop_token=None, temperature=1.0, xlm_language='')\n",
            "Model prompt >>> Whats the meaning of life?\n",
            "Whats the meaning of life?\n",
            "\n",
            "If not entirely silent, there is any interval in time when it becomes silent.\n",
            "And I shall return to the subject matter first, of dealing with the spirit,\n",
            "with which we are to deal in the Stoic philosophy. A word will bestow its\n",
            "benefit upon you: that is, not upon Stoics, for you must remember\n",
            "that philosophy is both really and unjustly led by common principles\n",
            "which are disgraceful, and which are wicked: that, consequently, Socrates becomes a\n",
            "prophet. A man who takes no pains to bear the truth, a man who\n",
            "who is forced to confess no secrets, falls into those channels of vice\n",
            "which afterwards form it, slips into your own being, and hides\n",
            "away; a man who is hard to believe is saved by prayers,\n",
            "who becomes famous, even when he has promised to come to me with\n",
            "discover it.\n",
            "\n",
            "\n",
            "XXXII. It would not!\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ckogEp3vucv7",
        "colab_type": "text"
      },
      "source": [
        "# Wih perplexity 13 after 10 epochs\n",
        "\n",
        "## Love\n",
        "<pre>\n",
        "Love,    What blood, sooth, burns                1554\n",
        "     By the flame of good fortune,\n",
        "    Shall a grateful owner fall,\n",
        "    The vanquished foe's fate;\n",
        "    Thy brothers yoke, thy wives, thy daughters,                       1555\n",
        "    That wild youth of the Rhine who dared\n",
        "     As he might, give a victory to kings and princes?\n",
        "    The brave Caligula\n",
        "    Her hosts with their armored host                               1560\n",
        "    Gives courage to the Rhine's coast;\n",
        "</pre>\n",
        "\n",
        "## Whats the meaning of life?\n",
        "\n",
        "<pre>\n",
        "If not entirely silent, there is any interval in time when it becomes silent.\n",
        "And I shall return to the subject matter first, of dealing with the spirit,\n",
        "with which we are to deal in the Stoic philosophy. A word will bestow its\n",
        "benefit upon you: that is, not upon Stoics, for you must remember\n",
        "that philosophy is both really and unjustly led by common principles\n",
        "which are disgraceful, and which are wicked: that, consequently, Socrates becomes a\n",
        "prophet. A man who takes no pains to bear the truth, a man who\n",
        "who is forced to confess no secrets, falls into those channels of vice\n",
        "which afterwards form it, slips into your own being, and hides\n",
        "away; a man who is hard to believe is saved by prayers,\n",
        "who becomes famous, even when he has promised to come to me with\n",
        "discover it.\n",
        "\n",
        "\n",
        "XXXII. It would not!\n",
        "<pre>"
      ]
    }
  ]
}