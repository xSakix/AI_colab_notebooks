{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "accelerator": "TPU",
    "colab": {
      "name": "Test Cloud TPUs and Keras",
      "provenance": [],
      "collapsed_sections": [
        "N6ZDpd9XzFeN"
      ],
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/xSakix/AI_colab_notebooks/blob/master/Test_Cloud_TPUs_and_Keras.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "N6ZDpd9XzFeN"
      },
      "source": [
        "##### Copyright 2018 The TensorFlow Hub Authors.\n",
        "\n",
        "Licensed under the Apache License, Version 2.0 (the \"License\");"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "cellView": "form",
        "colab_type": "code",
        "id": "KUu4vOt5zI9d",
        "colab": {}
      },
      "source": [
        "# Copyright 2018 The TensorFlow Hub Authors. All Rights Reserved.\n",
        "#\n",
        "# Licensed under the Apache License, Version 2.0 (the \"License\");\n",
        "# you may not use this file except in compliance with the License.\n",
        "# You may obtain a copy of the License at\n",
        "#\n",
        "#     http://www.apache.org/licenses/LICENSE-2.0\n",
        "#\n",
        "# Unless required by applicable law or agreed to in writing, software\n",
        "# distributed under the License is distributed on an \"AS IS\" BASIS,\n",
        "# WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n",
        "# See the License for the specific language governing permissions and\n",
        "# limitations under the License.\n",
        "# =============================================================================="
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "innBbve1LdjE",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "kYxeFuKCUx9d"
      },
      "source": [
        "TPUs are located in Google Cloud, for optimal performance, they read data directly from Google Cloud Storage (GCS)"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "aJiYai-GjQRk",
        "colab_type": "code",
        "outputId": "c69ae7eb-106a-4ec8-a840-4834edbf40bf",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 204
        }
      },
      "source": [
        "!head -n5 content/socrates.txt\n",
        "!echo \"...\"\n",
        "!shuf -n5 content/socrates.txt"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "How you, O Athenians, have been affected by my accusers, I cannot tell;\r\n",
            "but I know that they almost made me forget who I was--so persuasively\r\n",
            "did they speak; and yet they have hardly uttered a word of truth. But\r\n",
            "of the many falsehoods told by them, there was one which quite amazed\r\n",
            "me;--I mean when they said that you should be upon your guard and not\r\n",
            "...\n",
            "\"It is by no means difficult,\" he replied, \"to understand what I mean;\n",
            "\n",
            "body, and delighting in the same things, it is compelled, I think, to\n",
            "bad man into a good one.'\n",
            "no one, I am far from intending to injure myself, and of pronouncing\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "E3V4V-Jxmuv3",
        "outputId": "09f88170-711d-4d75-ce17-981385e1a93b",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 63
        }
      },
      "source": [
        "import numpy as np\n",
        "import tensorflow as tf\n",
        "import os\n",
        "\n",
        "import distutils\n",
        "if distutils.version.LooseVersion(tf.__version__) < '1.14':\n",
        "    raise Exception('This notebook is compatible with TensorFlow 1.14 or higher, for TensorFlow 1.13 or lower please use the previous version at https://github.com/tensorflow/tpu/blob/r1.13/tools/colab/shakespeare_with_tpu_and_keras.ipynb')\n",
        "\n",
        "# This address identifies the TPU we'll use when configuring TensorFlow.\n",
        "TPU_WORKER = 'grpc://' + os.environ['COLAB_TPU_ADDR']\n",
        "\n",
        "IN_TXT = 'content/socrates.txt'\n",
        "\n",
        "def transform(txt):\n",
        "  return np.asarray([ord(c) for c in txt if ord(c) < 255], dtype=np.int32)\n",
        "\n",
        "def input_fn(seq_len=100, batch_size=1024):\n",
        "  \"\"\"Return a dataset of source and target sequences for training.\"\"\"\n",
        "  with tf.io.gfile.GFile(IN_TXT, 'r') as f:\n",
        "    txt = f.read()\n",
        "\n",
        "  source = tf.constant(transform(txt), dtype=tf.int32)\n",
        "\n",
        "  ds = tf.data.Dataset.from_tensor_slices(source).batch(seq_len+1, drop_remainder=True)\n",
        "\n",
        "  def split_input_target(chunk):\n",
        "    input_text = chunk[:-1]\n",
        "    target_text = chunk[1:]\n",
        "    return input_text, target_text\n",
        "\n",
        "  BUFFER_SIZE = 10000\n",
        "  ds = ds.map(split_input_target).shuffle(BUFFER_SIZE).batch(batch_size, drop_remainder=True)\n",
        "\n",
        "  return ds.repeat()"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/html": [
              "<p style=\"color: red;\">\n",
              "The default version of TensorFlow in Colab will soon switch to TensorFlow 2.x.<br>\n",
              "We recommend you <a href=\"https://www.tensorflow.org/guide/migrate\" target=\"_blank\">upgrade</a> now \n",
              "or ensure your notebook will continue to use TensorFlow 1.x via the <code>%tensorflow_version 1.x</code> magic:\n",
              "<a href=\"https://colab.research.google.com/notebooks/tensorflow_version.ipynb\" target=\"_blank\">more info</a>.</p>\n"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {
            "tags": []
          }
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "Bbb05dNynDrQ"
      },
      "source": [
        "### Build the model\n",
        "\n",
        "The model is defined as a two-layer, forward-LSTM, the same model should work both on CPU and TPU.\n",
        "\n",
        "Because our vocabulary size is 256, the input dimension to the Embedding layer is 256.\n",
        "\n",
        "When specifying the arguments to the LSTM, it is important to note how the stateful argument is used. When training we will make sure that `stateful=False` because we do want to reset the state of our model between batches, but when sampling (computing predictions) from a trained model, we want `stateful=True` so that the model can retain information across the current batch and generate more interesting text."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "yLEM-fLJlEEt",
        "colab": {}
      },
      "source": [
        "EMBEDDING_DIM = 512\n",
        "\n",
        "def lstm_model(seq_len=100, batch_size=None, stateful=True):\n",
        "  \"\"\"Language model: predict the next word given the current word.\"\"\"\n",
        "  source = tf.keras.Input(\n",
        "      name='seed', shape=(seq_len,), batch_size=batch_size, dtype=tf.int32)\n",
        "\n",
        "  embedding = tf.keras.layers.Embedding(input_dim=256, output_dim=EMBEDDING_DIM)(source)\n",
        "  lstm_1 = tf.keras.layers.LSTM(EMBEDDING_DIM, stateful=stateful, return_sequences=True)(embedding)\n",
        "  lstm_2 = tf.keras.layers.LSTM(EMBEDDING_DIM, stateful=stateful, return_sequences=True)(lstm_1)\n",
        "  predicted_char = tf.keras.layers.TimeDistributed(tf.keras.layers.Dense(256, activation='softmax'))(lstm_2)\n",
        "  return tf.keras.Model(inputs=[source], outputs=[predicted_char])"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "VzBYDJI0_Tfm"
      },
      "source": [
        "### Train the model\n",
        "\n",
        "First, we need to create a distribution strategy that can use the TPU. In this case it is TPUStrategy. You can create and compile the model inside its scope. Once that is done, future calls to the standard Keras methods `fit`, `evaluate` and `predict` use the TPU.\n",
        "\n",
        "Again note that we train with `stateful=False` because while training, we only care about one batch at a time."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "ExQ922tfzSGA",
        "outputId": "201624a3-781c-4a39-b721-ef07c6792398",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        }
      },
      "source": [
        "tf.keras.backend.clear_session()\n",
        "\n",
        "resolver = tf.contrib.cluster_resolver.TPUClusterResolver(TPU_WORKER)\n",
        "tf.contrib.distribute.initialize_tpu_system(resolver)\n",
        "strategy = tf.contrib.distribute.TPUStrategy(resolver)\n",
        "\n",
        "with strategy.scope():\n",
        "  training_model = lstm_model(seq_len=100, stateful=False)\n",
        "  training_model.compile(\n",
        "      optimizer=tf.keras.optimizers.RMSprop(learning_rate=3e-4),\n",
        "      loss='sparse_categorical_crossentropy',\n",
        "      metrics=['sparse_categorical_accuracy'])\n",
        "\n",
        "training_model.fit(\n",
        "    input_fn(),\n",
        "    steps_per_epoch=100,\n",
        "    epochs=300\n",
        ")\n",
        "training_model.save_weights('/tmp/bard.h5', overwrite=True)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "WARNING:tensorflow:TPU system %s has already been initialized. Reinitializing the TPU can cause previously created variables on TPU to be lost.\n",
            "INFO:tensorflow:Initializing the TPU system: 10.113.235.42:8470\n",
            "INFO:tensorflow:Finished initializing TPU system.\n",
            "INFO:tensorflow:Querying Tensorflow master (grpc://10.113.235.42:8470) for TPU system metadata.\n",
            "INFO:tensorflow:Found TPU system:\n",
            "INFO:tensorflow:*** Num TPU Cores: 8\n",
            "INFO:tensorflow:*** Num TPU Workers: 1\n",
            "INFO:tensorflow:*** Num TPU Cores Per Worker: 8\n",
            "INFO:tensorflow:*** Available Device: _DeviceAttributes(/job:worker/replica:0/task:0/device:CPU:0, CPU, -1, 1767097598990659051)\n",
            "INFO:tensorflow:*** Available Device: _DeviceAttributes(/job:worker/replica:0/task:0/device:TPU:0, TPU, 17179869184, 17047413274731452232)\n",
            "INFO:tensorflow:*** Available Device: _DeviceAttributes(/job:worker/replica:0/task:0/device:TPU:1, TPU, 17179869184, 2306827021445831226)\n",
            "INFO:tensorflow:*** Available Device: _DeviceAttributes(/job:worker/replica:0/task:0/device:TPU:2, TPU, 17179869184, 16152545726597645409)\n",
            "INFO:tensorflow:*** Available Device: _DeviceAttributes(/job:worker/replica:0/task:0/device:TPU:3, TPU, 17179869184, 11221820495185113162)\n",
            "INFO:tensorflow:*** Available Device: _DeviceAttributes(/job:worker/replica:0/task:0/device:TPU:4, TPU, 17179869184, 8548594957040927414)\n",
            "INFO:tensorflow:*** Available Device: _DeviceAttributes(/job:worker/replica:0/task:0/device:TPU:5, TPU, 17179869184, 9422620835813108565)\n",
            "INFO:tensorflow:*** Available Device: _DeviceAttributes(/job:worker/replica:0/task:0/device:TPU:6, TPU, 17179869184, 7007849134292281756)\n",
            "INFO:tensorflow:*** Available Device: _DeviceAttributes(/job:worker/replica:0/task:0/device:TPU:7, TPU, 17179869184, 14815103462492593061)\n",
            "INFO:tensorflow:*** Available Device: _DeviceAttributes(/job:worker/replica:0/task:0/device:TPU_SYSTEM:0, TPU_SYSTEM, 8589934592, 9392334624897001482)\n",
            "INFO:tensorflow:*** Available Device: _DeviceAttributes(/job:worker/replica:0/task:0/device:XLA_CPU:0, XLA_CPU, 17179869184, 13044675269685245361)\n",
            "Epoch 1/300\n",
            "100/100 [==============================] - 20s 196ms/step - loss: 3.3439 - sparse_categorical_accuracy: 0.1540\n",
            "Epoch 2/300\n",
            "100/100 [==============================] - 15s 153ms/step - loss: 2.8489 - sparse_categorical_accuracy: 0.2292\n",
            "Epoch 3/300\n",
            "100/100 [==============================] - 15s 150ms/step - loss: 2.4121 - sparse_categorical_accuracy: 0.3302\n",
            "Epoch 4/300\n",
            "100/100 [==============================] - 16s 155ms/step - loss: 2.2286 - sparse_categorical_accuracy: 0.3720\n",
            "Epoch 5/300\n",
            "100/100 [==============================] - 15s 154ms/step - loss: 2.0847 - sparse_categorical_accuracy: 0.4086\n",
            "Epoch 6/300\n",
            "100/100 [==============================] - 16s 156ms/step - loss: 1.9506 - sparse_categorical_accuracy: 0.4398\n",
            "Epoch 7/300\n",
            "100/100 [==============================] - 16s 155ms/step - loss: 1.8357 - sparse_categorical_accuracy: 0.4705\n",
            "Epoch 8/300\n",
            "100/100 [==============================] - 16s 157ms/step - loss: 1.7349 - sparse_categorical_accuracy: 0.4948\n",
            "Epoch 9/300\n",
            "100/100 [==============================] - 16s 158ms/step - loss: 1.6447 - sparse_categorical_accuracy: 0.5192\n",
            "Epoch 10/300\n",
            "100/100 [==============================] - 15s 153ms/step - loss: 1.5660 - sparse_categorical_accuracy: 0.5410\n",
            "Epoch 11/300\n",
            "100/100 [==============================] - 15s 155ms/step - loss: 1.4986 - sparse_categorical_accuracy: 0.5591\n",
            "Epoch 12/300\n",
            "100/100 [==============================] - 16s 161ms/step - loss: 1.4410 - sparse_categorical_accuracy: 0.5749\n",
            "Epoch 13/300\n",
            "100/100 [==============================] - 16s 160ms/step - loss: 1.3919 - sparse_categorical_accuracy: 0.5880\n",
            "Epoch 14/300\n",
            "100/100 [==============================] - 16s 159ms/step - loss: 1.3494 - sparse_categorical_accuracy: 0.5988\n",
            "Epoch 15/300\n",
            "100/100 [==============================] - 16s 162ms/step - loss: 1.3122 - sparse_categorical_accuracy: 0.6082\n",
            "Epoch 16/300\n",
            "100/100 [==============================] - 16s 165ms/step - loss: 1.2804 - sparse_categorical_accuracy: 0.6163\n",
            "Epoch 17/300\n",
            "100/100 [==============================] - 16s 162ms/step - loss: 1.2509 - sparse_categorical_accuracy: 0.6239\n",
            "Epoch 18/300\n",
            "100/100 [==============================] - 17s 165ms/step - loss: 1.2244 - sparse_categorical_accuracy: 0.6306\n",
            "Epoch 19/300\n",
            "100/100 [==============================] - 16s 162ms/step - loss: 1.2017 - sparse_categorical_accuracy: 0.6364\n",
            "Epoch 20/300\n",
            "100/100 [==============================] - 17s 165ms/step - loss: 1.1801 - sparse_categorical_accuracy: 0.6420\n",
            "Epoch 21/300\n",
            "100/100 [==============================] - 16s 160ms/step - loss: 1.1606 - sparse_categorical_accuracy: 0.6471\n",
            "Epoch 22/300\n",
            "100/100 [==============================] - 16s 158ms/step - loss: 1.1429 - sparse_categorical_accuracy: 0.6515\n",
            "Epoch 23/300\n",
            "100/100 [==============================] - 17s 169ms/step - loss: 1.1260 - sparse_categorical_accuracy: 0.6560\n",
            "Epoch 24/300\n",
            "100/100 [==============================] - 17s 166ms/step - loss: 1.1104 - sparse_categorical_accuracy: 0.6600\n",
            "Epoch 25/300\n",
            "100/100 [==============================] - 17s 168ms/step - loss: 1.0953 - sparse_categorical_accuracy: 0.6638\n",
            "Epoch 26/300\n",
            "100/100 [==============================] - 17s 166ms/step - loss: 1.0815 - sparse_categorical_accuracy: 0.6675\n",
            "Epoch 27/300\n",
            "100/100 [==============================] - 17s 169ms/step - loss: 1.0680 - sparse_categorical_accuracy: 0.6711\n",
            "Epoch 28/300\n",
            "100/100 [==============================] - 17s 174ms/step - loss: 1.0547 - sparse_categorical_accuracy: 0.6747\n",
            "Epoch 29/300\n",
            "100/100 [==============================] - 17s 170ms/step - loss: 1.0422 - sparse_categorical_accuracy: 0.6781\n",
            "Epoch 30/300\n",
            "100/100 [==============================] - 17s 172ms/step - loss: 1.0303 - sparse_categorical_accuracy: 0.6813\n",
            "Epoch 31/300\n",
            "100/100 [==============================] - 17s 173ms/step - loss: 1.0177 - sparse_categorical_accuracy: 0.6848\n",
            "Epoch 32/300\n",
            "100/100 [==============================] - 16s 165ms/step - loss: 1.0065 - sparse_categorical_accuracy: 0.6879\n",
            "Epoch 33/300\n",
            "100/100 [==============================] - 17s 168ms/step - loss: 0.9950 - sparse_categorical_accuracy: 0.6911\n",
            "Epoch 34/300\n",
            "100/100 [==============================] - 18s 179ms/step - loss: 0.9839 - sparse_categorical_accuracy: 0.6944\n",
            "Epoch 35/300\n",
            "100/100 [==============================] - 18s 177ms/step - loss: 0.9726 - sparse_categorical_accuracy: 0.6975\n",
            "Epoch 36/300\n",
            "100/100 [==============================] - 18s 176ms/step - loss: 0.9615 - sparse_categorical_accuracy: 0.7007\n",
            "Epoch 37/300\n",
            "100/100 [==============================] - 18s 180ms/step - loss: 0.9507 - sparse_categorical_accuracy: 0.7039\n",
            "Epoch 38/300\n",
            "100/100 [==============================] - 18s 182ms/step - loss: 0.9402 - sparse_categorical_accuracy: 0.7070\n",
            "Epoch 39/300\n",
            "100/100 [==============================] - 18s 180ms/step - loss: 0.9293 - sparse_categorical_accuracy: 0.7103\n",
            "Epoch 40/300\n",
            "100/100 [==============================] - 18s 182ms/step - loss: 0.9186 - sparse_categorical_accuracy: 0.7135\n",
            "Epoch 41/300\n",
            "100/100 [==============================] - 18s 181ms/step - loss: 0.9082 - sparse_categorical_accuracy: 0.7166\n",
            "Epoch 42/300\n",
            "100/100 [==============================] - 18s 182ms/step - loss: 0.8976 - sparse_categorical_accuracy: 0.7198\n",
            "Epoch 43/300\n",
            "100/100 [==============================] - 18s 176ms/step - loss: 0.8871 - sparse_categorical_accuracy: 0.7230\n",
            "Epoch 44/300\n",
            "100/100 [==============================] - 18s 178ms/step - loss: 0.8769 - sparse_categorical_accuracy: 0.7262\n",
            "Epoch 45/300\n",
            "100/100 [==============================] - 18s 183ms/step - loss: 0.8664 - sparse_categorical_accuracy: 0.7294\n",
            "Epoch 46/300\n",
            "100/100 [==============================] - 18s 182ms/step - loss: 0.8560 - sparse_categorical_accuracy: 0.7326\n",
            "Epoch 47/300\n",
            "100/100 [==============================] - 18s 183ms/step - loss: 0.8459 - sparse_categorical_accuracy: 0.7358\n",
            "Epoch 48/300\n",
            "100/100 [==============================] - 18s 185ms/step - loss: 0.8353 - sparse_categorical_accuracy: 0.7391\n",
            "Epoch 49/300\n",
            "100/100 [==============================] - 18s 184ms/step - loss: 0.8250 - sparse_categorical_accuracy: 0.7424\n",
            "Epoch 50/300\n",
            "100/100 [==============================] - 19s 188ms/step - loss: 0.8150 - sparse_categorical_accuracy: 0.7455\n",
            "Epoch 51/300\n",
            "100/100 [==============================] - 19s 189ms/step - loss: 0.8045 - sparse_categorical_accuracy: 0.7489\n",
            "Epoch 52/300\n",
            "100/100 [==============================] - 19s 189ms/step - loss: 0.7942 - sparse_categorical_accuracy: 0.7521\n",
            "Epoch 53/300\n",
            "100/100 [==============================] - 19s 188ms/step - loss: 0.7839 - sparse_categorical_accuracy: 0.7553\n",
            "Epoch 54/300\n",
            "100/100 [==============================] - 18s 185ms/step - loss: 0.7738 - sparse_categorical_accuracy: 0.7586\n",
            "Epoch 55/300\n",
            "100/100 [==============================] - 19s 186ms/step - loss: 0.7636 - sparse_categorical_accuracy: 0.7618\n",
            "Epoch 56/300\n",
            "100/100 [==============================] - 19s 193ms/step - loss: 0.7534 - sparse_categorical_accuracy: 0.7650\n",
            "Epoch 57/300\n",
            "100/100 [==============================] - 19s 194ms/step - loss: 0.7431 - sparse_categorical_accuracy: 0.7685\n",
            "Epoch 58/300\n",
            "100/100 [==============================] - 19s 192ms/step - loss: 0.7329 - sparse_categorical_accuracy: 0.7718\n",
            "Epoch 59/300\n",
            "100/100 [==============================] - 19s 194ms/step - loss: 0.7234 - sparse_categorical_accuracy: 0.7747\n",
            "Epoch 60/300\n",
            "100/100 [==============================] - 20s 197ms/step - loss: 0.7128 - sparse_categorical_accuracy: 0.7784\n",
            "Epoch 61/300\n",
            "100/100 [==============================] - 19s 194ms/step - loss: 0.7027 - sparse_categorical_accuracy: 0.7815\n",
            "Epoch 62/300\n",
            "100/100 [==============================] - 19s 192ms/step - loss: 0.6926 - sparse_categorical_accuracy: 0.7848\n",
            "Epoch 63/300\n",
            "100/100 [==============================] - 19s 194ms/step - loss: 0.6830 - sparse_categorical_accuracy: 0.7881\n",
            "Epoch 64/300\n",
            "100/100 [==============================] - 20s 196ms/step - loss: 0.6726 - sparse_categorical_accuracy: 0.7914\n",
            "Epoch 65/300\n",
            "100/100 [==============================] - 19s 192ms/step - loss: 0.6630 - sparse_categorical_accuracy: 0.7946\n",
            "Epoch 66/300\n",
            "100/100 [==============================] - 19s 191ms/step - loss: 0.6531 - sparse_categorical_accuracy: 0.7980\n",
            "Epoch 67/300\n",
            "100/100 [==============================] - 19s 194ms/step - loss: 0.6433 - sparse_categorical_accuracy: 0.8012\n",
            "Epoch 68/300\n",
            "100/100 [==============================] - 20s 202ms/step - loss: 0.6334 - sparse_categorical_accuracy: 0.8043\n",
            "Epoch 69/300\n",
            "100/100 [==============================] - 20s 200ms/step - loss: 0.6239 - sparse_categorical_accuracy: 0.8076\n",
            "Epoch 70/300\n",
            "100/100 [==============================] - 20s 203ms/step - loss: 0.6144 - sparse_categorical_accuracy: 0.8107\n",
            "Epoch 71/300\n",
            "100/100 [==============================] - 20s 201ms/step - loss: 0.6047 - sparse_categorical_accuracy: 0.8140\n",
            "Epoch 72/300\n",
            "100/100 [==============================] - 20s 205ms/step - loss: 0.5948 - sparse_categorical_accuracy: 0.8173\n",
            "Epoch 73/300\n",
            "100/100 [==============================] - 20s 200ms/step - loss: 0.5860 - sparse_categorical_accuracy: 0.8202\n",
            "Epoch 74/300\n",
            "100/100 [==============================] - 20s 202ms/step - loss: 0.5761 - sparse_categorical_accuracy: 0.8235\n",
            "Epoch 75/300\n",
            "100/100 [==============================] - 20s 203ms/step - loss: 0.5672 - sparse_categorical_accuracy: 0.8266\n",
            "Epoch 76/300\n",
            "100/100 [==============================] - 20s 197ms/step - loss: 0.5578 - sparse_categorical_accuracy: 0.8297\n",
            "Epoch 77/300\n",
            "100/100 [==============================] - 20s 198ms/step - loss: 0.5486 - sparse_categorical_accuracy: 0.8328\n",
            "Epoch 78/300\n",
            "100/100 [==============================] - 21s 208ms/step - loss: 0.5394 - sparse_categorical_accuracy: 0.8360\n",
            "Epoch 79/300\n",
            "100/100 [==============================] - 21s 208ms/step - loss: 0.5303 - sparse_categorical_accuracy: 0.8389\n",
            "Epoch 80/300\n",
            "100/100 [==============================] - 21s 208ms/step - loss: 0.5216 - sparse_categorical_accuracy: 0.8419\n",
            "Epoch 81/300\n",
            "100/100 [==============================] - 21s 207ms/step - loss: 0.5127 - sparse_categorical_accuracy: 0.8448\n",
            "Epoch 82/300\n",
            "100/100 [==============================] - 20s 204ms/step - loss: 0.5038 - sparse_categorical_accuracy: 0.8479\n",
            "Epoch 83/300\n",
            "100/100 [==============================] - 21s 212ms/step - loss: 0.4945 - sparse_categorical_accuracy: 0.8512\n",
            "Epoch 84/300\n",
            "100/100 [==============================] - 21s 212ms/step - loss: 0.4866 - sparse_categorical_accuracy: 0.8537\n",
            "Epoch 85/300\n",
            "100/100 [==============================] - 21s 208ms/step - loss: 0.4778 - sparse_categorical_accuracy: 0.8568\n",
            "Epoch 86/300\n",
            "100/100 [==============================] - 21s 209ms/step - loss: 0.4695 - sparse_categorical_accuracy: 0.8594\n",
            "Epoch 87/300\n",
            "100/100 [==============================] - 21s 208ms/step - loss: 0.4608 - sparse_categorical_accuracy: 0.8625\n",
            "Epoch 88/300\n",
            "100/100 [==============================] - 21s 207ms/step - loss: 0.4526 - sparse_categorical_accuracy: 0.8651\n",
            "Epoch 89/300\n",
            "100/100 [==============================] - 21s 214ms/step - loss: 0.4444 - sparse_categorical_accuracy: 0.8679\n",
            "Epoch 90/300\n",
            "100/100 [==============================] - 21s 212ms/step - loss: 0.4360 - sparse_categorical_accuracy: 0.8709\n",
            "Epoch 91/300\n",
            "100/100 [==============================] - 21s 212ms/step - loss: 0.4282 - sparse_categorical_accuracy: 0.8735\n",
            "Epoch 92/300\n",
            "100/100 [==============================] - 21s 214ms/step - loss: 0.4202 - sparse_categorical_accuracy: 0.8762\n",
            "Epoch 93/300\n",
            "100/100 [==============================] - 21s 214ms/step - loss: 0.4127 - sparse_categorical_accuracy: 0.8788\n",
            "Epoch 94/300\n",
            "100/100 [==============================] - 21s 213ms/step - loss: 0.4044 - sparse_categorical_accuracy: 0.8817\n",
            "Epoch 95/300\n",
            "100/100 [==============================] - 22s 219ms/step - loss: 0.3968 - sparse_categorical_accuracy: 0.8842\n",
            "Epoch 96/300\n",
            "100/100 [==============================] - 21s 214ms/step - loss: 0.3895 - sparse_categorical_accuracy: 0.8865\n",
            "Epoch 97/300\n",
            "100/100 [==============================] - 22s 216ms/step - loss: 0.3824 - sparse_categorical_accuracy: 0.8891\n",
            "Epoch 98/300\n",
            "100/100 [==============================] - 21s 212ms/step - loss: 0.3742 - sparse_categorical_accuracy: 0.8919\n",
            "Epoch 99/300\n",
            "100/100 [==============================] - 22s 215ms/step - loss: 0.3673 - sparse_categorical_accuracy: 0.8941\n",
            "Epoch 100/300\n",
            "100/100 [==============================] - 22s 223ms/step - loss: 0.3603 - sparse_categorical_accuracy: 0.8967\n",
            "Epoch 101/300\n",
            "100/100 [==============================] - 22s 221ms/step - loss: 0.3531 - sparse_categorical_accuracy: 0.8990\n",
            "Epoch 102/300\n",
            "100/100 [==============================] - 22s 220ms/step - loss: 0.3458 - sparse_categorical_accuracy: 0.9016\n",
            "Epoch 103/300\n",
            "100/100 [==============================] - 22s 220ms/step - loss: 0.3392 - sparse_categorical_accuracy: 0.9037\n",
            "Epoch 104/300\n",
            "100/100 [==============================] - 22s 222ms/step - loss: 0.3325 - sparse_categorical_accuracy: 0.9059\n",
            "Epoch 105/300\n",
            "100/100 [==============================] - 22s 220ms/step - loss: 0.3256 - sparse_categorical_accuracy: 0.9084\n",
            "Epoch 106/300\n",
            "100/100 [==============================] - 22s 222ms/step - loss: 0.3198 - sparse_categorical_accuracy: 0.9103\n",
            "Epoch 107/300\n",
            "100/100 [==============================] - 22s 220ms/step - loss: 0.3125 - sparse_categorical_accuracy: 0.9129\n",
            "Epoch 108/300\n",
            "100/100 [==============================] - 22s 221ms/step - loss: 0.3063 - sparse_categorical_accuracy: 0.9149\n",
            "Epoch 109/300\n",
            "100/100 [==============================] - 22s 223ms/step - loss: 0.3006 - sparse_categorical_accuracy: 0.9169\n",
            "Epoch 110/300\n",
            "100/100 [==============================] - 22s 217ms/step - loss: 0.2943 - sparse_categorical_accuracy: 0.9189\n",
            "Epoch 111/300\n",
            "100/100 [==============================] - 22s 223ms/step - loss: 0.2883 - sparse_categorical_accuracy: 0.9211\n",
            "Epoch 112/300\n",
            "100/100 [==============================] - 22s 225ms/step - loss: 0.2820 - sparse_categorical_accuracy: 0.9231\n",
            "Epoch 113/300\n",
            "100/100 [==============================] - 23s 231ms/step - loss: 0.2764 - sparse_categorical_accuracy: 0.9250\n",
            "Epoch 114/300\n",
            "100/100 [==============================] - 23s 229ms/step - loss: 0.2707 - sparse_categorical_accuracy: 0.9268\n",
            "Epoch 115/300\n",
            "100/100 [==============================] - 23s 227ms/step - loss: 0.2654 - sparse_categorical_accuracy: 0.9285\n",
            "Epoch 116/300\n",
            "100/100 [==============================] - 23s 226ms/step - loss: 0.2598 - sparse_categorical_accuracy: 0.9305\n",
            "Epoch 117/300\n",
            "100/100 [==============================] - 23s 228ms/step - loss: 0.2543 - sparse_categorical_accuracy: 0.9323\n",
            "Epoch 118/300\n",
            "100/100 [==============================] - 23s 227ms/step - loss: 0.2493 - sparse_categorical_accuracy: 0.9339\n",
            "Epoch 119/300\n",
            "100/100 [==============================] - 23s 232ms/step - loss: 0.2437 - sparse_categorical_accuracy: 0.9358\n",
            "Epoch 120/300\n",
            "100/100 [==============================] - 22s 224ms/step - loss: 0.2389 - sparse_categorical_accuracy: 0.9373\n",
            "Epoch 121/300\n",
            "100/100 [==============================] - 23s 225ms/step - loss: 0.2340 - sparse_categorical_accuracy: 0.9389\n",
            "Epoch 122/300\n",
            "100/100 [==============================] - 24s 236ms/step - loss: 0.2294 - sparse_categorical_accuracy: 0.9404\n",
            "Epoch 123/300\n",
            "100/100 [==============================] - 23s 234ms/step - loss: 0.2242 - sparse_categorical_accuracy: 0.9422\n",
            "Epoch 124/300\n",
            "100/100 [==============================] - 23s 230ms/step - loss: 0.2196 - sparse_categorical_accuracy: 0.9435\n",
            "Epoch 125/300\n",
            "100/100 [==============================] - 23s 235ms/step - loss: 0.2149 - sparse_categorical_accuracy: 0.9450\n",
            "Epoch 126/300\n",
            "100/100 [==============================] - 23s 235ms/step - loss: 0.2111 - sparse_categorical_accuracy: 0.9460\n",
            "Epoch 127/300\n",
            "100/100 [==============================] - 24s 237ms/step - loss: 0.2066 - sparse_categorical_accuracy: 0.9475\n",
            "Epoch 128/300\n",
            "100/100 [==============================] - 24s 236ms/step - loss: 0.2024 - sparse_categorical_accuracy: 0.9489\n",
            "Epoch 129/300\n",
            "100/100 [==============================] - 24s 238ms/step - loss: 0.1986 - sparse_categorical_accuracy: 0.9499\n",
            "Epoch 130/300\n",
            "100/100 [==============================] - 24s 241ms/step - loss: 0.1931 - sparse_categorical_accuracy: 0.9518\n",
            "Epoch 131/300\n",
            "100/100 [==============================] - 23s 230ms/step - loss: 0.1912 - sparse_categorical_accuracy: 0.9519\n",
            "Epoch 132/300\n",
            "100/100 [==============================] - 24s 238ms/step - loss: 0.1863 - sparse_categorical_accuracy: 0.9535\n",
            "Epoch 133/300\n",
            "100/100 [==============================] - 24s 241ms/step - loss: 0.1837 - sparse_categorical_accuracy: 0.9542\n",
            "Epoch 134/300\n",
            "100/100 [==============================] - 24s 238ms/step - loss: 0.1797 - sparse_categorical_accuracy: 0.9550\n",
            "Epoch 135/300\n",
            "100/100 [==============================] - 24s 238ms/step - loss: 0.1751 - sparse_categorical_accuracy: 0.9563\n",
            "Epoch 136/300\n",
            "100/100 [==============================] - 24s 240ms/step - loss: 0.1726 - sparse_categorical_accuracy: 0.9565\n",
            "Epoch 137/300\n",
            "100/100 [==============================] - 24s 243ms/step - loss: 0.1691 - sparse_categorical_accuracy: 0.9574\n",
            "Epoch 138/300\n",
            "100/100 [==============================] - 24s 241ms/step - loss: 0.1659 - sparse_categorical_accuracy: 0.9588\n",
            "Epoch 139/300\n",
            "100/100 [==============================] - 25s 246ms/step - loss: 0.1625 - sparse_categorical_accuracy: 0.9588\n",
            "Epoch 140/300\n",
            "100/100 [==============================] - 24s 241ms/step - loss: 0.1584 - sparse_categorical_accuracy: 0.9602\n",
            "Epoch 141/300\n",
            "100/100 [==============================] - 24s 242ms/step - loss: 0.1597 - sparse_categorical_accuracy: 0.9588\n",
            "Epoch 142/300\n",
            "100/100 [==============================] - 24s 241ms/step - loss: 0.1529 - sparse_categorical_accuracy: 0.9609\n",
            "Epoch 143/300\n",
            "100/100 [==============================] - 24s 237ms/step - loss: 0.1519 - sparse_categorical_accuracy: 0.9610\n",
            "Epoch 144/300\n",
            "100/100 [==============================] - 25s 246ms/step - loss: 0.1524 - sparse_categorical_accuracy: 0.9600\n",
            "Epoch 145/300\n",
            "100/100 [==============================] - 25s 247ms/step - loss: 0.1473 - sparse_categorical_accuracy: 0.9620\n",
            "Epoch 146/300\n",
            "100/100 [==============================] - 24s 244ms/step - loss: 0.1411 - sparse_categorical_accuracy: 0.9636\n",
            "Epoch 147/300\n",
            "100/100 [==============================] - 25s 251ms/step - loss: 0.1437 - sparse_categorical_accuracy: 0.9621\n",
            "Epoch 148/300\n",
            "100/100 [==============================] - 25s 246ms/step - loss: 0.1429 - sparse_categorical_accuracy: 0.9622\n",
            "Epoch 149/300\n",
            "100/100 [==============================] - 25s 253ms/step - loss: 0.1371 - sparse_categorical_accuracy: 0.9637\n",
            "Epoch 150/300\n",
            "100/100 [==============================] - 25s 251ms/step - loss: 0.1385 - sparse_categorical_accuracy: 0.9630\n",
            "Epoch 151/300\n",
            "100/100 [==============================] - 25s 251ms/step - loss: 0.1336 - sparse_categorical_accuracy: 0.9642\n",
            "Epoch 152/300\n",
            "100/100 [==============================] - 25s 248ms/step - loss: 0.1319 - sparse_categorical_accuracy: 0.9644\n",
            "Epoch 153/300\n",
            "100/100 [==============================] - 24s 243ms/step - loss: 0.1306 - sparse_categorical_accuracy: 0.9645\n",
            "Epoch 154/300\n",
            "100/100 [==============================] - 24s 239ms/step - loss: 0.1316 - sparse_categorical_accuracy: 0.9641\n",
            "Epoch 155/300\n",
            "100/100 [==============================] - 25s 249ms/step - loss: 0.1279 - sparse_categorical_accuracy: 0.9650\n",
            "Epoch 156/300\n",
            "100/100 [==============================] - 25s 254ms/step - loss: 0.1275 - sparse_categorical_accuracy: 0.9647\n",
            "Epoch 157/300\n",
            "100/100 [==============================] - 25s 254ms/step - loss: 0.1278 - sparse_categorical_accuracy: 0.9644\n",
            "Epoch 158/300\n",
            "100/100 [==============================] - 25s 252ms/step - loss: 0.1261 - sparse_categorical_accuracy: 0.9648\n",
            "Epoch 159/300\n",
            "100/100 [==============================] - 25s 250ms/step - loss: 0.1185 - sparse_categorical_accuracy: 0.9670\n",
            "Epoch 160/300\n",
            "100/100 [==============================] - 26s 261ms/step - loss: 0.1241 - sparse_categorical_accuracy: 0.9648\n",
            "Epoch 161/300\n",
            "100/100 [==============================] - 26s 260ms/step - loss: 0.1173 - sparse_categorical_accuracy: 0.9670\n",
            "Epoch 162/300\n",
            "100/100 [==============================] - 26s 256ms/step - loss: 0.1239 - sparse_categorical_accuracy: 0.9646\n",
            "Epoch 163/300\n",
            "100/100 [==============================] - 25s 253ms/step - loss: 0.1156 - sparse_categorical_accuracy: 0.9671\n",
            "Epoch 164/300\n",
            "100/100 [==============================] - 25s 248ms/step - loss: 0.1153 - sparse_categorical_accuracy: 0.9671\n",
            "Epoch 165/300\n",
            "100/100 [==============================] - 25s 249ms/step - loss: 0.1206 - sparse_categorical_accuracy: 0.9652\n",
            "Epoch 166/300\n",
            "100/100 [==============================] - 25s 253ms/step - loss: 0.1144 - sparse_categorical_accuracy: 0.9669\n",
            "Epoch 167/300\n",
            "100/100 [==============================] - 26s 260ms/step - loss: 0.1133 - sparse_categorical_accuracy: 0.9672\n",
            "Epoch 168/300\n",
            "100/100 [==============================] - 26s 260ms/step - loss: 0.1132 - sparse_categorical_accuracy: 0.9671\n",
            "Epoch 169/300\n",
            "100/100 [==============================] - 25s 254ms/step - loss: 0.1120 - sparse_categorical_accuracy: 0.9671\n",
            "Epoch 170/300\n",
            "100/100 [==============================] - 26s 259ms/step - loss: 0.1122 - sparse_categorical_accuracy: 0.9671\n",
            "Epoch 171/300\n",
            "100/100 [==============================] - 26s 257ms/step - loss: 0.1105 - sparse_categorical_accuracy: 0.9673\n",
            "Epoch 172/300\n",
            "100/100 [==============================] - 26s 259ms/step - loss: 0.1105 - sparse_categorical_accuracy: 0.9674\n",
            "Epoch 173/300\n",
            "100/100 [==============================] - 26s 256ms/step - loss: 0.1106 - sparse_categorical_accuracy: 0.9670\n",
            "Epoch 174/300\n",
            "100/100 [==============================] - 26s 261ms/step - loss: 0.1104 - sparse_categorical_accuracy: 0.9671\n",
            "Epoch 175/300\n",
            "100/100 [==============================] - 26s 257ms/step - loss: 0.1021 - sparse_categorical_accuracy: 0.9696\n",
            "Epoch 176/300\n",
            "100/100 [==============================] - 26s 256ms/step - loss: 0.1096 - sparse_categorical_accuracy: 0.9671\n",
            "Epoch 177/300\n",
            "100/100 [==============================] - 26s 263ms/step - loss: 0.1096 - sparse_categorical_accuracy: 0.9670\n",
            "Epoch 178/300\n",
            "100/100 [==============================] - 27s 267ms/step - loss: 0.1021 - sparse_categorical_accuracy: 0.9692\n",
            "Epoch 179/300\n",
            "100/100 [==============================] - 27s 267ms/step - loss: 0.1089 - sparse_categorical_accuracy: 0.9667\n",
            "Epoch 180/300\n",
            "100/100 [==============================] - 27s 274ms/step - loss: 0.1006 - sparse_categorical_accuracy: 0.9694\n",
            "Epoch 181/300\n",
            "100/100 [==============================] - 26s 265ms/step - loss: 0.1081 - sparse_categorical_accuracy: 0.9672\n",
            "Epoch 182/300\n",
            "100/100 [==============================] - 27s 265ms/step - loss: 0.0995 - sparse_categorical_accuracy: 0.9695\n",
            "Epoch 183/300\n",
            "100/100 [==============================] - 27s 271ms/step - loss: 0.1076 - sparse_categorical_accuracy: 0.9670\n",
            "Epoch 184/300\n",
            "100/100 [==============================] - 26s 264ms/step - loss: 0.1001 - sparse_categorical_accuracy: 0.9694\n",
            "Epoch 185/300\n",
            "100/100 [==============================] - 26s 264ms/step - loss: 0.1065 - sparse_categorical_accuracy: 0.9671\n",
            "Epoch 186/300\n",
            "100/100 [==============================] - 26s 265ms/step - loss: 0.0987 - sparse_categorical_accuracy: 0.9697\n",
            "Epoch 187/300\n",
            "100/100 [==============================] - 26s 260ms/step - loss: 0.0989 - sparse_categorical_accuracy: 0.9692\n",
            "Epoch 188/300\n",
            "100/100 [==============================] - 27s 269ms/step - loss: 0.1046 - sparse_categorical_accuracy: 0.9680\n",
            "Epoch 189/300\n",
            "100/100 [==============================] - 28s 276ms/step - loss: 0.0986 - sparse_categorical_accuracy: 0.9694\n",
            "Epoch 190/300\n",
            "100/100 [==============================] - 27s 271ms/step - loss: 0.0980 - sparse_categorical_accuracy: 0.9693\n",
            "Epoch 191/300\n",
            "100/100 [==============================] - 27s 274ms/step - loss: 0.0974 - sparse_categorical_accuracy: 0.9696\n",
            "Epoch 192/300\n",
            "100/100 [==============================] - 27s 267ms/step - loss: 0.1061 - sparse_categorical_accuracy: 0.9670\n",
            "Epoch 193/300\n",
            "100/100 [==============================] - 27s 266ms/step - loss: 0.0968 - sparse_categorical_accuracy: 0.9699\n",
            "Epoch 194/300\n",
            "100/100 [==============================] - 27s 269ms/step - loss: 0.0975 - sparse_categorical_accuracy: 0.9694\n",
            "Epoch 195/300\n",
            "100/100 [==============================] - 28s 282ms/step - loss: 0.0963 - sparse_categorical_accuracy: 0.9699\n",
            "Epoch 196/300\n",
            "100/100 [==============================] - 28s 276ms/step - loss: 0.0965 - sparse_categorical_accuracy: 0.9697\n",
            "Epoch 197/300\n",
            "100/100 [==============================] - 27s 266ms/step - loss: 0.0971 - sparse_categorical_accuracy: 0.9695\n",
            "Epoch 198/300\n",
            "100/100 [==============================] - 26s 264ms/step - loss: 0.0964 - sparse_categorical_accuracy: 0.9693\n",
            "Epoch 199/300\n",
            "100/100 [==============================] - 28s 280ms/step - loss: 0.0973 - sparse_categorical_accuracy: 0.9693\n",
            "Epoch 200/300\n",
            "100/100 [==============================] - 28s 278ms/step - loss: 0.0968 - sparse_categorical_accuracy: 0.9693\n",
            "Epoch 201/300\n",
            "100/100 [==============================] - 28s 282ms/step - loss: 0.0962 - sparse_categorical_accuracy: 0.9695\n",
            "Epoch 202/300\n",
            "100/100 [==============================] - 28s 283ms/step - loss: 0.0967 - sparse_categorical_accuracy: 0.9697\n",
            "Epoch 203/300\n",
            "100/100 [==============================] - 28s 281ms/step - loss: 0.0966 - sparse_categorical_accuracy: 0.9693\n",
            "Epoch 204/300\n",
            "100/100 [==============================] - 28s 277ms/step - loss: 0.0950 - sparse_categorical_accuracy: 0.9696\n",
            "Epoch 205/300\n",
            "100/100 [==============================] - 28s 280ms/step - loss: 0.0950 - sparse_categorical_accuracy: 0.9699\n",
            "Epoch 206/300\n",
            "100/100 [==============================] - 28s 282ms/step - loss: 0.0955 - sparse_categorical_accuracy: 0.9695\n",
            "Epoch 207/300\n",
            "100/100 [==============================] - 28s 278ms/step - loss: 0.0898 - sparse_categorical_accuracy: 0.9711\n",
            "Epoch 208/300\n",
            "100/100 [==============================] - 27s 274ms/step - loss: 0.0917 - sparse_categorical_accuracy: 0.9702\n",
            "Epoch 209/300\n",
            "100/100 [==============================] - 28s 275ms/step - loss: 0.0950 - sparse_categorical_accuracy: 0.9695\n",
            "Epoch 210/300\n",
            "100/100 [==============================] - 29s 287ms/step - loss: 0.0943 - sparse_categorical_accuracy: 0.9696\n",
            "Epoch 211/300\n",
            "100/100 [==============================] - 28s 285ms/step - loss: 0.0943 - sparse_categorical_accuracy: 0.9696\n",
            "Epoch 212/300\n",
            "100/100 [==============================] - 29s 290ms/step - loss: 0.0922 - sparse_categorical_accuracy: 0.9702\n",
            "Epoch 213/300\n",
            "100/100 [==============================] - 29s 285ms/step - loss: 0.0889 - sparse_categorical_accuracy: 0.9711\n",
            "Epoch 214/300\n",
            "100/100 [==============================] - 28s 281ms/step - loss: 0.0933 - sparse_categorical_accuracy: 0.9699\n",
            "Epoch 215/300\n",
            "100/100 [==============================] - 28s 279ms/step - loss: 0.0942 - sparse_categorical_accuracy: 0.9698\n",
            "Epoch 216/300\n",
            "100/100 [==============================] - 29s 286ms/step - loss: 0.0864 - sparse_categorical_accuracy: 0.9718\n",
            "Epoch 217/300\n",
            "100/100 [==============================] - 29s 286ms/step - loss: 0.0939 - sparse_categorical_accuracy: 0.9695\n",
            "Epoch 218/300\n",
            "100/100 [==============================] - 28s 282ms/step - loss: 0.0946 - sparse_categorical_accuracy: 0.9694\n",
            "Epoch 219/300\n",
            "100/100 [==============================] - 28s 277ms/step - loss: 0.0860 - sparse_categorical_accuracy: 0.9718\n",
            "Epoch 220/300\n",
            "100/100 [==============================] - 28s 280ms/step - loss: 0.0942 - sparse_categorical_accuracy: 0.9696\n",
            "Epoch 221/300\n",
            "100/100 [==============================] - 29s 294ms/step - loss: 0.0936 - sparse_categorical_accuracy: 0.9696\n",
            "Epoch 222/300\n",
            "100/100 [==============================] - 29s 288ms/step - loss: 0.0858 - sparse_categorical_accuracy: 0.9720\n",
            "Epoch 223/300\n",
            "100/100 [==============================] - 28s 283ms/step - loss: 0.0935 - sparse_categorical_accuracy: 0.9695\n",
            "Epoch 224/300\n",
            "100/100 [==============================] - 29s 289ms/step - loss: 0.0929 - sparse_categorical_accuracy: 0.9697\n",
            "Epoch 225/300\n",
            "100/100 [==============================] - 29s 293ms/step - loss: 0.0852 - sparse_categorical_accuracy: 0.9721\n",
            "Epoch 226/300\n",
            "100/100 [==============================] - 29s 286ms/step - loss: 0.0932 - sparse_categorical_accuracy: 0.9699\n",
            "Epoch 227/300\n",
            "100/100 [==============================] - 29s 286ms/step - loss: 0.0852 - sparse_categorical_accuracy: 0.9720\n",
            "Epoch 228/300\n",
            "100/100 [==============================] - 30s 299ms/step - loss: 0.0923 - sparse_categorical_accuracy: 0.9699\n",
            "Epoch 229/300\n",
            "100/100 [==============================] - 29s 288ms/step - loss: 0.0918 - sparse_categorical_accuracy: 0.9700\n",
            "Epoch 230/300\n",
            "100/100 [==============================] - 28s 285ms/step - loss: 0.0848 - sparse_categorical_accuracy: 0.9720\n",
            "Epoch 231/300\n",
            "100/100 [==============================] - 29s 292ms/step - loss: 0.0928 - sparse_categorical_accuracy: 0.9697\n",
            "Epoch 232/300\n",
            "100/100 [==============================] - 29s 295ms/step - loss: 0.0847 - sparse_categorical_accuracy: 0.9719\n",
            "Epoch 233/300\n",
            "100/100 [==============================] - 30s 297ms/step - loss: 0.0918 - sparse_categorical_accuracy: 0.9700\n",
            "Epoch 234/300\n",
            "100/100 [==============================] - 30s 301ms/step - loss: 0.0842 - sparse_categorical_accuracy: 0.9721\n",
            "Epoch 235/300\n",
            "100/100 [==============================] - 29s 293ms/step - loss: 0.0928 - sparse_categorical_accuracy: 0.9697\n",
            "Epoch 236/300\n",
            "100/100 [==============================] - 29s 293ms/step - loss: 0.0840 - sparse_categorical_accuracy: 0.9721\n",
            "Epoch 237/300\n",
            "100/100 [==============================] - 29s 291ms/step - loss: 0.0914 - sparse_categorical_accuracy: 0.9701\n",
            "Epoch 238/300\n",
            "100/100 [==============================] - 29s 292ms/step - loss: 0.0843 - sparse_categorical_accuracy: 0.9720\n",
            "Epoch 239/300\n",
            "100/100 [==============================] - 29s 292ms/step - loss: 0.0842 - sparse_categorical_accuracy: 0.9719\n",
            "Epoch 240/300\n",
            "100/100 [==============================] - 31s 306ms/step - loss: 0.0916 - sparse_categorical_accuracy: 0.9700\n",
            "Epoch 241/300\n",
            "100/100 [==============================] - 30s 295ms/step - loss: 0.0891 - sparse_categorical_accuracy: 0.9710\n",
            "Epoch 242/300\n",
            "100/100 [==============================] - 30s 297ms/step - loss: 0.0858 - sparse_categorical_accuracy: 0.9714\n",
            "Epoch 243/300\n",
            "100/100 [==============================] - 30s 298ms/step - loss: 0.0840 - sparse_categorical_accuracy: 0.9720\n",
            "Epoch 244/300\n",
            "100/100 [==============================] - 30s 302ms/step - loss: 0.0914 - sparse_categorical_accuracy: 0.9698\n",
            "Epoch 245/300\n",
            "100/100 [==============================] - 30s 298ms/step - loss: 0.0831 - sparse_categorical_accuracy: 0.9723\n",
            "Epoch 246/300\n",
            "100/100 [==============================] - 31s 308ms/step - loss: 0.0913 - sparse_categorical_accuracy: 0.9701\n",
            "Epoch 247/300\n",
            "100/100 [==============================] - 30s 303ms/step - loss: 0.0841 - sparse_categorical_accuracy: 0.9720\n",
            "Epoch 248/300\n",
            "100/100 [==============================] - 31s 311ms/step - loss: 0.0832 - sparse_categorical_accuracy: 0.9721\n",
            "Epoch 249/300\n",
            "100/100 [==============================] - 30s 304ms/step - loss: 0.0909 - sparse_categorical_accuracy: 0.9700\n",
            "Epoch 250/300\n",
            "100/100 [==============================] - 31s 310ms/step - loss: 0.0834 - sparse_categorical_accuracy: 0.9722\n",
            "Epoch 251/300\n",
            "100/100 [==============================] - 31s 310ms/step - loss: 0.0840 - sparse_categorical_accuracy: 0.9719\n",
            "Epoch 252/300\n",
            "100/100 [==============================] - 30s 302ms/step - loss: 0.0911 - sparse_categorical_accuracy: 0.9699\n",
            "Epoch 253/300\n",
            "100/100 [==============================] - 31s 306ms/step - loss: 0.0841 - sparse_categorical_accuracy: 0.9719\n",
            "Epoch 254/300\n",
            "100/100 [==============================] - 32s 317ms/step - loss: 0.0830 - sparse_categorical_accuracy: 0.9721\n",
            "Epoch 255/300\n",
            "100/100 [==============================] - 31s 314ms/step - loss: 0.0835 - sparse_categorical_accuracy: 0.9720\n",
            "Epoch 256/300\n",
            "100/100 [==============================] - 31s 313ms/step - loss: 0.0907 - sparse_categorical_accuracy: 0.9700\n",
            "Epoch 257/300\n",
            "100/100 [==============================] - 31s 312ms/step - loss: 0.0832 - sparse_categorical_accuracy: 0.9721\n",
            "Epoch 258/300\n",
            "100/100 [==============================] - 31s 306ms/step - loss: 0.0835 - sparse_categorical_accuracy: 0.9719\n",
            "Epoch 259/300\n",
            "100/100 [==============================] - 32s 316ms/step - loss: 0.0900 - sparse_categorical_accuracy: 0.9703\n",
            "Epoch 260/300\n",
            "100/100 [==============================] - 31s 309ms/step - loss: 0.0825 - sparse_categorical_accuracy: 0.9721\n",
            "Epoch 261/300\n",
            "100/100 [==============================] - 31s 313ms/step - loss: 0.0819 - sparse_categorical_accuracy: 0.9723\n",
            "Epoch 262/300\n",
            "100/100 [==============================] - 32s 321ms/step - loss: 0.0831 - sparse_categorical_accuracy: 0.9719\n",
            "Epoch 263/300\n",
            "100/100 [==============================] - 31s 307ms/step - loss: 0.0907 - sparse_categorical_accuracy: 0.9699\n",
            "Epoch 264/300\n",
            "100/100 [==============================] - 30s 304ms/step - loss: 0.0824 - sparse_categorical_accuracy: 0.9722\n",
            "Epoch 265/300\n",
            "100/100 [==============================] - 31s 313ms/step - loss: 0.0830 - sparse_categorical_accuracy: 0.9723\n",
            "Epoch 266/300\n",
            "100/100 [==============================] - 32s 321ms/step - loss: 0.0826 - sparse_categorical_accuracy: 0.9721\n",
            "Epoch 267/300\n",
            "100/100 [==============================] - 32s 317ms/step - loss: 0.0892 - sparse_categorical_accuracy: 0.9703\n",
            "Epoch 268/300\n",
            "100/100 [==============================] - 32s 322ms/step - loss: 0.0832 - sparse_categorical_accuracy: 0.9722\n",
            "Epoch 269/300\n",
            "100/100 [==============================] - 33s 326ms/step - loss: 0.0821 - sparse_categorical_accuracy: 0.9722\n",
            "Epoch 270/300\n",
            "100/100 [==============================] - 32s 323ms/step - loss: 0.0824 - sparse_categorical_accuracy: 0.9722\n",
            "Epoch 271/300\n",
            "100/100 [==============================] - 33s 329ms/step - loss: 0.0828 - sparse_categorical_accuracy: 0.9722\n",
            "Epoch 272/300\n",
            "100/100 [==============================] - 32s 321ms/step - loss: 0.0830 - sparse_categorical_accuracy: 0.9721\n",
            "Epoch 273/300\n",
            "100/100 [==============================] - 32s 325ms/step - loss: 0.0898 - sparse_categorical_accuracy: 0.9700\n",
            "Epoch 274/300\n",
            "100/100 [==============================] - 31s 310ms/step - loss: 0.0828 - sparse_categorical_accuracy: 0.9721\n",
            "Epoch 275/300\n",
            "100/100 [==============================] - 32s 322ms/step - loss: 0.0827 - sparse_categorical_accuracy: 0.9721\n",
            "Epoch 276/300\n",
            "100/100 [==============================] - 32s 317ms/step - loss: 0.0828 - sparse_categorical_accuracy: 0.9720\n",
            "Epoch 277/300\n",
            "100/100 [==============================] - 31s 314ms/step - loss: 0.0828 - sparse_categorical_accuracy: 0.9722\n",
            "Epoch 278/300\n",
            "100/100 [==============================] - 32s 324ms/step - loss: 0.0816 - sparse_categorical_accuracy: 0.9725\n",
            "Epoch 279/300\n",
            "100/100 [==============================] - 32s 318ms/step - loss: 0.0819 - sparse_categorical_accuracy: 0.9724\n",
            "Epoch 280/300\n",
            "100/100 [==============================] - 33s 325ms/step - loss: 0.0825 - sparse_categorical_accuracy: 0.9720\n",
            "Epoch 281/300\n",
            "100/100 [==============================] - 32s 325ms/step - loss: 0.0899 - sparse_categorical_accuracy: 0.9700\n",
            "Epoch 282/300\n",
            "100/100 [==============================] - 33s 335ms/step - loss: 0.0823 - sparse_categorical_accuracy: 0.9723\n",
            "Epoch 283/300\n",
            "100/100 [==============================] - 33s 328ms/step - loss: 0.0829 - sparse_categorical_accuracy: 0.9720\n",
            "Epoch 284/300\n",
            "100/100 [==============================] - 32s 324ms/step - loss: 0.0820 - sparse_categorical_accuracy: 0.9720\n",
            "Epoch 285/300\n",
            "100/100 [==============================] - 31s 311ms/step - loss: 0.0818 - sparse_categorical_accuracy: 0.9722\n",
            "Epoch 286/300\n",
            "100/100 [==============================] - 31s 311ms/step - loss: 0.0821 - sparse_categorical_accuracy: 0.9720\n",
            "Epoch 287/300\n",
            "100/100 [==============================] - 32s 319ms/step - loss: 0.0821 - sparse_categorical_accuracy: 0.9721\n",
            "Epoch 288/300\n",
            "100/100 [==============================] - 33s 326ms/step - loss: 0.0816 - sparse_categorical_accuracy: 0.9723\n",
            "Epoch 289/300\n",
            "100/100 [==============================] - 33s 334ms/step - loss: 0.0815 - sparse_categorical_accuracy: 0.9722\n",
            "Epoch 290/300\n",
            "100/100 [==============================] - 33s 330ms/step - loss: 0.0818 - sparse_categorical_accuracy: 0.9722\n",
            "Epoch 291/300\n",
            "100/100 [==============================] - 32s 325ms/step - loss: 0.0817 - sparse_categorical_accuracy: 0.9721\n",
            "Epoch 292/300\n",
            "100/100 [==============================] - 32s 320ms/step - loss: 0.0813 - sparse_categorical_accuracy: 0.9723\n",
            "Epoch 293/300\n",
            "100/100 [==============================] - 32s 323ms/step - loss: 0.0805 - sparse_categorical_accuracy: 0.9725\n",
            "Epoch 294/300\n",
            "100/100 [==============================] - 32s 323ms/step - loss: 0.0816 - sparse_categorical_accuracy: 0.9724\n",
            "Epoch 295/300\n",
            "100/100 [==============================] - 32s 323ms/step - loss: 0.0815 - sparse_categorical_accuracy: 0.9723\n",
            "Epoch 296/300\n",
            "100/100 [==============================] - 32s 319ms/step - loss: 0.0819 - sparse_categorical_accuracy: 0.9723\n",
            "Epoch 297/300\n",
            "100/100 [==============================] - 32s 318ms/step - loss: 0.0820 - sparse_categorical_accuracy: 0.9721\n",
            "Epoch 298/300\n",
            "100/100 [==============================] - 33s 326ms/step - loss: 0.0812 - sparse_categorical_accuracy: 0.9723\n",
            "Epoch 299/300\n",
            "100/100 [==============================] - 33s 326ms/step - loss: 0.0813 - sparse_categorical_accuracy: 0.9724\n",
            "Epoch 300/300\n",
            "100/100 [==============================] - 33s 325ms/step - loss: 0.0819 - sparse_categorical_accuracy: 0.9724\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "TCBtcpZkykSf"
      },
      "source": [
        "### Make predictions with the model\n",
        "\n",
        "Use the trained model to make predictions and generate your own Shakespeare-esque play.\n",
        "Start the model off with a *seed* sentence, then generate 250 characters from it. The model makes five predictions from the initial seed.\n",
        "\n",
        "The predictions are done on the CPU so the batch size (5) in this case does not have to be divisible by 8.\n",
        "\n",
        "Note that when we are doing predictions or, to be more precise, text generation, we set `stateful=True` so that the model's state is kept between batches. If stateful is false, the model state is reset between each batch, and the model will only be able to use the information from the current batch (a single character) to make a prediction.\n",
        "\n",
        "The output of the model is a set of probabilities for the next character (given the input so far). To build a paragraph, we predict one character at a time and sample a character (based on the probabilities provided by the model). For example, if the input character is \"o\" and the output probabilities are \"p\" (0.65), \"t\" (0.30), others characters (0.05), then we allow our model to generate text other than just \"Ophelia\" and \"Othello.\""
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "tU7M-EGGxR3E",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 867
        },
        "outputId": "ec41eb27-72f7-4116-8612-750c6ccc52bf"
      },
      "source": [
        "BATCH_SIZE = 5\n",
        "PREDICT_LEN = 250\n",
        "\n",
        "# Keras requires the batch size be specified ahead of time for stateful models.\n",
        "# We use a sequence length of 1, as we will be feeding in one character at a \n",
        "# time and predicting the next character.\n",
        "prediction_model = lstm_model(seq_len=1, batch_size=BATCH_SIZE, stateful=True)\n",
        "prediction_model.load_weights('/tmp/bard.h5')\n",
        "\n",
        "# We seed the model with our initial string, copied BATCH_SIZE times\n",
        "\n",
        "seed_txt = 'How to live?'\n",
        "seed = transform(seed_txt)\n",
        "seed = np.repeat(np.expand_dims(seed, 0), BATCH_SIZE, axis=0)\n",
        "\n",
        "# First, run the seed forward to prime the state of the model.\n",
        "prediction_model.reset_states()\n",
        "for i in range(len(seed_txt) - 1):\n",
        "  prediction_model.predict(seed[:, i:i + 1])\n",
        "\n",
        "# Now we can accumulate predictions!\n",
        "predictions = [seed[:, -1:]]\n",
        "for i in range(PREDICT_LEN):\n",
        "  last_word = predictions[-1]\n",
        "  next_probits = prediction_model.predict(last_word)[:, 0, :]\n",
        "  \n",
        "  # sample from our output distribution\n",
        "  next_idx = [\n",
        "      np.random.choice(256, p=next_probits[i])\n",
        "      for i in range(BATCH_SIZE)\n",
        "  ]\n",
        "  predictions.append(np.asarray(next_idx, dtype=np.int32))\n",
        "  \n",
        "\n",
        "for i in range(BATCH_SIZE):\n",
        "  print('PREDICTION %d\\n\\n' % i)\n",
        "  p = [predictions[j][i] for j in range(PREDICT_LEN)]\n",
        "  generated = ''.join([chr(c) for c in p])  # Convert back to text\n",
        "  print(generated)\n",
        "  print()\n",
        "  assert len(generated) == PREDICT_LEN, 'Generated text too short'"
      ],
      "execution_count": 17,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "PREDICTION 0\n",
            "\n",
            "\n",
            "?\r\n",
            "\r\n",
            "THEAETETUS: Clear.\r\n",
            "\r\n",
            "SOCRATES: Well, and must not the soul, if any one who is not saying to question you, not by\r\n",
            "thought. And as far may cannot be inmeriously is only that he way that ever\r\n",
            "in the soul, are called birth with it difficulty, I w\n",
            "\n",
            "PREDICTION 1\n",
            "\n",
            "\n",
            "? Wholly use of them, Athenian, in what way the best of them\r\n",
            "are grieved by the love of some have been good or bad, and was anxiously\r\n",
            "of the soul, and according to the present, the\r\n",
            "set honder he has constructed a regular and systematicg which you \n",
            "\n",
            "PREDICTION 2\n",
            "\n",
            "\n",
            "? Where is the absancity of human answers, and of the\r\n",
            "subject will have a law corresponding him court, and one another, but after\r\n",
            "the region of which the deaderandluss of false opinion is of appearance.\r\n",
            "\r\n",
            "SO,  Comes, he said, indeed, replied Simmi\n",
            "\n",
            "PREDICTION 3\n",
            "\n",
            "\n",
            "? I see;\r\n",
            "nor they will sufficiently explain him when the words is the meaning of gold, should I not rejoice\r\n",
            "to discover the cause of its beneation, and far asking him\r\n",
            "to do again, and earnest of influctur and love with reason, and they\r\n",
            "are man fo\n",
            "\n",
            "PREDICTION 4\n",
            "\n",
            "\n",
            "? I will not give you a\r\n",
            "man, and not a very interestable.\r\n",
            "\r\n",
            "_Socr._ Then were remained yet have said nothing to care about the\r\n",
            "dead.\r\n",
            "\r\n",
            "By all means, assent, Meno: it were not wise and justice?\"\r\n",
            "\r\n",
            "\"See now, Socrates,\" he replied, I will tell you \n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    }
  ]
}