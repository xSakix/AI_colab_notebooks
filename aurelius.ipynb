{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "aurelius.ipynb",
      "provenance": [],
      "machine_shape": "hm",
      "authorship_tag": "ABX9TyMFCCmglqz+dz47/OMHbQQD",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/xSakix/AI_colab_notebooks/blob/master/aurelius.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Nzf9tl16PUku",
        "colab_type": "text"
      },
      "source": [
        "# Aurelius\n",
        "\n",
        "Trained on data from meditation of Marcus Aurelius from gutenberg.org.\n",
        "\n",
        "Finetuned GPT-2. \n",
        "\n",
        "## love(length=200)\n",
        "\n",
        "love,\n",
        "neither hath any of them been able unto it: so that either unto any\n",
        "that is worthy of it, or unto no man, no respect is\n",
        "entirely due.\n",
        "\n",
        "VI. If thou wilt never perchance die one of those things whereby death\n",
        "is an external present object, thou must also be one of those things where life\n",
        "is an external cessation.\n",
        "\n",
        "VII. Either thou dost not work all things in very short;\n",
        "either thou shalt wait upon some other thing: or, neither shalt thou succeed\n",
        "in the search of that which is in very short.\n",
        "\n",
        "VIII. Neither must thou try to avoid all things by means of my vainglory, as\n",
        "having those elements of the universe which I would have put off\n",
        "for ever, be confined unto myself, or should I put off\n",
        "for ever any further use? As for me, they both know and understand what is\n",
        "good for me, and!\n",
        "\n",
        "## Love (lenght=400)\n",
        "\n",
        "Love, and if thou shalt live, go\n",
        "altogether. For if this should happen unto thee, that thou didst not do it by\n",
        "meekness, then be sure that it will not, because not by thee,\n",
        "nor by meekness, nor by modesty: for if it do happen unto thee\n",
        "that by an act that thou didst committed, thou didst nevertheless commit\n",
        "the act without thy consent, either of grieve or grieve-\n",
        "or indignation: yea therefore must thou live if by an act that by thy\n",
        "natural constitution, thou didst continue to be subject to it. That thou didst commit\n",
        "that which was contrary to nature, is true of thee: but that\n",
        "which is contrary to nature, is false of thee. '\n",
        "\n",
        "XXVIII. He who looks down, cannot see that he didst wrong. For once he that is\n",
        "flattered with grief, is no longer able to discern whether he didst wrong,\n",
        "or not. For whosoever either goes about or doth thing is\n",
        "according to nature according to its own proper constitution, he doth not perceive\n",
        "whatsoever is contrary unto him. For though that he that is truly bereft of reason\n",
        "wants to be rid of him, yet that he that is carried about in a false apprehension of\n",
        "the nature of the universe, beholdeth the whole world as it were as a flower\n",
        "and leaves falling down, through all the elements of the world. Now we\n",
        "may therefore speak with calmness, and with reference to nature.\n",
        "\n",
        "XXIX. Remember that the cause of any thing is apparent to every one\n",
        "whose consideration is particularly to understand it; but that we should always be\n",
        "especially careful not to forget this, as a general rule. For it is\n",
        "entirely to be said of the cause itself, that those things which happen\n",
        "either according to its own proper constitution, or according to its!\n",
        "\n",
        "## What is the meaning of life?\n",
        "\n",
        "Whose happiness is that which is just and equanimious? Is it not in one of those things,\n",
        "which depend so much from reason and experience?\n",
        "\n",
        "II. **What is a reasonable creature? Certainly, it is that which is good. But\n",
        "certainly, it is that which is unjust and wicked.**\n",
        "\n",
        "III. How many sins have been committed? Four or more? How many deaths\n",
        "have been committed? How many great calamities?\n",
        "Consider then whatsoever thou art about: how many are the creatures of\n",
        "these things: the earth, the sun, the fire, the wind; how many are such as are\n",
        "ever before and after; so many that presently they all pass away\n",
        "and vanish away with the same speed and effusion.\n",
        "\n",
        "IV. Either it be void of life, or full of matter; and out of it come all\n",
        "things. And if it be full, which then is it that needs be purged\n",
        "and purged, and purged again, or purged by the general\n",
        "substance and form of all things, that so needs be purged? If it be void, and out of\n",
        "it come all other things. If so be that all things in all are\n",
        "divided and gone out of one into another, what will be the remainder of\n",
        "it? That which was before dissolved and all manner of confusion and\n",
        "corruptions, is now accounted whole, and all things and things of that\n",
        "future world.\n",
        "\n",
        "V. Of all the things in the world that are of a nature better or worse,\n",
        "that is of a nature neither better nor worse than anything else; so that\n",
        "the nature itself, by which every consideration is cast, will soon give over\n",
        "all the things of that world, and all the things which in the\n",
        "future are of another nature, together: so that there will soon be\n",
        "one place!\n",
        "\n",
        "## What does it mean to love?\n",
        "\n",
        "a. Whether from a fear of death or of being hurt, anything can be said or done by me,\n",
        "whether without natural affection, or through the strength of my will.\n",
        "\n",
        "b. From a longing to live long, in order that (being of sufficient duration) I may be\n",
        "compassed together and renewed, and able to live without pain.\n",
        "\n",
        "c. Not to write my letters complaining of any calamity, or even to wax violent,\n",
        "against such deities as they are: but to think, as it were, that my part and\n",
        "ability in this very matter, may be overruling my will and understanding.\n",
        "\n",
        "d. **To laugh at silly things that happen without any reason at all; and that in\n",
        "their true true natural state of chaos and holiness, and simplicity.**\n",
        "\n",
        "e. **To take refuge in the calmness and peace of mind, that all things may be\n",
        "proceeded from reason and truth.**\n",
        "\n",
        "f. To be ready to put anything to sleep, if any, as some things in general require.\n",
        "But if the body be cast into the fire, how can it escape\n",
        "whatsoever it is cast into, and by what possible recourse it can pass away? or\n",
        "is it dissolved? and that is the end of all natural conceit and imagination?\n",
        "\n",
        "g. To fear or mistrust God, or to fear anything that happens\n",
        "either out of anger or contempt, without any respect to reason.\n",
        "\n",
        "h. To be sensible of things destinated and pernicious, without any means, or\n",
        "by uncertain advice, or by opportunity. To fancy as ridiculous things that happen in\n",
        "the world, as things external, or by fortune wrought by men, or by either\n",
        "own appointment, or by custom and natural appointment, and by lawful\n",
        "action, whatsoever is according to nature. To mind many kinds of objects\n",
        "and to call them!\n",
        "\n",
        "## Does a multiverse exists?\n",
        "\n",
        "IN THE BOOK\n",
        "\n",
        "**I answer that thou canst find no such thing.** But if a universe (if the beginning be nothing but a composition of things already\n",
        "present in the world)\n",
        "presently doth in the future consist of both matter and soul, wherein are\n",
        "all the actions of the universe itself, (as of rain and fire and dust) that in the generation\n",
        "of these things proceed together all the motions, and all the changes and\n",
        "apparent occurrences of things according to their age and order.\n",
        "\n",
        "II. Whether or no, any such one can be. If a universe\n",
        "did consist of either atoms or substances, it would not in either\n",
        "particular suffice for the general good and sufficient subsistence of a\n",
        "multiverse. It is not by itself sufficient that either the law or nature\n",
        "of nature should bring about any such thing. For whatsoever in\n",
        "particular doth happen unto us, it must always be according to the\n",
        "true nature, and according to the common nature of the universe. But\n",
        "in all things that are incidental unto the general good and\n",
        "causes of the world, it is necessary that either the nature or the\n",
        "rational parts of the world should bear this up; or else the nature\n",
        "and the irrational parts of the world would bear it no better.\n",
        "\n",
        "III. As a vine needs water for its vines, so do a vine needs to be\n",
        "conditioned and cured by certain certain seasons. But he that saith: Water doth\n",
        "nothing better than feed and feed the earth. And therefore every one\n",
        "thyself (whatsoever doth happen unto him, whatsoever he saith) hath good reason to\n",
        "believe that whatsoever doth happen unto others doth (unto him) use it,\n",
        "and not so with him.\n",
        "\n",
        "IV. He that denies the nature and properties of things in general doth\n",
        "negatively and equivocally!\n",
        "\n",
        "## What should i do with life?\n",
        "\n",
        "XII. **Do to thyself some evil, that thou mayest die a happy death**, and not\n",
        "one happy death but one life: not that death doth teach thee anything,\n",
        "nor that it hath an effect upon thee, but that it pleaseth thee to be of\n",
        "good help and assistance in all things, that thou mayest continue always in this\n",
        "kind and correspondence, both unto thy fellows and unto thy children, that they\n",
        "mightest not, neither desire thee to die in any manner, as a mad man. Hast thou any\n",
        "good to do with life, but to consider of those things which by thy\n",
        "throat and breath are cast forth? What is thy true worth, and true worth not\n",
        "not to be blamed for? as that which by thy diet is repressed and\n",
        "caused; it is not worth the while to think how much more it\n",
        "is worth to die.\n",
        "\n",
        "XIII. Remember thy mind, and soul, and actions, as well as thy\n",
        "hunting and flying, and how little it hath thyself in common with\n",
        "the gods. If not that, tell thyself what it is that thou dost seek,\n",
        "and where thou shalt find it. Then do thyself that which hath been\n",
        "properly assigned unto thee.\n",
        "\n",
        "\n",
        "THE ELEVENTH BOOK\n",
        "\n",
        "I. **Spend thy time in the education of men.**\n",
        "\n",
        "II. See both things that happen unto thee, and things that are done unto\n",
        "them. To my understanding, all things that happen by nature are\n",
        "determined by that general declination of the elements, which follows\n",
        "through every action; so that every action by itself (whether it be a sin or a\n",
        "wicked action) was consummated in the common fire. But the\n",
        "world hath an end, which is to restrain every man from doing anything rashly\n",
        "that is impossible, or!\n",
        "\n",
        "\n",
        "## investment\n",
        "\n",
        "**investment, to look into things according to their true worth** and worth; and to pray concerning them, that it may not be\n",
        "difficult for them, who will not receive the charity of their priest,\n",
        "to teach their fellows, that they have not this worth and worth, neither that\n",
        "they have not the calling and dispensation of a true priest: that they may not be\n",
        "indifferent towards the Gods, whensoever they do commend and call upon them, but\n",
        "so to rejoice themselves upon such occasions. For what is it, that can make such\n",
        "profound and wonderful a thing, that so many men as thou hast heard and heard of it,\n",
        "would so much rejoice themselves upon? yea and how many of them\n",
        "must there be, that would joyfully call upon their Gods in their manifold\n",
        "tremors to do good unto their fellow men, as much as thou art those\n",
        "men.\n",
        "\n",
        "XXXV. So angry at Caius that he saith, 'My God, what is this, that thou art angry\n",
        "with me? that thou hast any dislike of him, that he purposed\n",
        "to give thee,' speak thou? Though thou art well pleased with the dissembling\n",
        "faculty of Antoninus Pius, or Diotimus, that he is no man to thy credit, yet thou\n",
        "wilt seem angry with him. Hath not the middle of his forehead been infected\n",
        "with some kind of nematode? Am I not very angry with him for that, that it did\n",
        "party with him, and put some bounty upon it, when he saith\n",
        "'My God, what art thou doing here?' yet thou hast no knowledge of any such thing;\n",
        "and if thou hast never heard of him, thou hast not much to do with him.\n",
        "\n",
        "XXXVI. Suppose a man, whom thou seest daily, make any wonder at it: would\n",
        "he not rather rejoice himself upon such things!\n",
        "\n",
        "## What is work?\n",
        "\n",
        "**It is labor.**\n",
        "\n",
        "XII. For every proper part of one's own nature, one art\n",
        "doth depend: for every particular part, its own proper operations. If\n",
        "a tree grow as naturally, as it were, by the wind and fire from morning to\n",
        "after, and so forth by the heat of the sun from morning till evening, so\n",
        "of course also a reasonable part of herself must also depend, and from\n",
        "the relation of her to nature must likewise depend. If so\n",
        "then the part that is naturally benefited by its own proper\n",
        "operation, is the part that is benefited by nature's general welfare. **As for\n",
        "that which is contrary to nature, yea (all things in general) neither\n",
        "can be said to be against nature, but only against reason itself.**\n",
        "\n",
        "XIII. Do not think that through the error and ignorance which is\n",
        "through in all things the rational part, but through her own reasonable\n",
        "operation, be granted, that things as they are, may in some sense be\n",
        "happened unto us nevertheless; and those things by which we are led\n",
        "and led to believe that things which are contrary are\n",
        "true and popular, and that these things indeed are things contrary unto\n",
        "God, and as true and popular, as for example, (which is\n",
        "well unto thee) a vine she seems not to blush for, but puffed up and supped up\n",
        "with them (which is neither good nor bad? because\n",
        "otherwise it would be contrary): so may it be, that what is commonly called\n",
        "\"reasonable work\" or work, is the only thing which properly\n",
        "represents man as living and natural. For so must anything that is\n",
        "within reasonable bounds be, if all reasonable things be equally.\n",
        "\n",
        "XIV. **What is the true virtue, and the true use of rhetoric?\n",
        "To understand what reason is for any one to do**, let us consider!\n",
        "\n",
        "## Should one prefer family or work?\n",
        "\n",
        "How many blessings do\n",
        "most men own themselves, who so often depart from the true natural\n",
        "nature of the universe? Let no man by way of question or\n",
        "comment wonder at any of them. **For it will be hard for any man to understand\n",
        "why he ought not to live in a state of perpetual longing and\n",
        "inability to obtain any such happiness.** For by this perpetual striving, we are neither\n",
        "lived in perpetual servitude, nor in perpetual motion.\n",
        "\n",
        "XXXVI. From one beginning to another, a man's life depends not only\n",
        "on the order of his own constitution, but also upon some external\n",
        "reason. One must expect more or less from our constitution, depending\n",
        "only from the duration of our lives. **The first cause of this, is, that\n",
        "our souls are not accustomed to anything that is sudden and sudden:\n",
        "the body's continual change and alteration.** When even the smallest\n",
        "part of our soul is dissolved into nothing, the whole\n",
        "body cannot be easily preserved. Secondly, we must fear death, for it is\n",
        "certainly in thy power to make us lose our strength, and this strength\n",
        "being continually seized up by new injuries and pleasures, and no longer able to\n",
        "keep itself contained, thou must at every instant mind and expect\n",
        "more or less of thy body, as tending to that which is truly life-giving and\n",
        "possible, if thou shalt live a gentle and constant course. Thirdly,\n",
        "that this life is a perpetual bounty: that as soon as any thing doth\n",
        "exceed, thou thyself, being deemed no worse off, than that which\n",
        "had been before. Fourthly, that neither false modesty, nor ostentation\n",
        "and vainglory, nor ostentation of honour, or favours, or presents,\n",
        "nor modesty, or a readiness to speak freely of those things which are\n",
        "properly and truly among us!\n",
        "\n",
        "## How to build attention?\n",
        "\n",
        "It is somewhat natural, that in this manner the mind should do good unto herself, and to herself the most. For nothing more can be expected from a rational and vegetative nature than the\n",
        "supposed care and use of her body, as well as her own faculties and actions.\n",
        "\n",
        "XXVIII. To think, to speak; to live; to live as it were in a neat rosette; a wrestler's\n",
        "envy, or a pusillanimous wrestler's wrestler's wrestler's wrestler's wrestler's wrestler's wrestler's wrestler's\n",
        "whole life, is a mere and ridiculous error. Those words which thou must needs\n",
        "read withal, remember, that it will not please the body that doth speak but\n",
        "thou alone, and that all else that doth do, either shall within a few\n",
        "minutes or an hour else speak unto thee. But if thy body is apt to\n",
        "dissemble and excrete itself, with aye, that most proper part of it which\n",
        "soever it be, or whatsoever is furnished unto it by nature,\n",
        "can no more use to live that sort of life than that which she herself\n",
        "hath, and by her kind disposition doth herself desire. For it is not fitting that\n",
        "it should be thought necessary that any man should live either kind of life\n",
        "without fear of death or great affliction, but according to nature, which\n",
        "thou shalt desire. What then dost thou desire, if thou shalt use to live according to\n",
        "nature?\n",
        "\n",
        "XXIX. What do the senses and the senses of the body\n",
        "content themselves with? what use should they make upon thee of all things? or of\n",
        "everything to which thou oughtest to credit them? or of everything to which\n",
        "they apply themselves?\n",
        "\n",
        "XXV. This, must not any unreasonable part of thee either choose either this life or\n",
        "that, (whether truly!\n",
        "\n",
        "\n",
        "## Intelligence\n",
        "\n",
        "The ruler's\n",
        "own reason, either of himself or of others; that to set\n",
        "against him, and by reason of his own incapacity. If\n",
        "then only I did it, or if I thought the general best interest of the\n",
        "commonwealth, let me not trouble myself for it. For neither are\n",
        "I now inclined towards any particular rational being. And as it were, if I did\n",
        "throw myself unto the public for help, let not I, neither fall prey unto it.\n",
        "\n",
        "XXV. Whatsoever it is that pleases me, I do it, as the general\n",
        "best interest of the commonwealth. As for reason, that also that can\n",
        "agree with me, and helps me if need be, I am content.\n",
        "\n",
        "XXVI. How wretched dost thou think that the gods have made some things\n",
        "for thee? Thou art so stupid, that even they themselves\n",
        "wipe thee out of thy sight. And whosoever shall oppose thee, if he shall\n",
        "presently cast himself, as it were, upon either a marble, or a cross,\n",
        "as a mere sort of sacrificial couch, thou shalt either be cast down, or be grieved\n",
        "and offended. Why then shouldst thou think anything so strange, and\n",
        "shameful? If for any worldly object, the gods should require it, thou\n",
        "wilt be sorry for it.\n",
        "\n",
        "XXVII. Neither dogmata, nor dogmata, nor superstitions, nor superstitions, nor\n",
        "universaries, nor immortal souls, doth deter us from action, from\n",
        "passion. Moreover, everything either takes place according to reason, or\n",
        "preserves its place according to reference to truth, or according to\n",
        "order: and it is not against reason itself, that we offend, that we should\n",
        "be displeased. For what then is it that thou dost take care for? To put\n",
        "!\n",
        "\n",
        "#What is good?\n",
        "\n",
        "XII. Do the things that are according to nature happen unto thee according to the natural\n",
        "nature? and in what manner will they be benefited?\n",
        "\n",
        "XIII. How many are the ordinary persons, thou wilt find out, who are\n",
        "them that offend against reason; and who in their wicked imaginations\n",
        "incline themselves to reason and reason alone; and maintain that\n",
        "their opinions are idle and false?\n",
        "\n",
        "XIV. Nothing is more unrighteous than falsehood; for so will all those\n",
        "other things that were instituted for the good of the world,\n",
        "if they be subject to perpetual alteration and alteration. As for\n",
        "that which is good: it is of itself a thing that is evil, because it is\n",
        "unjust and ungracious. For what is worse, that which is good, that is\n",
        "contrary to reason? then thou wilt find out, who are them\n",
        "that offend against reason. Do thou therefore find\n",
        "out, who they that are both good and bad? what then is\n",
        "there that they are guilty of, besides their wicked\n",
        "rational opinions?\n",
        "\n",
        "XV. Not without reason and discretion shall these things happen unto thee.\n",
        "\n",
        "XVI. Can any soul be hurt in the course or performance of any\n",
        "thing? But would not that damage any worldly object, and thus avoid\n",
        "the danger of what? But of these objects by way of admonition\n",
        "such actions may be avoided: for as for them, they cannot by any\n",
        "reason operate against reason.\n",
        "\n",
        "XVII. Consider how many the ordinary persons, thou wilt find\n",
        "out, who have been unjustly prosecuted by thy physician; and who in their\n",
        "pleasure and indignation prosecute thee again, but without any further\n",
        "excrements.\n",
        "\n",
        "XVIII. Whatsoever doth happen unto any, hath taken it upon itself to be\n",
        "present at the same time. Consider how many"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "HfTQpaU3Ewo2",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "outputId": "b454bbf9-eeda-462d-c487-f4d1861cbda7"
      },
      "source": [
        "!git clone https://github.com/huggingface/transformers\n",
        "!pip install transformers\n",
        "!pip install -r transformers/examples/requirements.txt"
      ],
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Cloning into 'transformers'...\n",
            "remote: Enumerating objects: 20089, done.\u001b[K\n",
            "remote: Total 20089 (delta 0), reused 0 (delta 0), pack-reused 20089\u001b[K\n",
            "Receiving objects: 100% (20089/20089), 11.63 MiB | 24.90 MiB/s, done.\n",
            "Resolving deltas: 100% (14679/14679), done.\n",
            "Collecting transformers\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/ee/fc/bd726a15ab2c66dc09306689d04da07a3770dad724f0883f0a4bfb745087/transformers-2.4.1-py3-none-any.whl (475kB)\n",
            "\u001b[K     |████████████████████████████████| 481kB 3.5MB/s \n",
            "\u001b[?25hRequirement already satisfied: tqdm>=4.27 in /usr/local/lib/python3.6/dist-packages (from transformers) (4.28.1)\n",
            "Requirement already satisfied: regex!=2019.12.17 in /usr/local/lib/python3.6/dist-packages (from transformers) (2019.12.20)\n",
            "Collecting sentencepiece\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/74/f4/2d5214cbf13d06e7cb2c20d84115ca25b53ea76fa1f0ade0e3c9749de214/sentencepiece-0.1.85-cp36-cp36m-manylinux1_x86_64.whl (1.0MB)\n",
            "\u001b[K     |████████████████████████████████| 1.0MB 47.0MB/s \n",
            "\u001b[?25hRequirement already satisfied: boto3 in /usr/local/lib/python3.6/dist-packages (from transformers) (1.11.15)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.6/dist-packages (from transformers) (1.17.5)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.6/dist-packages (from transformers) (2.21.0)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.6/dist-packages (from transformers) (3.0.12)\n",
            "Collecting sacremoses\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/a6/b4/7a41d630547a4afd58143597d5a49e07bfd4c42914d8335b2a5657efc14b/sacremoses-0.0.38.tar.gz (860kB)\n",
            "\u001b[K     |████████████████████████████████| 870kB 38.1MB/s \n",
            "\u001b[?25hCollecting tokenizers==0.0.11\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/5e/36/7af38d572c935f8e0462ec7b4f7a46d73a2b3b1a938f50a5e8132d5b2dc5/tokenizers-0.0.11-cp36-cp36m-manylinux1_x86_64.whl (3.1MB)\n",
            "\u001b[K     |████████████████████████████████| 3.1MB 34.5MB/s \n",
            "\u001b[?25hRequirement already satisfied: botocore<1.15.0,>=1.14.15 in /usr/local/lib/python3.6/dist-packages (from boto3->transformers) (1.14.15)\n",
            "Requirement already satisfied: jmespath<1.0.0,>=0.7.1 in /usr/local/lib/python3.6/dist-packages (from boto3->transformers) (0.9.4)\n",
            "Requirement already satisfied: s3transfer<0.4.0,>=0.3.0 in /usr/local/lib/python3.6/dist-packages (from boto3->transformers) (0.3.3)\n",
            "Requirement already satisfied: idna<2.9,>=2.5 in /usr/local/lib/python3.6/dist-packages (from requests->transformers) (2.8)\n",
            "Requirement already satisfied: urllib3<1.25,>=1.21.1 in /usr/local/lib/python3.6/dist-packages (from requests->transformers) (1.24.3)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.6/dist-packages (from requests->transformers) (2019.11.28)\n",
            "Requirement already satisfied: chardet<3.1.0,>=3.0.2 in /usr/local/lib/python3.6/dist-packages (from requests->transformers) (3.0.4)\n",
            "Requirement already satisfied: six in /usr/local/lib/python3.6/dist-packages (from sacremoses->transformers) (1.12.0)\n",
            "Requirement already satisfied: click in /usr/local/lib/python3.6/dist-packages (from sacremoses->transformers) (7.0)\n",
            "Requirement already satisfied: joblib in /usr/local/lib/python3.6/dist-packages (from sacremoses->transformers) (0.14.1)\n",
            "Requirement already satisfied: python-dateutil<3.0.0,>=2.1 in /usr/local/lib/python3.6/dist-packages (from botocore<1.15.0,>=1.14.15->boto3->transformers) (2.6.1)\n",
            "Requirement already satisfied: docutils<0.16,>=0.10 in /usr/local/lib/python3.6/dist-packages (from botocore<1.15.0,>=1.14.15->boto3->transformers) (0.15.2)\n",
            "Building wheels for collected packages: sacremoses\n",
            "  Building wheel for sacremoses (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for sacremoses: filename=sacremoses-0.0.38-cp36-none-any.whl size=884628 sha256=ff4b52224a731031a6b04786f7a7fd9cc5ea18fb5302809a56d7d716dc8d3fe4\n",
            "  Stored in directory: /root/.cache/pip/wheels/6d/ec/1a/21b8912e35e02741306f35f66c785f3afe94de754a0eaf1422\n",
            "Successfully built sacremoses\n",
            "Installing collected packages: sentencepiece, sacremoses, tokenizers, transformers\n",
            "Successfully installed sacremoses-0.0.38 sentencepiece-0.1.85 tokenizers-0.0.11 transformers-2.4.1\n",
            "Collecting tensorboardX\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/35/f1/5843425495765c8c2dd0784a851a93ef204d314fc87bcc2bbb9f662a3ad1/tensorboardX-2.0-py2.py3-none-any.whl (195kB)\n",
            "\u001b[K     |████████████████████████████████| 204kB 3.5MB/s \n",
            "\u001b[?25hRequirement already satisfied: tensorboard in /usr/local/lib/python3.6/dist-packages (from -r transformers/examples/requirements.txt (line 2)) (1.15.0)\n",
            "Requirement already satisfied: scikit-learn in /usr/local/lib/python3.6/dist-packages (from -r transformers/examples/requirements.txt (line 3)) (0.22.1)\n",
            "Collecting seqeval\n",
            "  Downloading https://files.pythonhosted.org/packages/34/91/068aca8d60ce56dd9ba4506850e876aba5e66a6f2f29aa223224b50df0de/seqeval-0.0.12.tar.gz\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.6/dist-packages (from tensorboardX->-r transformers/examples/requirements.txt (line 1)) (1.17.5)\n",
            "Requirement already satisfied: protobuf>=3.8.0 in /usr/local/lib/python3.6/dist-packages (from tensorboardX->-r transformers/examples/requirements.txt (line 1)) (3.10.0)\n",
            "Requirement already satisfied: six in /usr/local/lib/python3.6/dist-packages (from tensorboardX->-r transformers/examples/requirements.txt (line 1)) (1.12.0)\n",
            "Requirement already satisfied: absl-py>=0.4 in /usr/local/lib/python3.6/dist-packages (from tensorboard->-r transformers/examples/requirements.txt (line 2)) (0.9.0)\n",
            "Requirement already satisfied: grpcio>=1.6.3 in /usr/local/lib/python3.6/dist-packages (from tensorboard->-r transformers/examples/requirements.txt (line 2)) (1.27.1)\n",
            "Requirement already satisfied: markdown>=2.6.8 in /usr/local/lib/python3.6/dist-packages (from tensorboard->-r transformers/examples/requirements.txt (line 2)) (3.2.1)\n",
            "Requirement already satisfied: setuptools>=41.0.0 in /usr/local/lib/python3.6/dist-packages (from tensorboard->-r transformers/examples/requirements.txt (line 2)) (45.1.0)\n",
            "Requirement already satisfied: wheel>=0.26; python_version >= \"3\" in /usr/local/lib/python3.6/dist-packages (from tensorboard->-r transformers/examples/requirements.txt (line 2)) (0.34.2)\n",
            "Requirement already satisfied: werkzeug>=0.11.15 in /usr/local/lib/python3.6/dist-packages (from tensorboard->-r transformers/examples/requirements.txt (line 2)) (1.0.0)\n",
            "Requirement already satisfied: joblib>=0.11 in /usr/local/lib/python3.6/dist-packages (from scikit-learn->-r transformers/examples/requirements.txt (line 3)) (0.14.1)\n",
            "Requirement already satisfied: scipy>=0.17.0 in /usr/local/lib/python3.6/dist-packages (from scikit-learn->-r transformers/examples/requirements.txt (line 3)) (1.4.1)\n",
            "Requirement already satisfied: Keras>=2.2.4 in /usr/local/lib/python3.6/dist-packages (from seqeval->-r transformers/examples/requirements.txt (line 4)) (2.2.5)\n",
            "Requirement already satisfied: h5py in /usr/local/lib/python3.6/dist-packages (from Keras>=2.2.4->seqeval->-r transformers/examples/requirements.txt (line 4)) (2.8.0)\n",
            "Requirement already satisfied: keras-preprocessing>=1.1.0 in /usr/local/lib/python3.6/dist-packages (from Keras>=2.2.4->seqeval->-r transformers/examples/requirements.txt (line 4)) (1.1.0)\n",
            "Requirement already satisfied: keras-applications>=1.0.8 in /usr/local/lib/python3.6/dist-packages (from Keras>=2.2.4->seqeval->-r transformers/examples/requirements.txt (line 4)) (1.0.8)\n",
            "Requirement already satisfied: pyyaml in /usr/local/lib/python3.6/dist-packages (from Keras>=2.2.4->seqeval->-r transformers/examples/requirements.txt (line 4)) (3.13)\n",
            "Building wheels for collected packages: seqeval\n",
            "  Building wheel for seqeval (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for seqeval: filename=seqeval-0.0.12-cp36-none-any.whl size=7424 sha256=72ddcbec70f71f7229e708d96e3c4984dd523bb5ac59ee6a3f111a89ccae600a\n",
            "  Stored in directory: /root/.cache/pip/wheels/4f/32/0a/df3b340a82583566975377d65e724895b3fad101a3fb729f68\n",
            "Successfully built seqeval\n",
            "Installing collected packages: tensorboardX, seqeval\n",
            "Successfully installed seqeval-0.0.12 tensorboardX-2.0\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "gwued9UYE3FB",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 122
        },
        "outputId": "ee77a435-f5a7-4e94-e730-f798cdbd799c"
      },
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Go to this URL in a browser: https://accounts.google.com/o/oauth2/auth?client_id=947318989803-6bn6qk8qdgf4n4g3pfee6491hc0brc4i.apps.googleusercontent.com&redirect_uri=urn%3aietf%3awg%3aoauth%3a2.0%3aoob&response_type=code&scope=email%20https%3a%2f%2fwww.googleapis.com%2fauth%2fdocs.test%20https%3a%2f%2fwww.googleapis.com%2fauth%2fdrive%20https%3a%2f%2fwww.googleapis.com%2fauth%2fdrive.photos.readonly%20https%3a%2f%2fwww.googleapis.com%2fauth%2fpeopleapi.readonly\n",
            "\n",
            "Enter your authorization code:\n",
            "··········\n",
            "Mounted at /content/drive\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "SzPUHJA9E5t1",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#check files\n",
        "import os\n",
        "\n",
        "dirs=['/content/drive/My Drive/aurelius/output']\n",
        "files=['/content/drive/My Drive/aurelius/aurelius.txt']\n",
        "for f in dirs:\n",
        "  if not os.path.isdir(f):\n",
        "    print(f'{f} not found')\n",
        "\n",
        "for f in files:\n",
        "  if not os.path.isfile(f):\n",
        "    print(f'{f} not found')"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "WzXlE4HlFDIo",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "outputId": "2a0d962b-c796-4d0a-8490-ecd79966f44a"
      },
      "source": [
        "!python transformers/examples/run_language_modeling.py --output_dir='/content/drive/My Drive/aurelius/output' --model_type=gpt2 --model_name_or_path='/content/drive/My Drive/aurelius/output' --do_train --train_data_file='/content/drive/My Drive/aurelius/aurelius.txt' --do_eval --eval_data_file='/content/drive/My Drive/aurelius/aurelius.txt' --no_cuda --num_train_epochs 10 --overwrite_output_dir"
      ],
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "02/18/2020 17:48:51 - WARNING - __main__ -   Process rank: -1, device: cpu, n_gpu: 0, distributed training: False, 16-bits training: False\n",
            "02/18/2020 17:48:51 - INFO - transformers.configuration_utils -   loading configuration file /content/drive/My Drive/aurelius/output/config.json\n",
            "02/18/2020 17:48:51 - INFO - transformers.configuration_utils -   Model config GPT2Config {\n",
            "  \"architectures\": [\n",
            "    \"GPT2LMHeadModel\"\n",
            "  ],\n",
            "  \"attn_pdrop\": 0.1,\n",
            "  \"bos_token_id\": 0,\n",
            "  \"do_sample\": false,\n",
            "  \"embd_pdrop\": 0.1,\n",
            "  \"eos_token_ids\": 0,\n",
            "  \"finetuning_task\": null,\n",
            "  \"id2label\": {\n",
            "    \"0\": \"LABEL_0\",\n",
            "    \"1\": \"LABEL_1\"\n",
            "  },\n",
            "  \"initializer_range\": 0.02,\n",
            "  \"is_decoder\": false,\n",
            "  \"label2id\": {\n",
            "    \"LABEL_0\": 0,\n",
            "    \"LABEL_1\": 1\n",
            "  },\n",
            "  \"layer_norm_epsilon\": 1e-05,\n",
            "  \"length_penalty\": 1.0,\n",
            "  \"max_length\": 20,\n",
            "  \"model_type\": \"gpt2\",\n",
            "  \"n_ctx\": 1024,\n",
            "  \"n_embd\": 768,\n",
            "  \"n_head\": 12,\n",
            "  \"n_layer\": 12,\n",
            "  \"n_positions\": 1024,\n",
            "  \"num_beams\": 1,\n",
            "  \"num_labels\": 2,\n",
            "  \"num_return_sequences\": 1,\n",
            "  \"output_attentions\": false,\n",
            "  \"output_hidden_states\": false,\n",
            "  \"output_past\": true,\n",
            "  \"pad_token_id\": 0,\n",
            "  \"pruned_heads\": {},\n",
            "  \"repetition_penalty\": 1.0,\n",
            "  \"resid_pdrop\": 0.1,\n",
            "  \"summary_activation\": null,\n",
            "  \"summary_first_dropout\": 0.1,\n",
            "  \"summary_proj_to_labels\": true,\n",
            "  \"summary_type\": \"cls_index\",\n",
            "  \"summary_use_proj\": true,\n",
            "  \"temperature\": 1.0,\n",
            "  \"top_k\": 50,\n",
            "  \"top_p\": 1.0,\n",
            "  \"torchscript\": false,\n",
            "  \"use_bfloat16\": false,\n",
            "  \"vocab_size\": 50257\n",
            "}\n",
            "\n",
            "02/18/2020 17:48:51 - INFO - transformers.tokenization_utils -   Model name '/content/drive/My Drive/aurelius/output' not found in model shortcut name list (gpt2, gpt2-medium, gpt2-large, gpt2-xl, distilgpt2). Assuming '/content/drive/My Drive/aurelius/output' is a path, a model identifier, or url to a directory containing tokenizer files.\n",
            "02/18/2020 17:48:51 - INFO - transformers.tokenization_utils -   Didn't find file /content/drive/My Drive/aurelius/output/added_tokens.json. We won't load it.\n",
            "02/18/2020 17:48:51 - INFO - transformers.tokenization_utils -   loading file /content/drive/My Drive/aurelius/output/vocab.json\n",
            "02/18/2020 17:48:51 - INFO - transformers.tokenization_utils -   loading file /content/drive/My Drive/aurelius/output/merges.txt\n",
            "02/18/2020 17:48:51 - INFO - transformers.tokenization_utils -   loading file None\n",
            "02/18/2020 17:48:51 - INFO - transformers.tokenization_utils -   loading file /content/drive/My Drive/aurelius/output/special_tokens_map.json\n",
            "02/18/2020 17:48:51 - INFO - transformers.tokenization_utils -   loading file /content/drive/My Drive/aurelius/output/tokenizer_config.json\n",
            "02/18/2020 17:48:52 - INFO - transformers.modeling_utils -   loading weights file /content/drive/My Drive/aurelius/output/pytorch_model.bin\n",
            "02/18/2020 17:48:56 - INFO - __main__ -   Training/evaluation parameters Namespace(adam_epsilon=1e-08, block_size=1024, cache_dir=None, config_name=None, device=device(type='cpu'), do_eval=True, do_train=True, eval_all_checkpoints=False, eval_data_file='/content/drive/My Drive/aurelius/aurelius.txt', evaluate_during_training=False, fp16=False, fp16_opt_level='O1', gradient_accumulation_steps=1, learning_rate=5e-05, line_by_line=False, local_rank=-1, logging_steps=500, max_grad_norm=1.0, max_steps=-1, mlm=False, mlm_probability=0.15, model_name_or_path='/content/drive/My Drive/aurelius/output', model_type='gpt2', n_gpu=0, no_cuda=True, num_train_epochs=10.0, output_dir='/content/drive/My Drive/aurelius/output', overwrite_cache=False, overwrite_output_dir=True, per_gpu_eval_batch_size=4, per_gpu_train_batch_size=4, save_steps=500, save_total_limit=None, seed=42, server_ip='', server_port='', should_continue=False, tokenizer_name=None, train_data_file='/content/drive/My Drive/aurelius/aurelius.txt', warmup_steps=0, weight_decay=0.0)\n",
            "02/18/2020 17:48:56 - INFO - __main__ -   Loading features from cached file /content/drive/My Drive/aurelius/gpt2_cached_lm_1024_aurelius.txt\n",
            "02/18/2020 17:48:56 - INFO - __main__ -   ***** Running training *****\n",
            "02/18/2020 17:48:56 - INFO - __main__ -     Num examples = 75\n",
            "02/18/2020 17:48:56 - INFO - __main__ -     Num Epochs = 10\n",
            "02/18/2020 17:48:56 - INFO - __main__ -     Instantaneous batch size per GPU = 4\n",
            "02/18/2020 17:48:56 - INFO - __main__ -     Total train batch size (w. parallel, distributed & accumulation) = 4\n",
            "02/18/2020 17:48:56 - INFO - __main__ -     Gradient Accumulation steps = 1\n",
            "02/18/2020 17:48:56 - INFO - __main__ -     Total optimization steps = 190\n",
            "02/18/2020 17:48:56 - INFO - __main__ -     Starting fine-tuning.\n",
            "Epoch:   0% 0/10 [00:00<?, ?it/s]\n",
            "Iteration:   0% 0/19 [00:00<?, ?it/s]\u001b[A\n",
            "Iteration:   5% 1/19 [00:51<15:29, 51.66s/it]\u001b[A\n",
            "Iteration:  11% 2/19 [01:36<14:00, 49.46s/it]\u001b[A\n",
            "Iteration:  16% 3/19 [02:20<12:46, 47.91s/it]\u001b[A\n",
            "Iteration:  21% 4/19 [03:05<11:45, 47.00s/it]\u001b[A\n",
            "Iteration:  26% 5/19 [03:49<10:48, 46.30s/it]\u001b[A\n",
            "Iteration:  32% 6/19 [04:33<09:52, 45.57s/it]\u001b[A\n",
            "Iteration:  37% 7/19 [05:18<09:03, 45.29s/it]\u001b[A\n",
            "Iteration:  42% 8/19 [06:02<08:14, 44.91s/it]\u001b[A\n",
            "Iteration:  47% 9/19 [06:46<07:27, 44.75s/it]\u001b[A\n",
            "Iteration:  53% 10/19 [07:30<06:41, 44.57s/it]\u001b[A\n",
            "Iteration:  58% 11/19 [08:15<05:55, 44.44s/it]\u001b[A\n",
            "Iteration:  63% 12/19 [08:59<05:10, 44.35s/it]\u001b[A\n",
            "Iteration:  68% 13/19 [09:43<04:25, 44.23s/it]\u001b[A\n",
            "Iteration:  74% 14/19 [10:27<03:41, 44.27s/it]\u001b[A\n",
            "Iteration:  79% 15/19 [11:11<02:56, 44.23s/it]\u001b[A\n",
            "Iteration:  84% 16/19 [11:55<02:12, 44.15s/it]\u001b[A\n",
            "Iteration:  89% 17/19 [12:39<01:28, 44.18s/it]\u001b[A\n",
            "Iteration:  95% 18/19 [13:23<00:44, 44.16s/it]\u001b[A\n",
            "Iteration: 100% 19/19 [13:57<00:00, 41.04s/it]\u001b[A\n",
            "Epoch:  10% 1/10 [13:57<2:05:39, 837.69s/it]\n",
            "Iteration:   0% 0/19 [00:00<?, ?it/s]\u001b[A\n",
            "Iteration:   5% 1/19 [00:44<13:20, 44.47s/it]\u001b[A\n",
            "Iteration:  11% 2/19 [01:28<12:34, 44.38s/it]\u001b[A\n",
            "Iteration:  16% 3/19 [02:12<11:48, 44.25s/it]\u001b[A\n",
            "Iteration:  21% 4/19 [02:56<11:04, 44.27s/it]\u001b[A\n",
            "Iteration:  26% 5/19 [03:40<10:18, 44.19s/it]\u001b[A\n",
            "Iteration:  32% 6/19 [04:25<09:34, 44.20s/it]\u001b[A\n",
            "Iteration:  37% 7/19 [05:09<08:51, 44.27s/it]\u001b[A\n",
            "Iteration:  42% 8/19 [05:53<08:06, 44.20s/it]\u001b[A\n",
            "Iteration:  47% 9/19 [06:37<07:21, 44.16s/it]\u001b[A\n",
            "Iteration:  53% 10/19 [07:21<06:37, 44.15s/it]\u001b[A\n",
            "Iteration:  58% 11/19 [08:05<05:52, 44.09s/it]\u001b[A\n",
            "Iteration:  63% 12/19 [08:50<05:09, 44.18s/it]\u001b[A\n",
            "Iteration:  68% 13/19 [09:33<04:24, 44.08s/it]\u001b[A\n",
            "Iteration:  74% 14/19 [10:17<03:40, 44.06s/it]\u001b[A\n",
            "Iteration:  79% 15/19 [11:02<02:56, 44.11s/it]\u001b[A\n",
            "Iteration:  84% 16/19 [11:46<02:12, 44.14s/it]\u001b[A\n",
            "Iteration:  89% 17/19 [12:30<01:28, 44.09s/it]\u001b[A\n",
            "Iteration:  95% 18/19 [13:14<00:44, 44.08s/it]\u001b[A\n",
            "Iteration: 100% 19/19 [13:47<00:00, 40.91s/it]\u001b[A\n",
            "Epoch:  20% 2/10 [27:45<1:51:18, 834.77s/it]\n",
            "Iteration:   0% 0/19 [00:00<?, ?it/s]\u001b[A\n",
            "Iteration:   5% 1/19 [00:44<13:20, 44.46s/it]\u001b[A\n",
            "Iteration:  11% 2/19 [01:28<12:34, 44.38s/it]\u001b[A\n",
            "Iteration:  16% 3/19 [02:12<11:49, 44.32s/it]\u001b[A\n",
            "Iteration:  21% 4/19 [02:57<11:04, 44.30s/it]\u001b[A\n",
            "Iteration:  26% 5/19 [03:41<10:18, 44.20s/it]\u001b[A\n",
            "Iteration:  32% 6/19 [04:24<09:33, 44.09s/it]\u001b[A\n",
            "Iteration:  37% 7/19 [05:09<08:50, 44.20s/it]\u001b[A\n",
            "Iteration:  42% 8/19 [05:53<08:07, 44.28s/it]\u001b[A\n",
            "Iteration:  47% 9/19 [06:38<07:22, 44.26s/it]\u001b[A\n",
            "Iteration:  53% 10/19 [07:22<06:38, 44.30s/it]\u001b[A\n",
            "Iteration:  58% 11/19 [08:06<05:54, 44.36s/it]\u001b[A\n",
            "Iteration:  63% 12/19 [08:51<05:10, 44.30s/it]\u001b[A\n",
            "Iteration:  68% 13/19 [09:35<04:25, 44.29s/it]\u001b[A\n",
            "Iteration:  74% 14/19 [10:19<03:41, 44.21s/it]\u001b[A\n",
            "Iteration:  79% 15/19 [11:03<02:57, 44.32s/it]\u001b[A\n",
            "Iteration:  84% 16/19 [11:48<02:12, 44.27s/it]\u001b[A\n",
            "Iteration:  89% 17/19 [12:32<01:28, 44.21s/it]\u001b[A\n",
            "Iteration:  95% 18/19 [13:16<00:44, 44.31s/it]\u001b[A\n",
            "Iteration: 100% 19/19 [13:50<00:00, 41.18s/it]\u001b[A\n",
            "Epoch:  30% 3/10 [41:36<1:37:14, 833.52s/it]\n",
            "Iteration:   0% 0/19 [00:00<?, ?it/s]\u001b[A\n",
            "Iteration:   5% 1/19 [00:44<13:21, 44.51s/it]\u001b[A\n",
            "Iteration:  11% 2/19 [01:28<12:36, 44.50s/it]\u001b[A\n",
            "Iteration:  16% 3/19 [02:13<11:52, 44.55s/it]\u001b[A\n",
            "Iteration:  21% 4/19 [02:57<11:05, 44.38s/it]\u001b[A\n",
            "Iteration:  26% 5/19 [03:41<10:20, 44.29s/it]\u001b[A\n",
            "Iteration:  32% 6/19 [04:25<09:35, 44.26s/it]\u001b[A\n",
            "Iteration:  37% 7/19 [05:10<08:51, 44.32s/it]\u001b[A\n",
            "Iteration:  42% 8/19 [05:54<08:05, 44.15s/it]\u001b[A\n",
            "Iteration:  47% 9/19 [06:38<07:20, 44.09s/it]\u001b[A\n",
            "Iteration:  53% 10/19 [07:22<06:38, 44.28s/it]\u001b[A\n",
            "Iteration:  58% 11/19 [08:06<05:53, 44.20s/it]\u001b[A\n",
            "Iteration:  63% 12/19 [08:50<05:08, 44.10s/it]\u001b[A\n",
            "Iteration:  68% 13/19 [09:35<04:25, 44.20s/it]\u001b[A\n",
            "Iteration:  74% 14/19 [10:19<03:40, 44.18s/it]\u001b[A\n",
            "Iteration:  79% 15/19 [11:03<02:56, 44.20s/it]\u001b[A\n",
            "Iteration:  84% 16/19 [11:47<02:12, 44.24s/it]\u001b[A\n",
            "Iteration:  89% 17/19 [12:32<01:28, 44.23s/it]\u001b[A\n",
            "Iteration:  95% 18/19 [13:16<00:44, 44.35s/it]\u001b[A\n",
            "Iteration: 100% 19/19 [13:50<00:00, 41.09s/it]\u001b[A\n",
            "Epoch:  40% 4/10 [55:26<1:23:14, 832.50s/it]\n",
            "Iteration:   0% 0/19 [00:00<?, ?it/s]\u001b[A\n",
            "Iteration:   5% 1/19 [00:44<13:19, 44.40s/it]\u001b[A\n",
            "Iteration:  11% 2/19 [01:28<12:35, 44.46s/it]\u001b[A\n",
            "Iteration:  16% 3/19 [02:12<11:48, 44.30s/it]\u001b[A\n",
            "Iteration:  21% 4/19 [02:56<11:02, 44.18s/it]\u001b[A\n",
            "Iteration:  26% 5/19 [03:41<10:21, 44.38s/it]\u001b[A\n",
            "Iteration:  32% 6/19 [04:25<09:36, 44.32s/it]\u001b[A\n",
            "Iteration:  37% 7/19 [05:09<08:50, 44.21s/it]\u001b[A\n",
            "Iteration:  42% 8/19 [05:53<08:05, 44.15s/it]\u001b[A\n",
            "Iteration:  47% 9/19 [06:37<07:20, 44.05s/it]\u001b[A\n",
            "Iteration:  53% 10/19 [07:22<06:37, 44.18s/it]\u001b[A\n",
            "Iteration:  58% 11/19 [08:05<05:52, 44.02s/it]\u001b[A\n",
            "Iteration:  63% 12/19 [08:49<05:07, 43.98s/it]\u001b[A\n",
            "Iteration:  68% 13/19 [09:34<04:24, 44.10s/it]\u001b[A\n",
            "Iteration:  74% 14/19 [10:18<03:40, 44.08s/it]\u001b[A\n",
            "Iteration:  79% 15/19 [11:02<02:56, 44.12s/it]\u001b[A\n",
            "Iteration:  84% 16/19 [11:46<02:12, 44.21s/it]\u001b[A\n",
            "Iteration:  89% 17/19 [12:30<01:28, 44.07s/it]\u001b[A\n",
            "Iteration:  95% 18/19 [13:14<00:44, 44.02s/it]\u001b[A\n",
            "Iteration: 100% 19/19 [13:48<00:00, 40.92s/it]\u001b[A\n",
            "Epoch:  50% 5/10 [1:09:14<1:09:15, 831.16s/it]\n",
            "Iteration:   0% 0/19 [00:00<?, ?it/s]\u001b[A\n",
            "Iteration:   5% 1/19 [00:44<13:16, 44.23s/it]\u001b[A\n",
            "Iteration:  11% 2/19 [01:28<12:31, 44.22s/it]\u001b[A\n",
            "Iteration:  16% 3/19 [02:12<11:48, 44.27s/it]\u001b[A\n",
            "Iteration:  21% 4/19 [02:56<11:02, 44.19s/it]\u001b[A\n",
            "Iteration:  26% 5/19 [03:41<10:19, 44.27s/it]\u001b[A\n",
            "Iteration:  32% 6/19 [04:25<09:34, 44.19s/it]\u001b[A\n",
            "Iteration:  37% 7/19 [05:09<08:49, 44.16s/it]\u001b[A\n",
            "Iteration:  42% 8/19 [05:54<08:07, 44.32s/it]\u001b[A\n",
            "Iteration:  47% 9/19 [06:38<07:24, 44.45s/it]\u001b[A\n",
            "Iteration:  53% 10/19 [07:22<06:38, 44.32s/it]\u001b[A\n",
            "Iteration:  58% 11/19 [08:06<05:53, 44.19s/it]\u001b[A\n",
            "Iteration:  63% 12/19 [08:50<05:08, 44.13s/it]\u001b[A\n",
            "Iteration:  68% 13/19 [09:34<04:24, 44.14s/it]\u001b[A\n",
            "Iteration:  74% 14/19 [10:18<03:40, 44.02s/it]\u001b[A\n",
            "Iteration:  79% 15/19 [11:02<02:56, 44.06s/it]\u001b[A\n",
            "Iteration:  84% 16/19 [11:47<02:12, 44.12s/it]\u001b[A\n",
            "Iteration:  89% 17/19 [12:31<01:28, 44.12s/it]\u001b[A\n",
            "Iteration:  95% 18/19 [13:14<00:43, 43.97s/it]\u001b[A\n",
            "Iteration: 100% 19/19 [13:48<00:00, 40.86s/it]\u001b[A\n",
            "Epoch:  60% 6/10 [1:23:02<55:21, 830.31s/it]  \n",
            "Iteration:   0% 0/19 [00:00<?, ?it/s]\u001b[A\n",
            "Iteration:   5% 1/19 [00:44<13:15, 44.21s/it]\u001b[A\n",
            "Iteration:  11% 2/19 [01:28<12:29, 44.10s/it]\u001b[A\n",
            "Iteration:  16% 3/19 [02:12<11:46, 44.13s/it]\u001b[A\n",
            "Iteration:  21% 4/19 [02:56<11:00, 44.02s/it]\u001b[A\n",
            "Iteration:  26% 5/19 [03:40<10:17, 44.09s/it]\u001b[A\n",
            "Iteration:  32% 6/19 [04:24<09:31, 43.99s/it]\u001b[A\n",
            "Iteration:  37% 7/19 [05:07<08:47, 43.93s/it]\u001b[A\n",
            "Iteration:  42% 8/19 [05:52<08:04, 44.01s/it]\u001b[A\n",
            "Iteration:  47% 9/19 [06:35<07:19, 43.95s/it]\u001b[A\n",
            "Iteration:  53% 10/19 [07:19<06:35, 43.92s/it]\u001b[A\n",
            "Iteration:  58% 11/19 [08:04<05:53, 44.16s/it]\u001b[A\n",
            "Iteration:  63% 12/19 [08:48<05:08, 44.14s/it]\u001b[A\n",
            "Iteration:  68% 13/19 [09:32<04:24, 44.05s/it]\u001b[A\n",
            "Iteration:  74% 14/19 [10:16<03:40, 44.02s/it]\u001b[A\n",
            "Iteration:  79% 15/19 [11:00<02:55, 43.93s/it]\u001b[A\n",
            "Iteration:  84% 16/19 [11:44<02:11, 43.97s/it]\u001b[A\n",
            "Iteration:  89% 17/19 [12:27<01:27, 43.81s/it]\u001b[A\n",
            "Iteration:  95% 18/19 [13:11<00:43, 43.88s/it]\u001b[A\n",
            "Iteration: 100% 19/19 [13:45<00:00, 40.79s/it]\u001b[A\n",
            "Epoch:  70% 7/10 [1:36:47<41:26, 828.75s/it]\n",
            "Iteration:   0% 0/19 [00:00<?, ?it/s]\u001b[A\n",
            "Iteration:   5% 1/19 [00:43<13:07, 43.77s/it]\u001b[A\n",
            "Iteration:  11% 2/19 [01:27<12:24, 43.77s/it]\u001b[A\n",
            "Iteration:  16% 3/19 [02:11<11:42, 43.89s/it]\u001b[A\n",
            "Iteration:  21% 4/19 [02:55<10:57, 43.85s/it]\u001b[A\n",
            "Iteration:  26% 5/19 [03:39<10:14, 43.87s/it]\u001b[A\n",
            "Iteration:  32% 6/19 [04:23<09:31, 43.99s/it]\u001b[A\n",
            "Iteration:  37% 7/19 [05:07<08:46, 43.90s/it]\u001b[A\n",
            "Iteration:  42% 8/19 [05:51<08:02, 43.83s/it]\u001b[A\n",
            "Iteration:  47% 9/19 [06:34<07:18, 43.86s/it]\u001b[A\n",
            "Iteration:  53% 10/19 [07:18<06:33, 43.73s/it]\u001b[A\n",
            "Iteration:  58% 11/19 [08:02<05:50, 43.81s/it]\u001b[A\n",
            "Iteration:  63% 12/19 [08:45<05:06, 43.72s/it]\u001b[A\n",
            "Iteration:  68% 13/19 [09:30<04:23, 43.88s/it]\u001b[A\n",
            "Iteration:  74% 14/19 [10:14<03:39, 43.89s/it]\u001b[A\n",
            "Iteration:  79% 15/19 [10:57<02:55, 43.79s/it]\u001b[A\n",
            "Iteration:  84% 16/19 [11:40<02:10, 43.64s/it]\u001b[A\n",
            "Iteration:  89% 17/19 [12:24<01:27, 43.66s/it]\u001b[A\n",
            "Iteration:  95% 18/19 [13:07<00:43, 43.54s/it]\u001b[A\n",
            "Iteration: 100% 19/19 [13:41<00:00, 40.64s/it]\u001b[A\n",
            "Epoch:  80% 8/10 [1:50:29<27:33, 826.65s/it]\n",
            "Iteration:   0% 0/19 [00:00<?, ?it/s]\u001b[A\n",
            "Iteration:   5% 1/19 [00:44<13:15, 44.21s/it]\u001b[A\n",
            "Iteration:  11% 2/19 [01:27<12:28, 44.05s/it]\u001b[A\n",
            "Iteration:  16% 3/19 [02:11<11:44, 44.02s/it]\u001b[A\n",
            "Iteration:  21% 4/19 [02:55<10:59, 43.95s/it]\u001b[A\n",
            "Iteration:  26% 5/19 [03:39<10:13, 43.80s/it]\u001b[A\n",
            "Iteration:  32% 6/19 [04:23<09:30, 43.85s/it]\u001b[A\n",
            "Iteration:  37% 7/19 [05:06<08:44, 43.73s/it]\u001b[A\n",
            "Iteration:  42% 8/19 [05:50<08:01, 43.77s/it]\u001b[A\n",
            "Iteration:  47% 9/19 [06:34<07:18, 43.88s/it]\u001b[A\n",
            "Iteration:  53% 10/19 [07:18<06:34, 43.81s/it]\u001b[A\n",
            "Iteration:  58% 11/19 [08:01<05:50, 43.76s/it]\u001b[A\n",
            "Iteration:  63% 12/19 [08:45<05:06, 43.85s/it]\u001b[A\n",
            "Iteration:  68% 13/19 [09:29<04:22, 43.75s/it]\u001b[A\n",
            "Iteration:  74% 14/19 [10:13<03:38, 43.77s/it]\u001b[A\n",
            "Iteration:  79% 15/19 [10:57<02:55, 43.83s/it]\u001b[A\n",
            "Iteration:  84% 16/19 [11:41<02:11, 43.91s/it]\u001b[A\n",
            "Iteration:  89% 17/19 [12:25<01:27, 43.99s/it]\u001b[A\n",
            "Iteration:  95% 18/19 [13:09<00:43, 43.90s/it]\u001b[A\n",
            "Iteration: 100% 19/19 [13:42<00:00, 40.78s/it]\u001b[A\n",
            "Epoch:  90% 9/10 [2:04:12<13:45, 825.44s/it]\n",
            "Iteration:   0% 0/19 [00:00<?, ?it/s]\u001b[A\n",
            "Iteration:   5% 1/19 [00:44<13:14, 44.14s/it]\u001b[A\n",
            "Iteration:  11% 2/19 [01:27<12:27, 43.95s/it]\u001b[A\n",
            "Iteration:  16% 3/19 [02:11<11:41, 43.83s/it]\u001b[A\n",
            "Iteration:  21% 4/19 [02:55<10:59, 43.95s/it]\u001b[A\n",
            "Iteration:  26% 5/19 [03:39<10:13, 43.84s/it]\u001b[A\n",
            "Iteration:  32% 6/19 [04:22<09:28, 43.70s/it]\u001b[A\n",
            "Iteration:  37% 7/19 [05:06<08:44, 43.73s/it]\u001b[A\n",
            "Iteration:  42% 8/19 [05:49<08:00, 43.66s/it]\u001b[A\n",
            "Iteration:  47% 9/19 [06:33<07:18, 43.83s/it]\u001b[A\n",
            "Iteration:  53% 10/19 [07:17<06:32, 43.65s/it]\u001b[A\n",
            "Iteration:  58% 11/19 [08:00<05:49, 43.67s/it]\u001b[A\n",
            "Iteration:  63% 12/19 [08:44<05:06, 43.75s/it]\u001b[A\n",
            "Iteration:  68% 13/19 [09:28<04:22, 43.70s/it]\u001b[A\n",
            "Iteration:  74% 14/19 [10:11<03:38, 43.64s/it]\u001b[A\n",
            "Iteration:  79% 15/19 [10:55<02:54, 43.67s/it]\u001b[A\n",
            "Iteration:  84% 16/19 [11:39<02:10, 43.64s/it]\u001b[A\n",
            "Iteration:  89% 17/19 [12:22<01:27, 43.58s/it]\u001b[A\n",
            "Iteration:  95% 18/19 [13:06<00:43, 43.62s/it]\u001b[A\n",
            "Iteration: 100% 19/19 [13:39<00:00, 40.59s/it]\u001b[A\n",
            "Epoch: 100% 10/10 [2:17:52<00:00, 823.77s/it]\n",
            "02/18/2020 20:06:48 - INFO - __main__ -    global_step = 190, average loss = 2.424758233522114\n",
            "02/18/2020 20:06:49 - INFO - __main__ -   Saving model checkpoint to /content/drive/My Drive/aurelius/output\n",
            "02/18/2020 20:06:49 - INFO - transformers.configuration_utils -   Configuration saved in /content/drive/My Drive/aurelius/output/config.json\n",
            "02/18/2020 20:06:50 - INFO - transformers.modeling_utils -   Model weights saved in /content/drive/My Drive/aurelius/output/pytorch_model.bin\n",
            "02/18/2020 20:06:52 - INFO - transformers.configuration_utils -   loading configuration file /content/drive/My Drive/aurelius/output/config.json\n",
            "02/18/2020 20:06:52 - INFO - transformers.configuration_utils -   Model config GPT2Config {\n",
            "  \"architectures\": [\n",
            "    \"GPT2LMHeadModel\"\n",
            "  ],\n",
            "  \"attn_pdrop\": 0.1,\n",
            "  \"bos_token_id\": 0,\n",
            "  \"do_sample\": false,\n",
            "  \"embd_pdrop\": 0.1,\n",
            "  \"eos_token_ids\": 0,\n",
            "  \"finetuning_task\": null,\n",
            "  \"id2label\": {\n",
            "    \"0\": \"LABEL_0\",\n",
            "    \"1\": \"LABEL_1\"\n",
            "  },\n",
            "  \"initializer_range\": 0.02,\n",
            "  \"is_decoder\": false,\n",
            "  \"label2id\": {\n",
            "    \"LABEL_0\": 0,\n",
            "    \"LABEL_1\": 1\n",
            "  },\n",
            "  \"layer_norm_epsilon\": 1e-05,\n",
            "  \"length_penalty\": 1.0,\n",
            "  \"max_length\": 20,\n",
            "  \"model_type\": \"gpt2\",\n",
            "  \"n_ctx\": 1024,\n",
            "  \"n_embd\": 768,\n",
            "  \"n_head\": 12,\n",
            "  \"n_layer\": 12,\n",
            "  \"n_positions\": 1024,\n",
            "  \"num_beams\": 1,\n",
            "  \"num_labels\": 2,\n",
            "  \"num_return_sequences\": 1,\n",
            "  \"output_attentions\": false,\n",
            "  \"output_hidden_states\": false,\n",
            "  \"output_past\": true,\n",
            "  \"pad_token_id\": 0,\n",
            "  \"pruned_heads\": {},\n",
            "  \"repetition_penalty\": 1.0,\n",
            "  \"resid_pdrop\": 0.1,\n",
            "  \"summary_activation\": null,\n",
            "  \"summary_first_dropout\": 0.1,\n",
            "  \"summary_proj_to_labels\": true,\n",
            "  \"summary_type\": \"cls_index\",\n",
            "  \"summary_use_proj\": true,\n",
            "  \"temperature\": 1.0,\n",
            "  \"top_k\": 50,\n",
            "  \"top_p\": 1.0,\n",
            "  \"torchscript\": false,\n",
            "  \"use_bfloat16\": false,\n",
            "  \"vocab_size\": 50257\n",
            "}\n",
            "\n",
            "02/18/2020 20:06:52 - INFO - transformers.modeling_utils -   loading weights file /content/drive/My Drive/aurelius/output/pytorch_model.bin\n",
            "02/18/2020 20:06:56 - INFO - transformers.tokenization_utils -   Model name '/content/drive/My Drive/aurelius/output' not found in model shortcut name list (gpt2, gpt2-medium, gpt2-large, gpt2-xl, distilgpt2). Assuming '/content/drive/My Drive/aurelius/output' is a path, a model identifier, or url to a directory containing tokenizer files.\n",
            "02/18/2020 20:06:56 - INFO - transformers.tokenization_utils -   Didn't find file /content/drive/My Drive/aurelius/output/added_tokens.json. We won't load it.\n",
            "02/18/2020 20:06:56 - INFO - transformers.tokenization_utils -   loading file /content/drive/My Drive/aurelius/output/vocab.json\n",
            "02/18/2020 20:06:56 - INFO - transformers.tokenization_utils -   loading file /content/drive/My Drive/aurelius/output/merges.txt\n",
            "02/18/2020 20:06:56 - INFO - transformers.tokenization_utils -   loading file None\n",
            "02/18/2020 20:06:56 - INFO - transformers.tokenization_utils -   loading file /content/drive/My Drive/aurelius/output/special_tokens_map.json\n",
            "02/18/2020 20:06:56 - INFO - transformers.tokenization_utils -   loading file /content/drive/My Drive/aurelius/output/tokenizer_config.json\n",
            "02/18/2020 20:06:56 - INFO - __main__ -   Evaluate the following checkpoints: ['/content/drive/My Drive/aurelius/output']\n",
            "02/18/2020 20:06:56 - INFO - transformers.configuration_utils -   loading configuration file /content/drive/My Drive/aurelius/output/config.json\n",
            "02/18/2020 20:06:56 - INFO - transformers.configuration_utils -   Model config GPT2Config {\n",
            "  \"architectures\": [\n",
            "    \"GPT2LMHeadModel\"\n",
            "  ],\n",
            "  \"attn_pdrop\": 0.1,\n",
            "  \"bos_token_id\": 0,\n",
            "  \"do_sample\": false,\n",
            "  \"embd_pdrop\": 0.1,\n",
            "  \"eos_token_ids\": 0,\n",
            "  \"finetuning_task\": null,\n",
            "  \"id2label\": {\n",
            "    \"0\": \"LABEL_0\",\n",
            "    \"1\": \"LABEL_1\"\n",
            "  },\n",
            "  \"initializer_range\": 0.02,\n",
            "  \"is_decoder\": false,\n",
            "  \"label2id\": {\n",
            "    \"LABEL_0\": 0,\n",
            "    \"LABEL_1\": 1\n",
            "  },\n",
            "  \"layer_norm_epsilon\": 1e-05,\n",
            "  \"length_penalty\": 1.0,\n",
            "  \"max_length\": 20,\n",
            "  \"model_type\": \"gpt2\",\n",
            "  \"n_ctx\": 1024,\n",
            "  \"n_embd\": 768,\n",
            "  \"n_head\": 12,\n",
            "  \"n_layer\": 12,\n",
            "  \"n_positions\": 1024,\n",
            "  \"num_beams\": 1,\n",
            "  \"num_labels\": 2,\n",
            "  \"num_return_sequences\": 1,\n",
            "  \"output_attentions\": false,\n",
            "  \"output_hidden_states\": false,\n",
            "  \"output_past\": true,\n",
            "  \"pad_token_id\": 0,\n",
            "  \"pruned_heads\": {},\n",
            "  \"repetition_penalty\": 1.0,\n",
            "  \"resid_pdrop\": 0.1,\n",
            "  \"summary_activation\": null,\n",
            "  \"summary_first_dropout\": 0.1,\n",
            "  \"summary_proj_to_labels\": true,\n",
            "  \"summary_type\": \"cls_index\",\n",
            "  \"summary_use_proj\": true,\n",
            "  \"temperature\": 1.0,\n",
            "  \"top_k\": 50,\n",
            "  \"top_p\": 1.0,\n",
            "  \"torchscript\": false,\n",
            "  \"use_bfloat16\": false,\n",
            "  \"vocab_size\": 50257\n",
            "}\n",
            "\n",
            "02/18/2020 20:06:56 - INFO - transformers.modeling_utils -   loading weights file /content/drive/My Drive/aurelius/output/pytorch_model.bin\n",
            "02/18/2020 20:07:01 - INFO - __main__ -   Loading features from cached file /content/drive/My Drive/aurelius/gpt2_cached_lm_1024_aurelius.txt\n",
            "02/18/2020 20:07:01 - INFO - __main__ -   ***** Running evaluation  *****\n",
            "02/18/2020 20:07:01 - INFO - __main__ -     Num examples = 75\n",
            "02/18/2020 20:07:01 - INFO - __main__ -     Batch size = 4\n",
            "Evaluating: 100% 19/19 [04:14<00:00, 12.56s/it]\n",
            "02/18/2020 20:11:15 - INFO - __main__ -   ***** Eval results  *****\n",
            "02/18/2020 20:11:15 - INFO - __main__ -     perplexity = tensor(7.9028)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "0sOVWImWasdg",
        "colab_type": "text"
      },
      "source": [
        "# Remarks\n",
        "\n",
        "perplexity ~11 after 20 epochs\n",
        "the sample data is to small\n",
        "\n",
        "perplexity ~7.9 after 30 epochs!"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "mPO67Vj-GIIZ",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "outputId": "49c37dee-09f6-4f73-f291-0aaf17ab336d"
      },
      "source": [
        "!python transformers/examples/run_generation.py --model_type=gpt2 --model_name_or_path='/content/drive/My Drive/aurelius/output' --no_cuda --length 400"
      ],
      "execution_count": 15,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "02/19/2020 08:11:42 - INFO - transformers.tokenization_utils -   Model name '/content/drive/My Drive/aurelius/output' not found in model shortcut name list (gpt2, gpt2-medium, gpt2-large, gpt2-xl, distilgpt2). Assuming '/content/drive/My Drive/aurelius/output' is a path, a model identifier, or url to a directory containing tokenizer files.\n",
            "02/19/2020 08:11:42 - INFO - transformers.tokenization_utils -   Didn't find file /content/drive/My Drive/aurelius/output/added_tokens.json. We won't load it.\n",
            "02/19/2020 08:11:42 - INFO - transformers.tokenization_utils -   loading file /content/drive/My Drive/aurelius/output/vocab.json\n",
            "02/19/2020 08:11:42 - INFO - transformers.tokenization_utils -   loading file /content/drive/My Drive/aurelius/output/merges.txt\n",
            "02/19/2020 08:11:42 - INFO - transformers.tokenization_utils -   loading file None\n",
            "02/19/2020 08:11:42 - INFO - transformers.tokenization_utils -   loading file /content/drive/My Drive/aurelius/output/special_tokens_map.json\n",
            "02/19/2020 08:11:42 - INFO - transformers.tokenization_utils -   loading file /content/drive/My Drive/aurelius/output/tokenizer_config.json\n",
            "02/19/2020 08:11:42 - INFO - transformers.configuration_utils -   loading configuration file /content/drive/My Drive/aurelius/output/config.json\n",
            "02/19/2020 08:11:42 - INFO - transformers.configuration_utils -   Model config GPT2Config {\n",
            "  \"architectures\": [\n",
            "    \"GPT2LMHeadModel\"\n",
            "  ],\n",
            "  \"attn_pdrop\": 0.1,\n",
            "  \"bos_token_id\": 0,\n",
            "  \"do_sample\": false,\n",
            "  \"embd_pdrop\": 0.1,\n",
            "  \"eos_token_ids\": 0,\n",
            "  \"finetuning_task\": null,\n",
            "  \"id2label\": {\n",
            "    \"0\": \"LABEL_0\",\n",
            "    \"1\": \"LABEL_1\"\n",
            "  },\n",
            "  \"initializer_range\": 0.02,\n",
            "  \"is_decoder\": false,\n",
            "  \"label2id\": {\n",
            "    \"LABEL_0\": 0,\n",
            "    \"LABEL_1\": 1\n",
            "  },\n",
            "  \"layer_norm_epsilon\": 1e-05,\n",
            "  \"length_penalty\": 1.0,\n",
            "  \"max_length\": 20,\n",
            "  \"model_type\": \"gpt2\",\n",
            "  \"n_ctx\": 1024,\n",
            "  \"n_embd\": 768,\n",
            "  \"n_head\": 12,\n",
            "  \"n_layer\": 12,\n",
            "  \"n_positions\": 1024,\n",
            "  \"num_beams\": 1,\n",
            "  \"num_labels\": 2,\n",
            "  \"num_return_sequences\": 1,\n",
            "  \"output_attentions\": false,\n",
            "  \"output_hidden_states\": false,\n",
            "  \"output_past\": true,\n",
            "  \"pad_token_id\": 0,\n",
            "  \"pruned_heads\": {},\n",
            "  \"repetition_penalty\": 1.0,\n",
            "  \"resid_pdrop\": 0.1,\n",
            "  \"summary_activation\": null,\n",
            "  \"summary_first_dropout\": 0.1,\n",
            "  \"summary_proj_to_labels\": true,\n",
            "  \"summary_type\": \"cls_index\",\n",
            "  \"summary_use_proj\": true,\n",
            "  \"temperature\": 1.0,\n",
            "  \"top_k\": 50,\n",
            "  \"top_p\": 1.0,\n",
            "  \"torchscript\": false,\n",
            "  \"use_bfloat16\": false,\n",
            "  \"vocab_size\": 50257\n",
            "}\n",
            "\n",
            "02/19/2020 08:11:42 - INFO - transformers.modeling_utils -   loading weights file /content/drive/My Drive/aurelius/output/pytorch_model.bin\n",
            "02/19/2020 08:11:46 - INFO - __main__ -   Namespace(device=device(type='cpu'), k=0, length=400, model_name_or_path='/content/drive/My Drive/aurelius/output', model_type='gpt2', n_gpu=0, no_cuda=True, p=0.9, padding_text='', prompt='', repetition_penalty=1.0, seed=42, stop_token=None, temperature=1.0, xlm_language='')\n",
            "Model prompt >>> What is good?\n",
            "What is good?\n",
            "\n",
            "XII. Do the things that are according to nature happen unto thee according to the natural\n",
            "nature? and in what manner will they be benefited?\n",
            "\n",
            "XIII. How many are the ordinary persons, thou wilt find out, who are\n",
            "them that offend against reason; and who in their wicked imaginations\n",
            "incline themselves to reason and reason alone; and maintain that\n",
            "their opinions are idle and false?\n",
            "\n",
            "XIV. Nothing is more unrighteous than falsehood; for so will all those\n",
            "other things that were instituted for the good of the world,\n",
            "if they be subject to perpetual alteration and alteration. As for\n",
            "that which is good: it is of itself a thing that is evil, because it is\n",
            "unjust and ungracious. For what is worse, that which is good, that is\n",
            "contrary to reason? then thou wilt find out, who are them\n",
            "that offend against reason. Do thou therefore find\n",
            "out, who they that are both good and bad? what then is\n",
            "there that they are guilty of, besides their wicked\n",
            "rational opinions?\n",
            "\n",
            "XV. Not without reason and discretion shall these things happen unto thee.\n",
            "\n",
            "XVI. Can any soul be hurt in the course or performance of any\n",
            "thing? But would not that damage any worldly object, and thus avoid\n",
            "the danger of what? But of these objects by way of admonition\n",
            "such actions may be avoided: for as for them, they cannot by any\n",
            "reason operate against reason.\n",
            "\n",
            "XVII. Consider how many the ordinary persons, thou wilt find\n",
            "out, who have been unjustly prosecuted by thy physician; and who in their\n",
            "pleasure and indignation prosecute thee again, but without any further\n",
            "excrements.\n",
            "\n",
            "XVIII. Whatsoever doth happen unto any, hath taken it upon itself to be\n",
            "present at the same time. Consider how many!\n"
          ],
          "name": "stdout"
        }
      ]
    }
  ]
}