{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "transformers_test.ipynb",
      "provenance": [],
      "machine_shape": "hm",
      "authorship_tag": "ABX9TyO7fCUMlU+HXqYMWY0R2/O+",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/xSakix/AI_colab_notebooks/blob/master/transformers_test.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_sfG4uQwrTPY",
        "colab_type": "code",
        "outputId": "dc47c881-9919-4eeb-9ed1-796ef4b1145d",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        }
      },
      "source": [
        "!git clone https://github.com/huggingface/transformers\n",
        "!pip install transformers\n",
        "!pip install -r transformers/examples/requirements.txt"
      ],
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Cloning into 'transformers'...\n",
            "remote: Enumerating objects: 98, done.\u001b[K\n",
            "remote: Counting objects: 100% (98/98), done.\u001b[K\n",
            "remote: Compressing objects: 100% (68/68), done.\u001b[K\n",
            "remote: Total 20037 (delta 42), reused 43 (delta 15), pack-reused 19939\u001b[K\n",
            "Receiving objects: 100% (20037/20037), 11.66 MiB | 27.31 MiB/s, done.\n",
            "Resolving deltas: 100% (14636/14636), done.\n",
            "Collecting transformers\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/ee/fc/bd726a15ab2c66dc09306689d04da07a3770dad724f0883f0a4bfb745087/transformers-2.4.1-py3-none-any.whl (475kB)\n",
            "\u001b[K     |████████████████████████████████| 481kB 3.4MB/s \n",
            "\u001b[?25hRequirement already satisfied: filelock in /usr/local/lib/python3.6/dist-packages (from transformers) (3.0.12)\n",
            "Requirement already satisfied: boto3 in /usr/local/lib/python3.6/dist-packages (from transformers) (1.11.15)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.6/dist-packages (from transformers) (1.17.5)\n",
            "Collecting sentencepiece\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/74/f4/2d5214cbf13d06e7cb2c20d84115ca25b53ea76fa1f0ade0e3c9749de214/sentencepiece-0.1.85-cp36-cp36m-manylinux1_x86_64.whl (1.0MB)\n",
            "\u001b[K     |████████████████████████████████| 1.0MB 53.2MB/s \n",
            "\u001b[?25hCollecting sacremoses\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/a6/b4/7a41d630547a4afd58143597d5a49e07bfd4c42914d8335b2a5657efc14b/sacremoses-0.0.38.tar.gz (860kB)\n",
            "\u001b[K     |████████████████████████████████| 870kB 55.6MB/s \n",
            "\u001b[?25hCollecting tokenizers==0.0.11\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/5e/36/7af38d572c935f8e0462ec7b4f7a46d73a2b3b1a938f50a5e8132d5b2dc5/tokenizers-0.0.11-cp36-cp36m-manylinux1_x86_64.whl (3.1MB)\n",
            "\u001b[K     |████████████████████████████████| 3.1MB 48.0MB/s \n",
            "\u001b[?25hRequirement already satisfied: requests in /usr/local/lib/python3.6/dist-packages (from transformers) (2.21.0)\n",
            "Requirement already satisfied: tqdm>=4.27 in /usr/local/lib/python3.6/dist-packages (from transformers) (4.28.1)\n",
            "Requirement already satisfied: regex!=2019.12.17 in /usr/local/lib/python3.6/dist-packages (from transformers) (2019.12.20)\n",
            "Requirement already satisfied: s3transfer<0.4.0,>=0.3.0 in /usr/local/lib/python3.6/dist-packages (from boto3->transformers) (0.3.3)\n",
            "Requirement already satisfied: jmespath<1.0.0,>=0.7.1 in /usr/local/lib/python3.6/dist-packages (from boto3->transformers) (0.9.4)\n",
            "Requirement already satisfied: botocore<1.15.0,>=1.14.15 in /usr/local/lib/python3.6/dist-packages (from boto3->transformers) (1.14.15)\n",
            "Requirement already satisfied: six in /usr/local/lib/python3.6/dist-packages (from sacremoses->transformers) (1.12.0)\n",
            "Requirement already satisfied: click in /usr/local/lib/python3.6/dist-packages (from sacremoses->transformers) (7.0)\n",
            "Requirement already satisfied: joblib in /usr/local/lib/python3.6/dist-packages (from sacremoses->transformers) (0.14.1)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.6/dist-packages (from requests->transformers) (2019.11.28)\n",
            "Requirement already satisfied: urllib3<1.25,>=1.21.1 in /usr/local/lib/python3.6/dist-packages (from requests->transformers) (1.24.3)\n",
            "Requirement already satisfied: idna<2.9,>=2.5 in /usr/local/lib/python3.6/dist-packages (from requests->transformers) (2.8)\n",
            "Requirement already satisfied: chardet<3.1.0,>=3.0.2 in /usr/local/lib/python3.6/dist-packages (from requests->transformers) (3.0.4)\n",
            "Requirement already satisfied: docutils<0.16,>=0.10 in /usr/local/lib/python3.6/dist-packages (from botocore<1.15.0,>=1.14.15->boto3->transformers) (0.15.2)\n",
            "Requirement already satisfied: python-dateutil<3.0.0,>=2.1 in /usr/local/lib/python3.6/dist-packages (from botocore<1.15.0,>=1.14.15->boto3->transformers) (2.6.1)\n",
            "Building wheels for collected packages: sacremoses\n",
            "  Building wheel for sacremoses (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for sacremoses: filename=sacremoses-0.0.38-cp36-none-any.whl size=884628 sha256=7e554a81a1103a6e182d34f62adfef659cffc9f36b3e578e677821a1b791a2d2\n",
            "  Stored in directory: /root/.cache/pip/wheels/6d/ec/1a/21b8912e35e02741306f35f66c785f3afe94de754a0eaf1422\n",
            "Successfully built sacremoses\n",
            "Installing collected packages: sentencepiece, sacremoses, tokenizers, transformers\n",
            "Successfully installed sacremoses-0.0.38 sentencepiece-0.1.85 tokenizers-0.0.11 transformers-2.4.1\n",
            "Collecting tensorboardX\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/35/f1/5843425495765c8c2dd0784a851a93ef204d314fc87bcc2bbb9f662a3ad1/tensorboardX-2.0-py2.py3-none-any.whl (195kB)\n",
            "\u001b[K     |████████████████████████████████| 204kB 3.5MB/s \n",
            "\u001b[?25hRequirement already satisfied: tensorboard in /usr/local/lib/python3.6/dist-packages (from -r transformers/examples/requirements.txt (line 2)) (1.15.0)\n",
            "Requirement already satisfied: scikit-learn in /usr/local/lib/python3.6/dist-packages (from -r transformers/examples/requirements.txt (line 3)) (0.22.1)\n",
            "Collecting seqeval\n",
            "  Downloading https://files.pythonhosted.org/packages/34/91/068aca8d60ce56dd9ba4506850e876aba5e66a6f2f29aa223224b50df0de/seqeval-0.0.12.tar.gz\n",
            "Requirement already satisfied: protobuf>=3.8.0 in /usr/local/lib/python3.6/dist-packages (from tensorboardX->-r transformers/examples/requirements.txt (line 1)) (3.10.0)\n",
            "Requirement already satisfied: six in /usr/local/lib/python3.6/dist-packages (from tensorboardX->-r transformers/examples/requirements.txt (line 1)) (1.12.0)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.6/dist-packages (from tensorboardX->-r transformers/examples/requirements.txt (line 1)) (1.17.5)\n",
            "Requirement already satisfied: wheel>=0.26; python_version >= \"3\" in /usr/local/lib/python3.6/dist-packages (from tensorboard->-r transformers/examples/requirements.txt (line 2)) (0.34.2)\n",
            "Requirement already satisfied: setuptools>=41.0.0 in /usr/local/lib/python3.6/dist-packages (from tensorboard->-r transformers/examples/requirements.txt (line 2)) (45.1.0)\n",
            "Requirement already satisfied: markdown>=2.6.8 in /usr/local/lib/python3.6/dist-packages (from tensorboard->-r transformers/examples/requirements.txt (line 2)) (3.2.1)\n",
            "Requirement already satisfied: absl-py>=0.4 in /usr/local/lib/python3.6/dist-packages (from tensorboard->-r transformers/examples/requirements.txt (line 2)) (0.9.0)\n",
            "Requirement already satisfied: werkzeug>=0.11.15 in /usr/local/lib/python3.6/dist-packages (from tensorboard->-r transformers/examples/requirements.txt (line 2)) (1.0.0)\n",
            "Requirement already satisfied: grpcio>=1.6.3 in /usr/local/lib/python3.6/dist-packages (from tensorboard->-r transformers/examples/requirements.txt (line 2)) (1.27.1)\n",
            "Requirement already satisfied: scipy>=0.17.0 in /usr/local/lib/python3.6/dist-packages (from scikit-learn->-r transformers/examples/requirements.txt (line 3)) (1.4.1)\n",
            "Requirement already satisfied: joblib>=0.11 in /usr/local/lib/python3.6/dist-packages (from scikit-learn->-r transformers/examples/requirements.txt (line 3)) (0.14.1)\n",
            "Requirement already satisfied: Keras>=2.2.4 in /usr/local/lib/python3.6/dist-packages (from seqeval->-r transformers/examples/requirements.txt (line 4)) (2.2.5)\n",
            "Requirement already satisfied: keras-preprocessing>=1.1.0 in /usr/local/lib/python3.6/dist-packages (from Keras>=2.2.4->seqeval->-r transformers/examples/requirements.txt (line 4)) (1.1.0)\n",
            "Requirement already satisfied: h5py in /usr/local/lib/python3.6/dist-packages (from Keras>=2.2.4->seqeval->-r transformers/examples/requirements.txt (line 4)) (2.8.0)\n",
            "Requirement already satisfied: pyyaml in /usr/local/lib/python3.6/dist-packages (from Keras>=2.2.4->seqeval->-r transformers/examples/requirements.txt (line 4)) (3.13)\n",
            "Requirement already satisfied: keras-applications>=1.0.8 in /usr/local/lib/python3.6/dist-packages (from Keras>=2.2.4->seqeval->-r transformers/examples/requirements.txt (line 4)) (1.0.8)\n",
            "Building wheels for collected packages: seqeval\n",
            "  Building wheel for seqeval (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for seqeval: filename=seqeval-0.0.12-cp36-none-any.whl size=7424 sha256=9db7e502464e5910251055de263c133d40337f42135fc58138df8eafecb8f3b7\n",
            "  Stored in directory: /root/.cache/pip/wheels/4f/32/0a/df3b340a82583566975377d65e724895b3fad101a3fb729f68\n",
            "Successfully built seqeval\n",
            "Installing collected packages: tensorboardX, seqeval\n",
            "Successfully installed seqeval-0.0.12 tensorboardX-2.0\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "iCv8tFnCr7h9",
        "colab_type": "code",
        "outputId": "d2a42408-d794-458c-9169-ffad084c84bc",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        }
      },
      "source": [
        "!python transformers/examples/run_generation.py --model_type=gpt2 --model_name_or_path=gpt2 --no_cuda"
      ],
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "02/14/2020 18:52:34 - INFO - filelock -   Lock 139777389301152 acquired on /root/.cache/torch/transformers/f2808208f9bec2320371a9f5f891c184ae0b674ef866b79c58177067d15732dd.1512018be4ba4e8726e41b9145129dc30651ea4fec86aa61f4b9f40bf94eac71.lock\n",
            "02/14/2020 18:52:34 - INFO - transformers.file_utils -   https://s3.amazonaws.com/models.huggingface.co/bert/gpt2-vocab.json not found in cache or force_download set to True, downloading to /root/.cache/torch/transformers/tmpzu3cfpgq\n",
            "Downloading: 100% 1.04M/1.04M [00:00<00:00, 13.7MB/s]\n",
            "02/14/2020 18:52:34 - INFO - transformers.file_utils -   storing https://s3.amazonaws.com/models.huggingface.co/bert/gpt2-vocab.json in cache at /root/.cache/torch/transformers/f2808208f9bec2320371a9f5f891c184ae0b674ef866b79c58177067d15732dd.1512018be4ba4e8726e41b9145129dc30651ea4fec86aa61f4b9f40bf94eac71\n",
            "02/14/2020 18:52:34 - INFO - transformers.file_utils -   creating metadata file for /root/.cache/torch/transformers/f2808208f9bec2320371a9f5f891c184ae0b674ef866b79c58177067d15732dd.1512018be4ba4e8726e41b9145129dc30651ea4fec86aa61f4b9f40bf94eac71\n",
            "02/14/2020 18:52:34 - INFO - filelock -   Lock 139777389301152 released on /root/.cache/torch/transformers/f2808208f9bec2320371a9f5f891c184ae0b674ef866b79c58177067d15732dd.1512018be4ba4e8726e41b9145129dc30651ea4fec86aa61f4b9f40bf94eac71.lock\n",
            "02/14/2020 18:52:34 - INFO - filelock -   Lock 139777758629672 acquired on /root/.cache/torch/transformers/d629f792e430b3c76a1291bb2766b0a047e36fae0588f9dbc1ae51decdff691b.70bec105b4158ed9a1747fea67a43f5dee97855c64d62b6ec3742f4cfdb5feda.lock\n",
            "02/14/2020 18:52:34 - INFO - transformers.file_utils -   https://s3.amazonaws.com/models.huggingface.co/bert/gpt2-merges.txt not found in cache or force_download set to True, downloading to /root/.cache/torch/transformers/tmpvv0gw3fb\n",
            "Downloading: 100% 456k/456k [00:00<00:00, 7.14MB/s]\n",
            "02/14/2020 18:52:34 - INFO - transformers.file_utils -   storing https://s3.amazonaws.com/models.huggingface.co/bert/gpt2-merges.txt in cache at /root/.cache/torch/transformers/d629f792e430b3c76a1291bb2766b0a047e36fae0588f9dbc1ae51decdff691b.70bec105b4158ed9a1747fea67a43f5dee97855c64d62b6ec3742f4cfdb5feda\n",
            "02/14/2020 18:52:34 - INFO - transformers.file_utils -   creating metadata file for /root/.cache/torch/transformers/d629f792e430b3c76a1291bb2766b0a047e36fae0588f9dbc1ae51decdff691b.70bec105b4158ed9a1747fea67a43f5dee97855c64d62b6ec3742f4cfdb5feda\n",
            "02/14/2020 18:52:34 - INFO - filelock -   Lock 139777758629672 released on /root/.cache/torch/transformers/d629f792e430b3c76a1291bb2766b0a047e36fae0588f9dbc1ae51decdff691b.70bec105b4158ed9a1747fea67a43f5dee97855c64d62b6ec3742f4cfdb5feda.lock\n",
            "02/14/2020 18:52:34 - INFO - transformers.tokenization_utils -   loading file https://s3.amazonaws.com/models.huggingface.co/bert/gpt2-vocab.json from cache at /root/.cache/torch/transformers/f2808208f9bec2320371a9f5f891c184ae0b674ef866b79c58177067d15732dd.1512018be4ba4e8726e41b9145129dc30651ea4fec86aa61f4b9f40bf94eac71\n",
            "02/14/2020 18:52:34 - INFO - transformers.tokenization_utils -   loading file https://s3.amazonaws.com/models.huggingface.co/bert/gpt2-merges.txt from cache at /root/.cache/torch/transformers/d629f792e430b3c76a1291bb2766b0a047e36fae0588f9dbc1ae51decdff691b.70bec105b4158ed9a1747fea67a43f5dee97855c64d62b6ec3742f4cfdb5feda\n",
            "02/14/2020 18:52:35 - INFO - filelock -   Lock 139777389301600 acquired on /root/.cache/torch/transformers/4be02c5697d91738003fb1685c9872f284166aa32e061576bbe6aaeb95649fcf.699bbd1c449e9861456f359d6daa51bd523ac085b4b531ab0aad5a55d091e942.lock\n",
            "02/14/2020 18:52:35 - INFO - transformers.file_utils -   https://s3.amazonaws.com/models.huggingface.co/bert/gpt2-config.json not found in cache or force_download set to True, downloading to /root/.cache/torch/transformers/tmp10fazg54\n",
            "Downloading: 100% 224/224 [00:00<00:00, 134kB/s]\n",
            "02/14/2020 18:52:35 - INFO - transformers.file_utils -   storing https://s3.amazonaws.com/models.huggingface.co/bert/gpt2-config.json in cache at /root/.cache/torch/transformers/4be02c5697d91738003fb1685c9872f284166aa32e061576bbe6aaeb95649fcf.699bbd1c449e9861456f359d6daa51bd523ac085b4b531ab0aad5a55d091e942\n",
            "02/14/2020 18:52:35 - INFO - transformers.file_utils -   creating metadata file for /root/.cache/torch/transformers/4be02c5697d91738003fb1685c9872f284166aa32e061576bbe6aaeb95649fcf.699bbd1c449e9861456f359d6daa51bd523ac085b4b531ab0aad5a55d091e942\n",
            "02/14/2020 18:52:35 - INFO - filelock -   Lock 139777389301600 released on /root/.cache/torch/transformers/4be02c5697d91738003fb1685c9872f284166aa32e061576bbe6aaeb95649fcf.699bbd1c449e9861456f359d6daa51bd523ac085b4b531ab0aad5a55d091e942.lock\n",
            "02/14/2020 18:52:35 - INFO - transformers.configuration_utils -   loading configuration file https://s3.amazonaws.com/models.huggingface.co/bert/gpt2-config.json from cache at /root/.cache/torch/transformers/4be02c5697d91738003fb1685c9872f284166aa32e061576bbe6aaeb95649fcf.699bbd1c449e9861456f359d6daa51bd523ac085b4b531ab0aad5a55d091e942\n",
            "02/14/2020 18:52:35 - INFO - transformers.configuration_utils -   Model config GPT2Config {\n",
            "  \"architectures\": [\n",
            "    \"GPT2LMHeadModel\"\n",
            "  ],\n",
            "  \"attn_pdrop\": 0.1,\n",
            "  \"bos_token_id\": 0,\n",
            "  \"do_sample\": false,\n",
            "  \"embd_pdrop\": 0.1,\n",
            "  \"eos_token_ids\": 0,\n",
            "  \"finetuning_task\": null,\n",
            "  \"id2label\": {\n",
            "    \"0\": \"LABEL_0\",\n",
            "    \"1\": \"LABEL_1\"\n",
            "  },\n",
            "  \"initializer_range\": 0.02,\n",
            "  \"is_decoder\": false,\n",
            "  \"label2id\": {\n",
            "    \"LABEL_0\": 0,\n",
            "    \"LABEL_1\": 1\n",
            "  },\n",
            "  \"layer_norm_epsilon\": 1e-05,\n",
            "  \"length_penalty\": 1.0,\n",
            "  \"max_length\": 20,\n",
            "  \"model_type\": \"gpt2\",\n",
            "  \"n_ctx\": 1024,\n",
            "  \"n_embd\": 768,\n",
            "  \"n_head\": 12,\n",
            "  \"n_layer\": 12,\n",
            "  \"n_positions\": 1024,\n",
            "  \"num_beams\": 1,\n",
            "  \"num_labels\": 2,\n",
            "  \"num_return_sequences\": 1,\n",
            "  \"output_attentions\": false,\n",
            "  \"output_hidden_states\": false,\n",
            "  \"output_past\": true,\n",
            "  \"pad_token_id\": 0,\n",
            "  \"pruned_heads\": {},\n",
            "  \"repetition_penalty\": 1.0,\n",
            "  \"resid_pdrop\": 0.1,\n",
            "  \"summary_activation\": null,\n",
            "  \"summary_first_dropout\": 0.1,\n",
            "  \"summary_proj_to_labels\": true,\n",
            "  \"summary_type\": \"cls_index\",\n",
            "  \"summary_use_proj\": true,\n",
            "  \"temperature\": 1.0,\n",
            "  \"top_k\": 50,\n",
            "  \"top_p\": 1.0,\n",
            "  \"torchscript\": false,\n",
            "  \"use_bfloat16\": false,\n",
            "  \"vocab_size\": 50257\n",
            "}\n",
            "\n",
            "02/14/2020 18:52:35 - INFO - filelock -   Lock 139777389298800 acquired on /root/.cache/torch/transformers/4295d67f022061768f4adc386234dbdb781c814c39662dd1662221c309962c55.778cf36f5c4e5d94c8cd9cefcf2a580c8643570eb327f0d4a1f007fab2acbdf1.lock\n",
            "02/14/2020 18:52:35 - INFO - transformers.file_utils -   https://s3.amazonaws.com/models.huggingface.co/bert/gpt2-pytorch_model.bin not found in cache or force_download set to True, downloading to /root/.cache/torch/transformers/tmpw7k15mbv\n",
            "Downloading: 100% 548M/548M [00:07<00:00, 78.0MB/s]\n",
            "02/14/2020 18:52:42 - INFO - transformers.file_utils -   storing https://s3.amazonaws.com/models.huggingface.co/bert/gpt2-pytorch_model.bin in cache at /root/.cache/torch/transformers/4295d67f022061768f4adc386234dbdb781c814c39662dd1662221c309962c55.778cf36f5c4e5d94c8cd9cefcf2a580c8643570eb327f0d4a1f007fab2acbdf1\n",
            "02/14/2020 18:52:42 - INFO - transformers.file_utils -   creating metadata file for /root/.cache/torch/transformers/4295d67f022061768f4adc386234dbdb781c814c39662dd1662221c309962c55.778cf36f5c4e5d94c8cd9cefcf2a580c8643570eb327f0d4a1f007fab2acbdf1\n",
            "02/14/2020 18:52:42 - INFO - filelock -   Lock 139777389298800 released on /root/.cache/torch/transformers/4295d67f022061768f4adc386234dbdb781c814c39662dd1662221c309962c55.778cf36f5c4e5d94c8cd9cefcf2a580c8643570eb327f0d4a1f007fab2acbdf1.lock\n",
            "02/14/2020 18:52:42 - INFO - transformers.modeling_utils -   loading weights file https://s3.amazonaws.com/models.huggingface.co/bert/gpt2-pytorch_model.bin from cache at /root/.cache/torch/transformers/4295d67f022061768f4adc386234dbdb781c814c39662dd1662221c309962c55.778cf36f5c4e5d94c8cd9cefcf2a580c8643570eb327f0d4a1f007fab2acbdf1\n",
            "02/14/2020 18:52:46 - INFO - __main__ -   Namespace(device=device(type='cpu'), k=0, length=20, model_name_or_path='gpt2', model_type='gpt2', n_gpu=0, no_cuda=True, p=0.9, padding_text='', prompt='', repetition_penalty=1.0, seed=42, stop_token=None, temperature=1.0, xlm_language='')\n",
            "Model prompt >>> what is life?\n",
            "what is life?\n",
            "\n",
            "23:41 *gakes his hands free, sees some light!\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "XyZPkJMmsO-N",
        "colab_type": "code",
        "outputId": "b5f6cc92-315c-4ab7-edd6-49be0b38ca59",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        }
      },
      "source": [
        "!python transformers/examples/run_language_modeling.py --output_dir=output --model_type=gpt2 --model_name_or_path=gpt2 --do_train --train_data_file=socrates.txt --do_eval --eval_data_file=socrates.txt --no_cuda --num_train_epochs 4"
      ],
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "02/15/2020 06:53:48 - WARNING - __main__ -   Process rank: -1, device: cpu, n_gpu: 0, distributed training: False, 16-bits training: False\n",
            "02/15/2020 06:53:48 - INFO - filelock -   Lock 140447106103280 acquired on /root/.cache/torch/transformers/4be02c5697d91738003fb1685c9872f284166aa32e061576bbe6aaeb95649fcf.699bbd1c449e9861456f359d6daa51bd523ac085b4b531ab0aad5a55d091e942.lock\n",
            "02/15/2020 06:53:48 - INFO - transformers.file_utils -   https://s3.amazonaws.com/models.huggingface.co/bert/gpt2-config.json not found in cache or force_download set to True, downloading to /root/.cache/torch/transformers/tmpt9u9gavh\n",
            "Downloading: 100% 224/224 [00:00<00:00, 160kB/s]\n",
            "02/15/2020 06:53:48 - INFO - transformers.file_utils -   storing https://s3.amazonaws.com/models.huggingface.co/bert/gpt2-config.json in cache at /root/.cache/torch/transformers/4be02c5697d91738003fb1685c9872f284166aa32e061576bbe6aaeb95649fcf.699bbd1c449e9861456f359d6daa51bd523ac085b4b531ab0aad5a55d091e942\n",
            "02/15/2020 06:53:48 - INFO - transformers.file_utils -   creating metadata file for /root/.cache/torch/transformers/4be02c5697d91738003fb1685c9872f284166aa32e061576bbe6aaeb95649fcf.699bbd1c449e9861456f359d6daa51bd523ac085b4b531ab0aad5a55d091e942\n",
            "02/15/2020 06:53:48 - INFO - filelock -   Lock 140447106103280 released on /root/.cache/torch/transformers/4be02c5697d91738003fb1685c9872f284166aa32e061576bbe6aaeb95649fcf.699bbd1c449e9861456f359d6daa51bd523ac085b4b531ab0aad5a55d091e942.lock\n",
            "02/15/2020 06:53:48 - INFO - transformers.configuration_utils -   loading configuration file https://s3.amazonaws.com/models.huggingface.co/bert/gpt2-config.json from cache at /root/.cache/torch/transformers/4be02c5697d91738003fb1685c9872f284166aa32e061576bbe6aaeb95649fcf.699bbd1c449e9861456f359d6daa51bd523ac085b4b531ab0aad5a55d091e942\n",
            "02/15/2020 06:53:48 - INFO - transformers.configuration_utils -   Model config GPT2Config {\n",
            "  \"architectures\": [\n",
            "    \"GPT2LMHeadModel\"\n",
            "  ],\n",
            "  \"attn_pdrop\": 0.1,\n",
            "  \"bos_token_id\": 0,\n",
            "  \"do_sample\": false,\n",
            "  \"embd_pdrop\": 0.1,\n",
            "  \"eos_token_ids\": 0,\n",
            "  \"finetuning_task\": null,\n",
            "  \"id2label\": {\n",
            "    \"0\": \"LABEL_0\",\n",
            "    \"1\": \"LABEL_1\"\n",
            "  },\n",
            "  \"initializer_range\": 0.02,\n",
            "  \"is_decoder\": false,\n",
            "  \"label2id\": {\n",
            "    \"LABEL_0\": 0,\n",
            "    \"LABEL_1\": 1\n",
            "  },\n",
            "  \"layer_norm_epsilon\": 1e-05,\n",
            "  \"length_penalty\": 1.0,\n",
            "  \"max_length\": 20,\n",
            "  \"model_type\": \"gpt2\",\n",
            "  \"n_ctx\": 1024,\n",
            "  \"n_embd\": 768,\n",
            "  \"n_head\": 12,\n",
            "  \"n_layer\": 12,\n",
            "  \"n_positions\": 1024,\n",
            "  \"num_beams\": 1,\n",
            "  \"num_labels\": 2,\n",
            "  \"num_return_sequences\": 1,\n",
            "  \"output_attentions\": false,\n",
            "  \"output_hidden_states\": false,\n",
            "  \"output_past\": true,\n",
            "  \"pad_token_id\": 0,\n",
            "  \"pruned_heads\": {},\n",
            "  \"repetition_penalty\": 1.0,\n",
            "  \"resid_pdrop\": 0.1,\n",
            "  \"summary_activation\": null,\n",
            "  \"summary_first_dropout\": 0.1,\n",
            "  \"summary_proj_to_labels\": true,\n",
            "  \"summary_type\": \"cls_index\",\n",
            "  \"summary_use_proj\": true,\n",
            "  \"temperature\": 1.0,\n",
            "  \"top_k\": 50,\n",
            "  \"top_p\": 1.0,\n",
            "  \"torchscript\": false,\n",
            "  \"use_bfloat16\": false,\n",
            "  \"vocab_size\": 50257\n",
            "}\n",
            "\n",
            "02/15/2020 06:53:48 - INFO - filelock -   Lock 140447106103280 acquired on /root/.cache/torch/transformers/f2808208f9bec2320371a9f5f891c184ae0b674ef866b79c58177067d15732dd.1512018be4ba4e8726e41b9145129dc30651ea4fec86aa61f4b9f40bf94eac71.lock\n",
            "02/15/2020 06:53:48 - INFO - transformers.file_utils -   https://s3.amazonaws.com/models.huggingface.co/bert/gpt2-vocab.json not found in cache or force_download set to True, downloading to /root/.cache/torch/transformers/tmpvtc76fzi\n",
            "Downloading: 100% 1.04M/1.04M [00:00<00:00, 5.61MB/s]\n",
            "02/15/2020 06:53:49 - INFO - transformers.file_utils -   storing https://s3.amazonaws.com/models.huggingface.co/bert/gpt2-vocab.json in cache at /root/.cache/torch/transformers/f2808208f9bec2320371a9f5f891c184ae0b674ef866b79c58177067d15732dd.1512018be4ba4e8726e41b9145129dc30651ea4fec86aa61f4b9f40bf94eac71\n",
            "02/15/2020 06:53:49 - INFO - transformers.file_utils -   creating metadata file for /root/.cache/torch/transformers/f2808208f9bec2320371a9f5f891c184ae0b674ef866b79c58177067d15732dd.1512018be4ba4e8726e41b9145129dc30651ea4fec86aa61f4b9f40bf94eac71\n",
            "02/15/2020 06:53:49 - INFO - filelock -   Lock 140447106103280 released on /root/.cache/torch/transformers/f2808208f9bec2320371a9f5f891c184ae0b674ef866b79c58177067d15732dd.1512018be4ba4e8726e41b9145129dc30651ea4fec86aa61f4b9f40bf94eac71.lock\n",
            "02/15/2020 06:53:49 - INFO - filelock -   Lock 140447106103280 acquired on /root/.cache/torch/transformers/d629f792e430b3c76a1291bb2766b0a047e36fae0588f9dbc1ae51decdff691b.70bec105b4158ed9a1747fea67a43f5dee97855c64d62b6ec3742f4cfdb5feda.lock\n",
            "02/15/2020 06:53:49 - INFO - transformers.file_utils -   https://s3.amazonaws.com/models.huggingface.co/bert/gpt2-merges.txt not found in cache or force_download set to True, downloading to /root/.cache/torch/transformers/tmprgy6_fd7\n",
            "Downloading: 100% 456k/456k [00:00<00:00, 3.83MB/s]\n",
            "02/15/2020 06:53:49 - INFO - transformers.file_utils -   storing https://s3.amazonaws.com/models.huggingface.co/bert/gpt2-merges.txt in cache at /root/.cache/torch/transformers/d629f792e430b3c76a1291bb2766b0a047e36fae0588f9dbc1ae51decdff691b.70bec105b4158ed9a1747fea67a43f5dee97855c64d62b6ec3742f4cfdb5feda\n",
            "02/15/2020 06:53:49 - INFO - transformers.file_utils -   creating metadata file for /root/.cache/torch/transformers/d629f792e430b3c76a1291bb2766b0a047e36fae0588f9dbc1ae51decdff691b.70bec105b4158ed9a1747fea67a43f5dee97855c64d62b6ec3742f4cfdb5feda\n",
            "02/15/2020 06:53:49 - INFO - filelock -   Lock 140447106103280 released on /root/.cache/torch/transformers/d629f792e430b3c76a1291bb2766b0a047e36fae0588f9dbc1ae51decdff691b.70bec105b4158ed9a1747fea67a43f5dee97855c64d62b6ec3742f4cfdb5feda.lock\n",
            "02/15/2020 06:53:49 - INFO - transformers.tokenization_utils -   loading file https://s3.amazonaws.com/models.huggingface.co/bert/gpt2-vocab.json from cache at /root/.cache/torch/transformers/f2808208f9bec2320371a9f5f891c184ae0b674ef866b79c58177067d15732dd.1512018be4ba4e8726e41b9145129dc30651ea4fec86aa61f4b9f40bf94eac71\n",
            "02/15/2020 06:53:49 - INFO - transformers.tokenization_utils -   loading file https://s3.amazonaws.com/models.huggingface.co/bert/gpt2-merges.txt from cache at /root/.cache/torch/transformers/d629f792e430b3c76a1291bb2766b0a047e36fae0588f9dbc1ae51decdff691b.70bec105b4158ed9a1747fea67a43f5dee97855c64d62b6ec3742f4cfdb5feda\n",
            "02/15/2020 06:53:49 - INFO - filelock -   Lock 140446734303360 acquired on /root/.cache/torch/transformers/4295d67f022061768f4adc386234dbdb781c814c39662dd1662221c309962c55.778cf36f5c4e5d94c8cd9cefcf2a580c8643570eb327f0d4a1f007fab2acbdf1.lock\n",
            "02/15/2020 06:53:49 - INFO - transformers.file_utils -   https://s3.amazonaws.com/models.huggingface.co/bert/gpt2-pytorch_model.bin not found in cache or force_download set to True, downloading to /root/.cache/torch/transformers/tmptool4_6j\n",
            "Downloading: 100% 548M/548M [00:08<00:00, 63.5MB/s]\n",
            "02/15/2020 06:53:58 - INFO - transformers.file_utils -   storing https://s3.amazonaws.com/models.huggingface.co/bert/gpt2-pytorch_model.bin in cache at /root/.cache/torch/transformers/4295d67f022061768f4adc386234dbdb781c814c39662dd1662221c309962c55.778cf36f5c4e5d94c8cd9cefcf2a580c8643570eb327f0d4a1f007fab2acbdf1\n",
            "02/15/2020 06:53:58 - INFO - transformers.file_utils -   creating metadata file for /root/.cache/torch/transformers/4295d67f022061768f4adc386234dbdb781c814c39662dd1662221c309962c55.778cf36f5c4e5d94c8cd9cefcf2a580c8643570eb327f0d4a1f007fab2acbdf1\n",
            "02/15/2020 06:53:58 - INFO - filelock -   Lock 140446734303360 released on /root/.cache/torch/transformers/4295d67f022061768f4adc386234dbdb781c814c39662dd1662221c309962c55.778cf36f5c4e5d94c8cd9cefcf2a580c8643570eb327f0d4a1f007fab2acbdf1.lock\n",
            "02/15/2020 06:53:58 - INFO - transformers.modeling_utils -   loading weights file https://s3.amazonaws.com/models.huggingface.co/bert/gpt2-pytorch_model.bin from cache at /root/.cache/torch/transformers/4295d67f022061768f4adc386234dbdb781c814c39662dd1662221c309962c55.778cf36f5c4e5d94c8cd9cefcf2a580c8643570eb327f0d4a1f007fab2acbdf1\n",
            "02/15/2020 06:54:03 - INFO - __main__ -   Training/evaluation parameters Namespace(adam_epsilon=1e-08, block_size=1024, cache_dir=None, config_name=None, device=device(type='cpu'), do_eval=True, do_train=True, eval_all_checkpoints=False, eval_data_file='socrates.txt', evaluate_during_training=False, fp16=False, fp16_opt_level='O1', gradient_accumulation_steps=1, learning_rate=5e-05, line_by_line=False, local_rank=-1, logging_steps=500, max_grad_norm=1.0, max_steps=-1, mlm=False, mlm_probability=0.15, model_name_or_path='gpt2', model_type='gpt2', n_gpu=0, no_cuda=True, num_train_epochs=4.0, output_dir='output', overwrite_cache=False, overwrite_output_dir=False, per_gpu_eval_batch_size=4, per_gpu_train_batch_size=4, save_steps=500, save_total_limit=None, seed=42, server_ip='', server_port='', should_continue=False, tokenizer_name=None, train_data_file='socrates.txt', warmup_steps=0, weight_decay=0.0)\n",
            "02/15/2020 06:54:03 - INFO - __main__ -   Creating features from dataset file at \n",
            "02/15/2020 06:54:04 - INFO - __main__ -   Saving features into cached file gpt2_cached_lm_1024_socrates.txt\n",
            "02/15/2020 06:54:04 - INFO - __main__ -   ***** Running training *****\n",
            "02/15/2020 06:54:04 - INFO - __main__ -     Num examples = 285\n",
            "02/15/2020 06:54:04 - INFO - __main__ -     Num Epochs = 4\n",
            "02/15/2020 06:54:04 - INFO - __main__ -     Instantaneous batch size per GPU = 4\n",
            "02/15/2020 06:54:04 - INFO - __main__ -     Total train batch size (w. parallel, distributed & accumulation) = 4\n",
            "02/15/2020 06:54:04 - INFO - __main__ -     Gradient Accumulation steps = 1\n",
            "02/15/2020 06:54:04 - INFO - __main__ -     Total optimization steps = 288\n",
            "Epoch:   0% 0/4 [00:00<?, ?it/s]\n",
            "Iteration:   0% 0/72 [00:00<?, ?it/s]\u001b[A\n",
            "Iteration:   1% 1/72 [00:49<58:04, 49.08s/it]\u001b[A\n",
            "Iteration:   3% 2/72 [01:33<55:31, 47.59s/it]\u001b[A\n",
            "Iteration:   4% 3/72 [02:15<53:04, 46.15s/it]\u001b[A\n",
            "Iteration:   6% 4/72 [02:59<51:23, 45.34s/it]\u001b[A\n",
            "Iteration:   7% 5/72 [03:42<49:54, 44.70s/it]\u001b[A\n",
            "Iteration:   8% 6/72 [04:25<48:28, 44.07s/it]\u001b[A\n",
            "Iteration:  10% 7/72 [05:07<47:16, 43.64s/it]\u001b[A\n",
            "Iteration:  11% 8/72 [05:54<47:24, 44.45s/it]\u001b[A\n",
            "Iteration:  12% 9/72 [06:38<46:30, 44.29s/it]\u001b[A\n",
            "Iteration:  14% 10/72 [07:20<45:19, 43.86s/it]\u001b[A\n",
            "Iteration:  15% 11/72 [08:03<44:11, 43.47s/it]\u001b[A\n",
            "Iteration:  17% 12/72 [08:46<43:15, 43.26s/it]\u001b[A\n",
            "Iteration:  18% 13/72 [09:29<42:23, 43.10s/it]\u001b[A\n",
            "Iteration:  19% 14/72 [10:11<41:31, 42.96s/it]\u001b[A\n",
            "Iteration:  21% 15/72 [10:54<40:43, 42.87s/it]\u001b[A\n",
            "Iteration:  22% 16/72 [11:37<40:10, 43.04s/it]\u001b[A\n",
            "Iteration:  24% 17/72 [12:20<39:29, 43.07s/it]\u001b[A\n",
            "Iteration:  25% 18/72 [13:04<38:46, 43.08s/it]\u001b[A\n",
            "Iteration:  26% 19/72 [13:47<38:05, 43.12s/it]\u001b[A\n",
            "Iteration:  28% 20/72 [14:30<37:17, 43.04s/it]\u001b[A\n",
            "Iteration:  29% 21/72 [15:12<36:29, 42.93s/it]\u001b[A\n",
            "Iteration:  31% 22/72 [15:55<35:42, 42.85s/it]\u001b[A\n",
            "Iteration:  32% 23/72 [16:38<34:57, 42.80s/it]\u001b[A\n",
            "Iteration:  33% 24/72 [17:20<34:12, 42.76s/it]\u001b[A\n",
            "Iteration:  35% 25/72 [18:03<33:23, 42.63s/it]\u001b[A\n",
            "Iteration:  36% 26/72 [18:45<32:39, 42.60s/it]\u001b[A\n",
            "Iteration:  38% 27/72 [19:28<31:58, 42.63s/it]\u001b[A\n",
            "Iteration:  39% 28/72 [20:10<31:08, 42.47s/it]\u001b[A\n",
            "Iteration:  40% 29/72 [20:52<30:25, 42.45s/it]\u001b[A\n",
            "Iteration:  42% 30/72 [21:37<30:06, 43.02s/it]\u001b[A\n",
            "Iteration:  43% 31/72 [22:19<29:12, 42.74s/it]\u001b[A\n",
            "Iteration:  44% 32/72 [23:01<28:23, 42.58s/it]\u001b[A\n",
            "Iteration:  46% 33/72 [23:44<27:40, 42.57s/it]\u001b[A\n",
            "Iteration:  47% 34/72 [24:26<26:54, 42.50s/it]\u001b[A\n",
            "Iteration:  49% 35/72 [25:08<26:08, 42.40s/it]\u001b[A\n",
            "Iteration:  50% 36/72 [25:50<25:25, 42.37s/it]\u001b[A\n",
            "Iteration:  51% 37/72 [26:33<24:42, 42.37s/it]\u001b[A\n",
            "Iteration:  53% 38/72 [27:15<23:58, 42.32s/it]\u001b[A\n",
            "Iteration:  54% 39/72 [27:57<23:16, 42.32s/it]\u001b[A\n",
            "Iteration:  56% 40/72 [28:40<22:34, 42.33s/it]\u001b[A\n",
            "Iteration:  57% 41/72 [29:22<21:55, 42.43s/it]\u001b[A\n",
            "Iteration:  58% 42/72 [30:05<21:11, 42.40s/it]\u001b[A\n",
            "Iteration:  60% 43/72 [30:47<20:30, 42.44s/it]\u001b[A\n",
            "Iteration:  61% 44/72 [31:29<19:46, 42.36s/it]\u001b[A\n",
            "Iteration:  62% 45/72 [32:11<19:02, 42.32s/it]\u001b[A\n",
            "Iteration:  64% 46/72 [32:53<18:17, 42.23s/it]\u001b[A\n",
            "Iteration:  65% 47/72 [33:36<17:34, 42.17s/it]\u001b[A\n",
            "Iteration:  67% 48/72 [34:18<16:52, 42.20s/it]\u001b[A\n",
            "Iteration:  68% 49/72 [35:00<16:08, 42.13s/it]\u001b[A\n",
            "Iteration:  69% 50/72 [35:42<15:27, 42.14s/it]\u001b[A\n",
            "Iteration:  71% 51/72 [36:25<14:51, 42.43s/it]\u001b[A\n",
            "Iteration:  72% 52/72 [37:07<14:08, 42.43s/it]\u001b[A\n",
            "Iteration:  74% 53/72 [37:50<13:25, 42.37s/it]\u001b[A\n",
            "Iteration:  75% 54/72 [38:32<12:42, 42.35s/it]\u001b[A\n",
            "Iteration:  76% 55/72 [39:14<11:58, 42.29s/it]\u001b[A\n",
            "Iteration:  78% 56/72 [39:57<11:17, 42.33s/it]\u001b[A\n",
            "Iteration:  79% 57/72 [40:39<10:34, 42.30s/it]\u001b[A\n",
            "Iteration:  81% 58/72 [41:21<09:52, 42.29s/it]\u001b[A\n",
            "Iteration:  82% 59/72 [42:03<09:09, 42.30s/it]\u001b[A\n",
            "Iteration:  83% 60/72 [42:46<08:27, 42.27s/it]\u001b[A\n",
            "Iteration:  85% 61/72 [43:28<07:44, 42.23s/it]\u001b[A\n",
            "Iteration:  86% 62/72 [44:10<07:01, 42.12s/it]\u001b[A\n",
            "Iteration:  88% 63/72 [44:52<06:19, 42.20s/it]\u001b[A\n",
            "Iteration:  89% 64/72 [45:34<05:37, 42.20s/it]\u001b[A\n",
            "Iteration:  90% 65/72 [46:16<04:54, 42.10s/it]\u001b[A\n",
            "Iteration:  92% 66/72 [46:58<04:12, 42.08s/it]\u001b[A\n",
            "Iteration:  93% 67/72 [47:40<03:30, 42.07s/it]\u001b[A\n",
            "Iteration:  94% 68/72 [48:22<02:48, 42.09s/it]\u001b[A\n",
            "Iteration:  96% 69/72 [49:04<02:06, 42.12s/it]\u001b[A\n",
            "Iteration:  97% 70/72 [49:47<01:24, 42.23s/it]\u001b[A\n",
            "Iteration:  99% 71/72 [50:29<00:42, 42.16s/it]\u001b[A\n",
            "Iteration: 100% 72/72 [50:42<00:00, 33.30s/it]\u001b[A\n",
            "Epoch:  25% 1/4 [50:42<2:32:06, 3042.08s/it]\n",
            "Iteration:   0% 0/72 [00:00<?, ?it/s]\u001b[A\n",
            "Iteration:   1% 1/72 [00:42<50:19, 42.53s/it]\u001b[A\n",
            "Iteration:   3% 2/72 [01:28<50:45, 43.50s/it]\u001b[A\n",
            "Iteration:   4% 3/72 [02:10<49:38, 43.16s/it]\u001b[A\n",
            "Iteration:   6% 4/72 [02:52<48:37, 42.91s/it]\u001b[A\n",
            "Iteration:   7% 5/72 [03:35<47:39, 42.68s/it]\u001b[A\n",
            "Iteration:   8% 6/72 [04:17<46:52, 42.62s/it]\u001b[A\n",
            "Iteration:  10% 7/72 [04:59<46:02, 42.51s/it]\u001b[A\n",
            "Iteration:  11% 8/72 [05:42<45:16, 42.45s/it]\u001b[A\n",
            "Iteration:  12% 9/72 [06:24<44:31, 42.40s/it]\u001b[A\n",
            "Iteration:  14% 10/72 [07:07<43:53, 42.48s/it]\u001b[A\n",
            "Iteration:  15% 11/72 [07:49<43:04, 42.36s/it]\u001b[A\n",
            "Iteration:  17% 12/72 [08:31<42:18, 42.30s/it]\u001b[A\n",
            "Iteration:  18% 13/72 [09:13<41:36, 42.31s/it]\u001b[A\n",
            "Iteration:  19% 14/72 [09:56<40:54, 42.31s/it]\u001b[A\n",
            "Iteration:  21% 15/72 [10:38<40:13, 42.34s/it]\u001b[A\n",
            "Iteration:  22% 16/72 [11:20<39:27, 42.28s/it]\u001b[A\n",
            "Iteration:  24% 17/72 [12:02<38:47, 42.32s/it]\u001b[A\n",
            "Iteration:  25% 18/72 [12:45<38:04, 42.30s/it]\u001b[A\n",
            "Iteration:  26% 19/72 [13:27<37:17, 42.22s/it]\u001b[A\n",
            "Iteration:  28% 20/72 [14:09<36:34, 42.21s/it]\u001b[A\n",
            "Iteration:  29% 21/72 [14:51<35:57, 42.31s/it]\u001b[A\n",
            "Iteration:  31% 22/72 [15:34<35:12, 42.26s/it]\u001b[A\n",
            "Iteration:  32% 23/72 [16:16<34:29, 42.24s/it]\u001b[A\n",
            "Iteration:  33% 24/72 [16:58<33:51, 42.32s/it]\u001b[A\n",
            "Iteration:  35% 25/72 [17:40<33:06, 42.26s/it]\u001b[A\n",
            "Iteration:  36% 26/72 [18:22<32:20, 42.18s/it]\u001b[A\n",
            "Iteration:  38% 27/72 [19:05<31:40, 42.24s/it]\u001b[A\n",
            "Iteration:  39% 28/72 [19:47<30:59, 42.27s/it]\u001b[A\n",
            "Iteration:  40% 29/72 [20:30<30:21, 42.35s/it]\u001b[A\n",
            "Iteration:  42% 30/72 [21:12<29:40, 42.40s/it]\u001b[A\n",
            "Iteration:  43% 31/72 [21:55<28:58, 42.40s/it]\u001b[A\n",
            "Iteration:  44% 32/72 [22:37<28:18, 42.45s/it]\u001b[A\n",
            "Iteration:  46% 33/72 [23:19<27:32, 42.37s/it]\u001b[A\n",
            "Iteration:  47% 34/72 [24:02<26:51, 42.41s/it]\u001b[A\n",
            "Iteration:  49% 35/72 [24:44<26:10, 42.43s/it]\u001b[A\n",
            "Iteration:  50% 36/72 [25:27<25:31, 42.54s/it]\u001b[A\n",
            "Iteration:  51% 37/72 [26:09<24:45, 42.45s/it]\u001b[A\n",
            "Iteration:  53% 38/72 [26:52<24:06, 42.55s/it]\u001b[A\n",
            "Iteration:  54% 39/72 [27:35<23:23, 42.52s/it]\u001b[A\n",
            "Iteration:  56% 40/72 [28:17<22:39, 42.47s/it]\u001b[A\n",
            "Iteration:  57% 41/72 [29:00<21:57, 42.51s/it]\u001b[A\n",
            "Iteration:  58% 42/72 [29:42<21:14, 42.47s/it]\u001b[A\n",
            "Iteration:  60% 43/72 [30:25<20:35, 42.61s/it]\u001b[A\n",
            "Iteration:  61% 44/72 [31:08<19:54, 42.66s/it]\u001b[A\n",
            "Iteration:  62% 45/72 [31:50<19:09, 42.58s/it]\u001b[A\n",
            "Iteration:  64% 46/72 [32:33<18:27, 42.61s/it]\u001b[A\n",
            "Iteration:  65% 47/72 [33:15<17:45, 42.63s/it]\u001b[A\n",
            "Iteration:  67% 48/72 [33:58<17:02, 42.62s/it]\u001b[A\n",
            "Iteration:  68% 49/72 [34:41<16:20, 42.62s/it]\u001b[A\n",
            "Iteration:  69% 50/72 [35:23<15:36, 42.58s/it]\u001b[A\n",
            "Iteration:  71% 51/72 [36:06<14:53, 42.56s/it]\u001b[A\n",
            "Iteration:  72% 52/72 [36:48<14:10, 42.51s/it]\u001b[A\n",
            "Iteration:  74% 53/72 [37:30<13:26, 42.44s/it]\u001b[A\n",
            "Iteration:  75% 54/72 [38:13<12:43, 42.40s/it]\u001b[A\n",
            "Iteration:  76% 55/72 [38:55<12:00, 42.41s/it]\u001b[A\n",
            "Iteration:  78% 56/72 [39:37<11:17, 42.36s/it]\u001b[A\n",
            "Iteration:  79% 57/72 [40:19<10:33, 42.26s/it]\u001b[A\n",
            "Iteration:  81% 58/72 [41:02<09:53, 42.42s/it]\u001b[A\n",
            "Iteration:  82% 59/72 [41:44<09:09, 42.30s/it]\u001b[A\n",
            "Iteration:  83% 60/72 [42:27<08:28, 42.35s/it]\u001b[A\n",
            "Iteration:  85% 61/72 [43:09<07:46, 42.39s/it]\u001b[A\n",
            "Iteration:  86% 62/72 [43:51<07:02, 42.26s/it]\u001b[A\n",
            "Iteration:  88% 63/72 [44:33<06:20, 42.31s/it]\u001b[A\n",
            "Iteration:  89% 64/72 [45:16<05:38, 42.30s/it]\u001b[A\n",
            "Iteration:  90% 65/72 [45:58<04:56, 42.39s/it]\u001b[A\n",
            "Iteration:  92% 66/72 [46:41<04:14, 42.38s/it]\u001b[A\n",
            "Iteration:  93% 67/72 [47:23<03:31, 42.33s/it]\u001b[A\n",
            "Iteration:  94% 68/72 [48:05<02:49, 42.36s/it]\u001b[A\n",
            "Iteration:  96% 69/72 [48:48<02:07, 42.40s/it]\u001b[A\n",
            "Iteration:  97% 70/72 [49:30<01:24, 42.35s/it]\u001b[A\n",
            "Iteration:  99% 71/72 [50:12<00:42, 42.34s/it]\u001b[A\n",
            "Iteration: 100% 72/72 [50:25<00:00, 33.39s/it]\u001b[A\n",
            "Epoch:  50% 2/4 [1:41:07<1:41:14, 3037.08s/it]\n",
            "Iteration:   0% 0/72 [00:00<?, ?it/s]\u001b[A\n",
            "Iteration:   1% 1/72 [00:42<50:47, 42.93s/it]\u001b[A\n",
            "Iteration:   3% 2/72 [01:25<49:51, 42.74s/it]\u001b[A\n",
            "Iteration:   4% 3/72 [02:07<49:00, 42.62s/it]\u001b[A\n",
            "Iteration:   6% 4/72 [02:49<48:11, 42.52s/it]\u001b[A\n",
            "Iteration:   7% 5/72 [03:31<47:15, 42.32s/it]\u001b[A\n",
            "Iteration:   8% 6/72 [04:14<46:33, 42.32s/it]\u001b[A\n",
            "Iteration:  10% 7/72 [04:55<45:42, 42.20s/it]\u001b[A\n",
            "Iteration:  11% 8/72 [05:37<44:56, 42.14s/it]\u001b[A\n",
            "Iteration:  12% 9/72 [06:20<44:21, 42.25s/it]\u001b[A\n",
            "Iteration:  14% 10/72 [07:02<43:36, 42.20s/it]\u001b[A\n",
            "Iteration:  15% 11/72 [07:44<42:57, 42.25s/it]\u001b[A\n",
            "Iteration:  17% 12/72 [08:27<42:15, 42.25s/it]\u001b[A\n",
            "Iteration:  18% 13/72 [09:09<41:30, 42.22s/it]\u001b[A\n",
            "Iteration:  19% 14/72 [09:51<40:44, 42.15s/it]\u001b[A\n",
            "Iteration:  21% 15/72 [10:33<40:06, 42.22s/it]\u001b[A\n",
            "Iteration:  22% 16/72 [11:16<39:29, 42.32s/it]\u001b[A\n",
            "Iteration:  24% 17/72 [11:58<38:46, 42.30s/it]\u001b[A\n",
            "Iteration:  25% 18/72 [12:40<38:06, 42.34s/it]\u001b[A\n",
            "Iteration:  26% 19/72 [13:22<37:18, 42.24s/it]\u001b[A\n",
            "Iteration:  28% 20/72 [14:05<36:34, 42.20s/it]\u001b[A\n",
            "Iteration:  29% 21/72 [14:47<35:52, 42.20s/it]\u001b[A\n",
            "Iteration:  31% 22/72 [15:29<35:06, 42.13s/it]\u001b[A\n",
            "Iteration:  32% 23/72 [16:11<34:31, 42.27s/it]\u001b[A\n",
            "Iteration:  33% 24/72 [16:53<33:43, 42.17s/it]\u001b[A\n",
            "Iteration:  35% 25/72 [17:35<33:02, 42.18s/it]\u001b[A\n",
            "Iteration:  36% 26/72 [18:18<32:23, 42.25s/it]\u001b[A\n",
            "Iteration:  38% 27/72 [19:00<31:40, 42.24s/it]\u001b[A\n",
            "Iteration:  39% 28/72 [19:43<31:01, 42.32s/it]\u001b[A\n",
            "Iteration:  40% 29/72 [20:25<30:23, 42.40s/it]\u001b[A\n",
            "Iteration:  42% 30/72 [21:08<29:40, 42.39s/it]\u001b[A\n",
            "Iteration:  43% 31/72 [21:50<28:59, 42.42s/it]\u001b[A\n",
            "Iteration:  44% 32/72 [22:32<28:16, 42.42s/it]\u001b[A\n",
            "Iteration:  46% 33/72 [23:15<27:33, 42.39s/it]\u001b[A\n",
            "Iteration:  47% 34/72 [23:57<26:49, 42.36s/it]\u001b[A\n",
            "Iteration:  49% 35/72 [24:40<26:09, 42.43s/it]\u001b[A\n",
            "Iteration:  50% 36/72 [25:22<25:28, 42.45s/it]\u001b[A\n",
            "Iteration:  51% 37/72 [26:05<24:45, 42.44s/it]\u001b[A\n",
            "Iteration:  53% 38/72 [26:47<24:07, 42.57s/it]\u001b[A\n",
            "Iteration:  54% 39/72 [27:30<23:23, 42.53s/it]\u001b[A\n",
            "Iteration:  56% 40/72 [28:13<22:43, 42.61s/it]\u001b[A\n",
            "Iteration:  57% 41/72 [28:55<22:00, 42.59s/it]\u001b[A\n",
            "Iteration:  58% 42/72 [29:38<21:17, 42.57s/it]\u001b[A\n",
            "Iteration:  60% 43/72 [30:20<20:34, 42.57s/it]\u001b[A\n",
            "Iteration:  61% 44/72 [31:03<19:49, 42.48s/it]\u001b[A\n",
            "Iteration:  62% 45/72 [31:45<19:07, 42.52s/it]\u001b[A\n",
            "Iteration:  64% 46/72 [32:28<18:25, 42.51s/it]\u001b[A\n",
            "Iteration:  65% 47/72 [33:10<17:41, 42.47s/it]\u001b[A\n",
            "Iteration:  67% 48/72 [33:52<16:56, 42.34s/it]\u001b[A\n",
            "Iteration:  68% 49/72 [34:35<16:16, 42.44s/it]\u001b[A\n",
            "Iteration:  69% 50/72 [35:17<15:32, 42.41s/it]\u001b[A\n",
            "Iteration:  71% 51/72 [35:59<14:49, 42.38s/it]\u001b[A\n",
            "Iteration:  72% 52/72 [36:42<14:07, 42.35s/it]\u001b[A\n",
            "Iteration:  74% 53/72 [37:24<13:24, 42.37s/it]\u001b[A\n",
            "Iteration:  75% 54/72 [38:07<12:43, 42.40s/it]\u001b[A\n",
            "Iteration:  76% 55/72 [38:49<11:59, 42.34s/it]\u001b[A\n",
            "Iteration:  78% 56/72 [39:31<11:17, 42.31s/it]\u001b[A\n",
            "Iteration:  79% 57/72 [40:14<10:35, 42.39s/it]\u001b[A\n",
            "Iteration:  81% 58/72 [40:55<09:51, 42.23s/it]\u001b[A\n",
            "Iteration:  82% 59/72 [41:37<09:08, 42.16s/it]\u001b[A\n",
            "Iteration:  83% 60/72 [42:20<08:27, 42.31s/it]\u001b[A\n",
            "Iteration:  85% 61/72 [43:02<07:45, 42.31s/it]\u001b[A\n",
            "Iteration:  86% 62/72 [43:48<07:13, 43.38s/it]\u001b[A\n",
            "Iteration:  88% 63/72 [44:31<06:27, 43.08s/it]\u001b[A\n",
            "Iteration:  89% 64/72 [45:13<05:42, 42.84s/it]\u001b[A\n",
            "Iteration:  90% 65/72 [45:55<04:58, 42.61s/it]\u001b[A\n",
            "Iteration:  92% 66/72 [46:37<04:15, 42.57s/it]\u001b[A\n",
            "Iteration:  93% 67/72 [47:20<03:32, 42.52s/it]\u001b[A\n",
            "Iteration:  94% 68/72 [48:02<02:49, 42.49s/it]\u001b[A\n",
            "Iteration:  96% 69/72 [48:45<02:07, 42.50s/it]\u001b[A\n",
            "Iteration:  97% 70/72 [49:27<01:24, 42.42s/it]\u001b[A\n",
            "Iteration:  99% 71/72 [50:09<00:42, 42.42s/it]\u001b[A\n",
            "Iteration: 100% 72/72 [50:22<00:00, 33.43s/it]\u001b[A\n",
            "Epoch:  75% 3/4 [2:31:29<50:32, 3032.69s/it]  \n",
            "Iteration:   0% 0/72 [00:00<?, ?it/s]\u001b[A\n",
            "Iteration:   1% 1/72 [00:42<50:19, 42.53s/it]\u001b[A\n",
            "Iteration:   3% 2/72 [01:24<49:27, 42.40s/it]\u001b[A\n",
            "Iteration:   4% 3/72 [02:06<48:43, 42.37s/it]\u001b[A\n",
            "Iteration:   6% 4/72 [02:48<47:53, 42.26s/it]\u001b[A\n",
            "Iteration:   7% 5/72 [03:30<47:07, 42.20s/it]\u001b[A\n",
            "Iteration:   8% 6/72 [04:13<46:28, 42.25s/it]\u001b[A\n",
            "Iteration:  10% 7/72 [04:55<45:42, 42.19s/it]\u001b[A\n",
            "Iteration:  11% 8/72 [05:37<44:59, 42.19s/it]\u001b[A\n",
            "Iteration:  12% 9/72 [06:19<44:18, 42.19s/it]\u001b[A\n",
            "Iteration:  14% 10/72 [07:01<43:34, 42.17s/it]\u001b[A\n",
            "Iteration:  15% 11/72 [07:44<42:59, 42.29s/it]\u001b[A\n",
            "Iteration:  17% 12/72 [08:28<42:41, 42.69s/it]\u001b[A\n",
            "Iteration:  18% 13/72 [09:10<41:49, 42.53s/it]\u001b[A\n",
            "Iteration:  19% 14/72 [09:52<41:03, 42.47s/it]\u001b[A\n",
            "Iteration:  21% 15/72 [10:34<40:14, 42.36s/it]\u001b[A\n",
            "Iteration:  22% 16/72 [11:16<39:29, 42.32s/it]\u001b[A\n",
            "Iteration:  24% 17/72 [11:59<38:45, 42.29s/it]\u001b[A\n",
            "Iteration:  25% 18/72 [12:41<38:01, 42.24s/it]\u001b[A\n",
            "Iteration:  26% 19/72 [13:23<37:15, 42.18s/it]\u001b[A\n",
            "Iteration:  28% 20/72 [14:05<36:34, 42.20s/it]\u001b[A\n",
            "Iteration:  29% 21/72 [14:47<35:48, 42.13s/it]\u001b[A\n",
            "Iteration:  31% 22/72 [15:29<35:04, 42.09s/it]\u001b[A\n",
            "Iteration:  32% 23/72 [16:11<34:22, 42.09s/it]\u001b[A\n",
            "Iteration:  33% 24/72 [16:53<33:41, 42.11s/it]\u001b[A\n",
            "Iteration:  35% 25/72 [17:36<33:01, 42.16s/it]\u001b[A\n",
            "Iteration:  36% 26/72 [18:18<32:23, 42.25s/it]\u001b[A\n",
            "Iteration:  38% 27/72 [19:00<31:37, 42.17s/it]\u001b[A\n",
            "Iteration:  39% 28/72 [19:42<30:56, 42.19s/it]\u001b[A\n",
            "Iteration:  40% 29/72 [20:24<30:14, 42.21s/it]\u001b[A\n",
            "Iteration:  42% 30/72 [21:06<29:30, 42.15s/it]\u001b[A\n",
            "Iteration:  43% 31/72 [21:49<28:53, 42.28s/it]\u001b[A\n",
            "Iteration:  44% 32/72 [22:31<28:10, 42.26s/it]\u001b[A\n",
            "Iteration:  46% 33/72 [23:14<27:32, 42.37s/it]\u001b[A\n",
            "Iteration:  47% 34/72 [23:56<26:51, 42.40s/it]\u001b[A\n",
            "Iteration:  49% 35/72 [24:38<26:05, 42.32s/it]\u001b[A\n",
            "Iteration:  50% 36/72 [25:21<25:22, 42.29s/it]\u001b[A\n",
            "Iteration:  51% 37/72 [26:03<24:40, 42.30s/it]\u001b[A\n",
            "Iteration:  53% 38/72 [26:45<23:56, 42.26s/it]\u001b[A\n",
            "Iteration:  54% 39/72 [27:27<23:13, 42.23s/it]\u001b[A\n",
            "Iteration:  56% 40/72 [28:10<22:34, 42.32s/it]\u001b[A\n",
            "Iteration:  57% 41/72 [28:52<21:53, 42.37s/it]\u001b[A\n",
            "Iteration:  58% 42/72 [29:35<21:09, 42.31s/it]\u001b[A\n",
            "Iteration:  60% 43/72 [30:17<20:28, 42.35s/it]\u001b[A\n",
            "Iteration:  61% 44/72 [30:59<19:42, 42.25s/it]\u001b[A\n",
            "Iteration:  62% 45/72 [31:41<18:59, 42.22s/it]\u001b[A\n",
            "Iteration:  64% 46/72 [32:23<18:18, 42.26s/it]\u001b[A\n",
            "Iteration:  65% 47/72 [33:06<17:36, 42.25s/it]\u001b[A\n",
            "Iteration:  67% 48/72 [33:49<16:58, 42.42s/it]\u001b[A\n",
            "Iteration:  68% 49/72 [34:31<16:14, 42.36s/it]\u001b[A\n",
            "Iteration:  69% 50/72 [35:13<15:30, 42.29s/it]\u001b[A\n",
            "Iteration:  71% 51/72 [35:55<14:46, 42.24s/it]\u001b[A\n",
            "Iteration:  72% 52/72 [36:37<14:03, 42.16s/it]\u001b[A\n",
            "Iteration:  74% 53/72 [37:19<13:21, 42.21s/it]\u001b[A\n",
            "Iteration:  75% 54/72 [38:02<12:39, 42.21s/it]\u001b[A\n",
            "Iteration:  76% 55/72 [38:44<11:58, 42.27s/it]\u001b[A\n",
            "Iteration:  78% 56/72 [39:26<11:16, 42.28s/it]\u001b[A\n",
            "Iteration:  79% 57/72 [40:09<10:34, 42.29s/it]\u001b[A\n",
            "Iteration:  81% 58/72 [40:51<09:51, 42.25s/it]\u001b[A\n",
            "Iteration:  82% 59/72 [41:33<09:08, 42.21s/it]\u001b[A\n",
            "Iteration:  83% 60/72 [42:15<08:26, 42.24s/it]\u001b[A\n",
            "Iteration:  85% 61/72 [42:57<07:44, 42.21s/it]\u001b[A\n",
            "Iteration:  86% 62/72 [43:40<07:02, 42.27s/it]\u001b[A\n",
            "Iteration:  88% 63/72 [44:22<06:20, 42.29s/it]\u001b[A\n",
            "Iteration:  89% 64/72 [45:04<05:37, 42.22s/it]\u001b[A\n",
            "Iteration:  90% 65/72 [45:46<04:55, 42.18s/it]\u001b[A\n",
            "Iteration:  92% 66/72 [46:29<04:13, 42.23s/it]\u001b[A\n",
            "Iteration:  93% 67/72 [47:11<03:31, 42.21s/it]\u001b[A\n",
            "Iteration:  94% 68/72 [47:53<02:49, 42.30s/it]\u001b[A\n",
            "Iteration:  96% 69/72 [48:36<02:06, 42.31s/it]\u001b[A\n",
            "Iteration:  97% 70/72 [49:18<01:24, 42.46s/it]\u001b[A\n",
            "Iteration:  99% 71/72 [50:01<00:42, 42.43s/it]\u001b[A\n",
            "Iteration: 100% 72/72 [50:13<00:00, 33.34s/it]\u001b[A\n",
            "Epoch: 100% 4/4 [3:21:43<00:00, 3026.88s/it]\n",
            "02/15/2020 10:15:47 - INFO - __main__ -    global_step = 288, average loss = 2.8283023685216904\n",
            "02/15/2020 10:15:47 - INFO - __main__ -   Saving model checkpoint to output\n",
            "02/15/2020 10:15:47 - INFO - transformers.configuration_utils -   Configuration saved in output/config.json\n",
            "02/15/2020 10:15:48 - INFO - transformers.modeling_utils -   Model weights saved in output/pytorch_model.bin\n",
            "02/15/2020 10:15:48 - INFO - transformers.configuration_utils -   loading configuration file output/config.json\n",
            "02/15/2020 10:15:48 - INFO - transformers.configuration_utils -   Model config GPT2Config {\n",
            "  \"architectures\": [\n",
            "    \"GPT2LMHeadModel\"\n",
            "  ],\n",
            "  \"attn_pdrop\": 0.1,\n",
            "  \"bos_token_id\": 0,\n",
            "  \"do_sample\": false,\n",
            "  \"embd_pdrop\": 0.1,\n",
            "  \"eos_token_ids\": 0,\n",
            "  \"finetuning_task\": null,\n",
            "  \"id2label\": {\n",
            "    \"0\": \"LABEL_0\",\n",
            "    \"1\": \"LABEL_1\"\n",
            "  },\n",
            "  \"initializer_range\": 0.02,\n",
            "  \"is_decoder\": false,\n",
            "  \"label2id\": {\n",
            "    \"LABEL_0\": 0,\n",
            "    \"LABEL_1\": 1\n",
            "  },\n",
            "  \"layer_norm_epsilon\": 1e-05,\n",
            "  \"length_penalty\": 1.0,\n",
            "  \"max_length\": 20,\n",
            "  \"model_type\": \"gpt2\",\n",
            "  \"n_ctx\": 1024,\n",
            "  \"n_embd\": 768,\n",
            "  \"n_head\": 12,\n",
            "  \"n_layer\": 12,\n",
            "  \"n_positions\": 1024,\n",
            "  \"num_beams\": 1,\n",
            "  \"num_labels\": 2,\n",
            "  \"num_return_sequences\": 1,\n",
            "  \"output_attentions\": false,\n",
            "  \"output_hidden_states\": false,\n",
            "  \"output_past\": true,\n",
            "  \"pad_token_id\": 0,\n",
            "  \"pruned_heads\": {},\n",
            "  \"repetition_penalty\": 1.0,\n",
            "  \"resid_pdrop\": 0.1,\n",
            "  \"summary_activation\": null,\n",
            "  \"summary_first_dropout\": 0.1,\n",
            "  \"summary_proj_to_labels\": true,\n",
            "  \"summary_type\": \"cls_index\",\n",
            "  \"summary_use_proj\": true,\n",
            "  \"temperature\": 1.0,\n",
            "  \"top_k\": 50,\n",
            "  \"top_p\": 1.0,\n",
            "  \"torchscript\": false,\n",
            "  \"use_bfloat16\": false,\n",
            "  \"vocab_size\": 50257\n",
            "}\n",
            "\n",
            "02/15/2020 10:15:48 - INFO - transformers.modeling_utils -   loading weights file output/pytorch_model.bin\n",
            "02/15/2020 10:15:52 - INFO - transformers.tokenization_utils -   Model name 'output' not found in model shortcut name list (gpt2, gpt2-medium, gpt2-large, gpt2-xl, distilgpt2). Assuming 'output' is a path, a model identifier, or url to a directory containing tokenizer files.\n",
            "02/15/2020 10:15:52 - INFO - transformers.tokenization_utils -   Didn't find file output/added_tokens.json. We won't load it.\n",
            "02/15/2020 10:15:52 - INFO - transformers.tokenization_utils -   loading file output/vocab.json\n",
            "02/15/2020 10:15:52 - INFO - transformers.tokenization_utils -   loading file output/merges.txt\n",
            "02/15/2020 10:15:52 - INFO - transformers.tokenization_utils -   loading file None\n",
            "02/15/2020 10:15:52 - INFO - transformers.tokenization_utils -   loading file output/special_tokens_map.json\n",
            "02/15/2020 10:15:52 - INFO - transformers.tokenization_utils -   loading file output/tokenizer_config.json\n",
            "02/15/2020 10:15:52 - INFO - __main__ -   Evaluate the following checkpoints: ['output']\n",
            "02/15/2020 10:15:52 - INFO - transformers.configuration_utils -   loading configuration file output/config.json\n",
            "02/15/2020 10:15:52 - INFO - transformers.configuration_utils -   Model config GPT2Config {\n",
            "  \"architectures\": [\n",
            "    \"GPT2LMHeadModel\"\n",
            "  ],\n",
            "  \"attn_pdrop\": 0.1,\n",
            "  \"bos_token_id\": 0,\n",
            "  \"do_sample\": false,\n",
            "  \"embd_pdrop\": 0.1,\n",
            "  \"eos_token_ids\": 0,\n",
            "  \"finetuning_task\": null,\n",
            "  \"id2label\": {\n",
            "    \"0\": \"LABEL_0\",\n",
            "    \"1\": \"LABEL_1\"\n",
            "  },\n",
            "  \"initializer_range\": 0.02,\n",
            "  \"is_decoder\": false,\n",
            "  \"label2id\": {\n",
            "    \"LABEL_0\": 0,\n",
            "    \"LABEL_1\": 1\n",
            "  },\n",
            "  \"layer_norm_epsilon\": 1e-05,\n",
            "  \"length_penalty\": 1.0,\n",
            "  \"max_length\": 20,\n",
            "  \"model_type\": \"gpt2\",\n",
            "  \"n_ctx\": 1024,\n",
            "  \"n_embd\": 768,\n",
            "  \"n_head\": 12,\n",
            "  \"n_layer\": 12,\n",
            "  \"n_positions\": 1024,\n",
            "  \"num_beams\": 1,\n",
            "  \"num_labels\": 2,\n",
            "  \"num_return_sequences\": 1,\n",
            "  \"output_attentions\": false,\n",
            "  \"output_hidden_states\": false,\n",
            "  \"output_past\": true,\n",
            "  \"pad_token_id\": 0,\n",
            "  \"pruned_heads\": {},\n",
            "  \"repetition_penalty\": 1.0,\n",
            "  \"resid_pdrop\": 0.1,\n",
            "  \"summary_activation\": null,\n",
            "  \"summary_first_dropout\": 0.1,\n",
            "  \"summary_proj_to_labels\": true,\n",
            "  \"summary_type\": \"cls_index\",\n",
            "  \"summary_use_proj\": true,\n",
            "  \"temperature\": 1.0,\n",
            "  \"top_k\": 50,\n",
            "  \"top_p\": 1.0,\n",
            "  \"torchscript\": false,\n",
            "  \"use_bfloat16\": false,\n",
            "  \"vocab_size\": 50257\n",
            "}\n",
            "\n",
            "02/15/2020 10:15:52 - INFO - transformers.modeling_utils -   loading weights file output/pytorch_model.bin\n",
            "02/15/2020 10:15:56 - INFO - __main__ -   Loading features from cached file gpt2_cached_lm_1024_socrates.txt\n",
            "02/15/2020 10:15:56 - INFO - __main__ -   ***** Running evaluation  *****\n",
            "02/15/2020 10:15:56 - INFO - __main__ -     Num examples = 285\n",
            "02/15/2020 10:15:56 - INFO - __main__ -     Batch size = 4\n",
            "Evaluating: 100% 72/72 [15:57<00:00, 10.45s/it]\n",
            "02/15/2020 10:31:54 - INFO - __main__ -   ***** Eval results  *****\n",
            "02/15/2020 10:31:54 - INFO - __main__ -     perplexity = tensor(12.9068)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ljYrA1p1UkMC",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "outputId": "ec0b418c-1fc3-4005-e664-dd445963a440"
      },
      "source": [
        "!python transformers/examples/run_generation.py --model_type=gpt2 --model_name_or_path=output --no_cuda"
      ],
      "execution_count": 27,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "02/15/2020 19:21:30 - INFO - transformers.tokenization_utils -   Model name 'output' not found in model shortcut name list (gpt2, gpt2-medium, gpt2-large, gpt2-xl, distilgpt2). Assuming 'output' is a path, a model identifier, or url to a directory containing tokenizer files.\n",
            "02/15/2020 19:21:30 - INFO - transformers.tokenization_utils -   Didn't find file output/added_tokens.json. We won't load it.\n",
            "02/15/2020 19:21:30 - INFO - transformers.tokenization_utils -   loading file output/vocab.json\n",
            "02/15/2020 19:21:30 - INFO - transformers.tokenization_utils -   loading file output/merges.txt\n",
            "02/15/2020 19:21:30 - INFO - transformers.tokenization_utils -   loading file None\n",
            "02/15/2020 19:21:30 - INFO - transformers.tokenization_utils -   loading file output/special_tokens_map.json\n",
            "02/15/2020 19:21:30 - INFO - transformers.tokenization_utils -   loading file output/tokenizer_config.json\n",
            "02/15/2020 19:21:30 - INFO - transformers.configuration_utils -   loading configuration file output/config.json\n",
            "02/15/2020 19:21:30 - INFO - transformers.configuration_utils -   Model config GPT2Config {\n",
            "  \"architectures\": [\n",
            "    \"GPT2LMHeadModel\"\n",
            "  ],\n",
            "  \"attn_pdrop\": 0.1,\n",
            "  \"bos_token_id\": 0,\n",
            "  \"do_sample\": false,\n",
            "  \"embd_pdrop\": 0.1,\n",
            "  \"eos_token_ids\": 0,\n",
            "  \"finetuning_task\": null,\n",
            "  \"id2label\": {\n",
            "    \"0\": \"LABEL_0\",\n",
            "    \"1\": \"LABEL_1\"\n",
            "  },\n",
            "  \"initializer_range\": 0.02,\n",
            "  \"is_decoder\": false,\n",
            "  \"label2id\": {\n",
            "    \"LABEL_0\": 0,\n",
            "    \"LABEL_1\": 1\n",
            "  },\n",
            "  \"layer_norm_epsilon\": 1e-05,\n",
            "  \"length_penalty\": 1.0,\n",
            "  \"max_length\": 20,\n",
            "  \"model_type\": \"gpt2\",\n",
            "  \"n_ctx\": 1024,\n",
            "  \"n_embd\": 768,\n",
            "  \"n_head\": 12,\n",
            "  \"n_layer\": 12,\n",
            "  \"n_positions\": 1024,\n",
            "  \"num_beams\": 1,\n",
            "  \"num_labels\": 2,\n",
            "  \"num_return_sequences\": 1,\n",
            "  \"output_attentions\": false,\n",
            "  \"output_hidden_states\": false,\n",
            "  \"output_past\": true,\n",
            "  \"pad_token_id\": 0,\n",
            "  \"pruned_heads\": {},\n",
            "  \"repetition_penalty\": 1.0,\n",
            "  \"resid_pdrop\": 0.1,\n",
            "  \"summary_activation\": null,\n",
            "  \"summary_first_dropout\": 0.1,\n",
            "  \"summary_proj_to_labels\": true,\n",
            "  \"summary_type\": \"cls_index\",\n",
            "  \"summary_use_proj\": true,\n",
            "  \"temperature\": 1.0,\n",
            "  \"top_k\": 50,\n",
            "  \"top_p\": 1.0,\n",
            "  \"torchscript\": false,\n",
            "  \"use_bfloat16\": false,\n",
            "  \"vocab_size\": 50257\n",
            "}\n",
            "\n",
            "02/15/2020 19:21:30 - INFO - transformers.modeling_utils -   loading weights file output/pytorch_model.bin\n",
            "02/15/2020 19:21:35 - INFO - __main__ -   Namespace(device=device(type='cpu'), k=0, length=20, model_name_or_path='output', model_type='gpt2', n_gpu=0, no_cuda=True, p=0.9, padding_text='', prompt='', repetition_penalty=1.0, seed=42, stop_token=None, temperature=1.0, xlm_language='')\n",
            "Model prompt >>> Does a multiverse exists?\n",
            "Does a multiverse exists?\n",
            "\n",
            "The answer is that, if it did exist, then!\n"
          ],
          "name": "stdout"
        }
      ]
    }
  ]
}